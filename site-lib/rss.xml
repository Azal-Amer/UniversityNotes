<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[ObsidianVault]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>ObsidianVault</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 17 Feb 2026 23:46:21 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 17 Feb 2026 23:46:11 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[1.10 Blocking and Programming Patterns]]></title><description><![CDATA[Today we mainly covered safer ways to context switch when implementing blocking in our system. Instead of running ./attach_qemu, if. you run ./debug_qemu you'll need to repeat a hundred times.
Attach_qemu is really good for cases where the program gets suck. Attach_qemu till start the program and we wait for it to get stuck. The best way to debug, and he went back through it with us, he always does it very early in the morning before he has coffee.
It's impossible to debug t0 with gdb, there's just too much happening at once trying to stress the heap and stopping test. The best way is that we simplify the test, until we find the simplest possible version of it that fails!
Find the simplest form which has the same failure. We'd find very often there's a 3 line test case which also fails, and that's what we debug
Put literally as many assertions down as possible when you assume for example, that an idle thread can never make it to a point. Make the assumptions explicit and test them. Me whenA weak pointer doesn't keep your object alive<a data-footref="1" href="#fn-1-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[1]</a>, just is the reference to it! So the pointer can become null1class Lock{2	Atomic bool{false} taken3	lock(){4 while(taken.exchange(true)){5 // spun in a loop6 }7	}8	9	unlock(){10 taken.set(false);11 // make sure you can't unlock it you don't own it12 // make sure you don't unlock it while unlocked13 // this is just the essence of the implementation14	}15}The issue with spinning is that it's wasteful!
The way we can improve it is with a yieldThe bZombie queue/reaper queue1post_switch(){2	yeild-&gt;rq.add(prev);3	stopping-&gt;z.add(prev);4	idle_thread-&gt;;5	lock-&gt;6 lock-&gt;spin.lock()7 if(lock-&gt;taken){8 lock.waiting.add(prev);9 spin.unlock()	10 }11 else{12 spin.unlock();13 rq.add(prev);14 }15}1next = rq.remove();2spin.lock()3while(taken){4	next = rq.tryRemove();5	// if this is null, try to get something and we might get null but we dunno where to swithc. this doesnt retru6	if(next == null){7	//did my best8	9 spin.unlock();10	}11	else{12 // we have someone to switch to13 wq.add(me);14 //waitingqueue15 block(next,&amp;spin);16 //context switch me to the next and release the spinlock17	}18	19	20	spin.unlock();21	// she's ready when the above line happen22}23// we wa <br><a data-href="1.9 Smart Pointers#Weak Pointer" href="school/cs/cs-439/notes/1.9-smart-pointers.html#Weak Pointer" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Smart Pointers &gt; Weak Pointer</a><a data-href="1.9 Smart Pointers#Weak Pointer" href="school/cs/cs-439/notes/1.9-smart-pointers.html#Weak Pointer" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.9 Smart Pointers &gt; Weak Pointer</a><a href="#fnref-1-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br><a data-href="1.8 Synchronization Primitives#Blocking Lock" href="school/cs/cs-439/notes/1.8-synchronization-primitives.html#Blocking Lock" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Synchronization Primitives &gt; Blocking Lock</a><a data-href="1.8 Synchronization Primitives#Blocking Lock" href="school/cs/cs-439/notes/1.8-synchronization-primitives.html#Blocking Lock" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.8 Synchronization Primitives &gt; Blocking Lock</a><a href="#fnref-2-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
]]></description><link>school/cs/cs-439/notes/1.10-blocking-and-programming-patterns.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.10 Blocking and Programming Patterns.md</guid><pubDate>Tue, 17 Feb 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.10 a QUANTUM Field theory]]></title><description><![CDATA[Midterm is Thursday March 5th
We want to start with a classical where particles might not strongly interact. <a data-footref="1" href="#fn-1-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[1]</a>
<br>Noether's Theorem<a data-footref="2" href="#fn-2-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[2]</a>
<br>Creation and Annihilation Operators <a data-footref="3" href="#fn-3-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[3]</a>
Now we're going to quantize our field by converting our complex scalar field to an operator field !<br>
That operator field which is a linear combination of plane wave solutions (from our book Ch 12) to our <a data-tooltip-position="top" aria-label="1.4 Least Action > ^a4a4c9" data-href="1.4 Least Action#^a4a4c9" href="school/physics/quantum-3/notes/1.4-least-action.html#^a4a4c9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">E-L Equation</a><a data-tooltip-position="top" aria-label="1.4 Least Action > ^a4a4c9" data-href="1.4 Least Action#^a4a4c9" href="school/physics/quantum-3/notes/1.4-least-action.html#^a4a4c9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">E-L Equation</a>. Instead of amplitude being a scalar, it's a combination of !
Then we think about our normal ordering, where comes to the right of Step 1 we found Step 2
Then Noether's theorem had energy density ofCurrent density of Last week
Step 3
Define = Our number operator returns out the amplitude of the number there where Today we're working on steps 4-6 (Step 6 is profit)Classically which depends on our The operator field also depends on these properties, but changes the state of the Fock space at . It implies that the operators are operating on the vacuum state or from an existing state. should be a linear combination of creation and destruction operators, where We can remove initial state particles
We can add final state particles with a given Conserve 4 momentum
<br><img alt="../../../../Supplemental Files/images/Pasted image 20260217112542.png" src="supplemental-files/images/pasted-image-20260217112542.png" target="_self">Our new particles are non interacting and free particles. If this was a fancy private school we'd use expensive particles but its not so they're freeOur operator field hasThis gives us creation and destruction operators for phions and anti-phions
<br>The really handwavey reason for why this works to swap our amplitudes to creation and annihilation operators s that we look back at our ball on spring example<a data-footref="4" href="#fn-4-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[4]</a>
<br>At the end what we're really interested is the total energy and total charge of this field, from <a data-href="#^0e78e7" href="#^0e78e7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^0e78e7</a><a data-href="#^0e78e7" href="#^0e78e7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.2)</a> and <a data-href="#^e5c428" href="#^e5c428" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^e5c428</a><a data-href="#^e5c428" href="#^e5c428" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.3)</a> <br>The total energy we then integrate the energy density <a data-href="#^0e78e7" href="#^0e78e7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^0e78e7</a><a data-href="#^0e78e7" href="#^0e78e7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.2)</a> over all space.
For the chargeWe can write the integrals for our system togetherIn the subscripts I ommited the vector signs, is that okay?
It is useful to have with dot products
Exercise 1.10.1 (Calculate the term ). because otherwise we get a bunch of dirac deltas throwing out the other options We're about to sweet an infinity under the rug for our total chargeUsing the fact that commutator of Those are just both number operators for the mutual particles! LOOK ANTI-PARTICLES HAVE OPPOSITE MASS BUT THE SAME CHARGE AS THE PARTICLE! <br><a data-href="1.5 Klien Gordon" href="school/physics/quantum-3/notes/1.5-klien-gordon.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.5 Klien Gordon</a><a data-href="1.5 Klien Gordon" href="school/physics/quantum-3/notes/1.5-klien-gordon.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.5 Klien Gordon</a><a href="#fnref-1-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br><a data-href="1.6 Noethers Theorem" href="school/physics/quantum-3/notes/1.6-noethers-theorem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Noethers Theorem</a><a data-href="1.6 Noethers Theorem" href="school/physics/quantum-3/notes/1.6-noethers-theorem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.6 Noethers Theorem</a><a href="#fnref-2-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br><a data-href="1.9 Creation and Annihilation Operators" href="school/physics/quantum-3/notes/1.9-creation-and-annihilation-operators.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Creation and Annihilation Operators</a><a data-href="1.9 Creation and Annihilation Operators" href="school/physics/quantum-3/notes/1.9-creation-and-annihilation-operators.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.9 Creation and Annihilation Operators</a><a href="#fnref-3-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br><a data-href="1.4 Least Action#Lagrangian for a String" href="school/physics/quantum-3/notes/1.4-least-action.html#Lagrangian for a String" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.4 Least Action &gt; Lagrangian for a String</a><a data-href="1.4 Least Action#Lagrangian for a String" href="school/physics/quantum-3/notes/1.4-least-action.html#Lagrangian for a String" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.4 Least Action &gt; Lagrangian for a String</a><a href="#fnref-4-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
]]></description><link>school/physics/quantum-3/notes/1.10-a-quantum-field-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.10 a QUANTUM Field theory.md</guid><pubDate>Tue, 17 Feb 2026 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.4 Least Action]]></title><description><![CDATA[Corrections get submitted on the same assignment on canvas, the homework solutions are due by tonight or tomorrow night
The first upload is just the honesty upload. We correct our own homework, Dalton just looks at it on top.
Corrections are not required for the Box problems
Hint will be very useful for things like exams!
Like the box problem, we start with a 1D oscillator, then take N to infinity and look at the continuous system, then 3D, then the EM field!Later we will work with quantized harmonic oscillators! The principle of least action is that the particle is going to take the shortest possible path between two points (minimizing trajectories)Definition 1.4.1 (Action).
Action is a property which is minimized in the trajectories of physical systems.
It can be defined via the Lagrangian below To minimize action, we can use the Euler Lagrange EquationDefinition 1.4.2 (Euler Lagrange Equation).
The Euler Lagrange Equation is a tool for helping us minimize the property of action for a given set of coordinates Where Because are independent coordinates, we can separate equations for the Euler Lagrange Equation.Example 1.4.3 (2D Potential).
Was one of the box problems (<a data-href="../Homework/Box Problems/Chapter 4#Box 4.3" href="school/physics/quantum-3/homework/box-problems/chapter-4.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Homework/Box Problems/Chapter 4 &gt; Box 4.3</a><a data-href="../Homework/Box Problems/Chapter 4#Box 4.3" href="school/physics/quantum-3/homework/box-problems/chapter-4.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Homework/Box Problems/Chapter 4 &gt; Box 4.3</a>) We have two independent variables, with two Euler Lagrange Equations.
The first one we can do See the rest of my box problem for this worked out, since by the looks of it I did it correctly!
Why is it that with the Euler Lagrange Equation we can treat as separate variables in the partial derivative? is coupled to no? it's because when we use the EL equation, we treat both variables as separate coordinates in phase space
There are oscilatorall connected to a spring, and they can only move up and down1The Lagrangian is the kinetic energy and potentials summedFor an interior mass the EL isTake to the continuum limit as , tension is . Sigma is the oscillation frequency of one mass on its own is In terms of our new variables it's Look it's the wave equation
We can use this to write our Lagrangian as<br>The above just restates <a data-href="#^fe07a2" href="#^fe07a2" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^fe07a2</a><a data-href="#^fe07a2" href="#^fe07a2" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.4.1)</a> !
The action is then (inserting the information from the Lagrangian)Now we think of not as a displacement, but could possibly be the temperature in the room (This is a scalar field)Where is the speed of our wave (the gradient is just for the derivative but in ) if there were no internal springs.Where<br>We can then insert our four vectors to <a data-href="#^e28486" href="#^e28486" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^e28486</a><a data-href="#^e28486" href="#^e28486" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.4.7)</a> with the <a data-href="1.2 Special Relativity#^0d82c4" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^0d82c4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.2 Special Relativity &gt; ^0d82c4</a><a data-href="1.2 Special Relativity#^0d82c4" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^0d82c4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.2.8 (Four vector)</a> metric information to get (and I got lost on teh derivation hereThe above is now a tensor equation which respects Lorentz invariance, and it's frame independent. The EL isand I'm officially lost<br>THIS IS JUST BOX 4.7 <a data-href="../Homework/Box Problems/Chapter 4#4.7.1" href="school/physics/quantum-3/homework/box-problems/chapter-4.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Homework/Box Problems/Chapter 4 &gt; 4.7.1</a><a data-href="../Homework/Box Problems/Chapter 4#4.7.1" href="school/physics/quantum-3/homework/box-problems/chapter-4.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Homework/Box Problems/Chapter 4 &gt; 4.7.1</a>. So at least I have something to review
This gets us toWe're treating all the 's where as independent variables
, ]]></description><link>school/physics/quantum-3/notes/1.4-least-action.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.4 Least Action.md</guid><pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.6 Noethers Theorem]]></title><description><![CDATA[Theorem 1.6.1 (Noether's Theorem).
Every conserved quantity is connected to a fundamental symmetry of nature Noether's Theorem is a tool for identifying
our conserved quantity and what symmetry it points us towards
Can we use fundamental symmetries to determine conservation lawsA Lagrangian depending on . What if where perturbs our coordinate with strength . So .Proof of <a data-href="#^354203" href="#^354203" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^354203</a><a data-href="#^354203" href="#^354203" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.6.1 (Noether's Theorem)</a>.
Noether's Theorem for a classical system has us wanting to find<br>Then we use <a data-href="1.4 Least Action#^a4a4c9" href="school/physics/quantum-3/notes/1.4-least-action.html#^a4a4c9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.4 Least Action &gt; ^a4a4c9</a><a data-href="1.4 Least Action#^a4a4c9" href="school/physics/quantum-3/notes/1.4-least-action.html#^a4a4c9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.4.2 (Euler Lagrange Equation)</a> !<br>We then use the first partial in <a data-href="#^bd2987" href="#^bd2987" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^bd2987</a><a data-href="#^bd2987" href="#^bd2987" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.6.1)</a> to evaluate and getWe can then pull out the partial derivative with respect to time in to getIf is unchanged with respect to or by then our summation equals a constant!
ThereforeThat's our conserved quantity with respect to our symmetry.
□
If we want to know what is conserved, we figure that outHow should I know what conserved quantities that I need to look at for a given system?
Intuition and experimentalism!
When we want to work with relativity, we have to swap our time derivative for something that treats things more even handedIn EM we already measure charge, so we're using that here for (see textbook for description on why it's a density). We also use as current density. Relativistically we just haveConservation of charge is the statement thatCharge is time conserved<br>See <a data-href="../Homework/Box Problems/Chapter 6#Box 6.6" href="school/physics/quantum-3/homework/box-problems/chapter-6.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Homework/Box Problems/Chapter 6 &gt; Box 6.6</a><a data-href="../Homework/Box Problems/Chapter 6#Box 6.6" href="school/physics/quantum-3/homework/box-problems/chapter-6.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Homework/Box Problems/Chapter 6 &gt; Box 6.6</a>Definition 1.6.2 (testing).
Definition 1.6.2 (testing).
Definition 1.6.2 (testing).
Definition 1.6.2 (testing).
Definition 1.6.2 (testing).
Definition 1.6.2 (testing). 1.6 Noethers Theorem.md What if our transformation explicitt]]></description><link>school/physics/quantum-3/notes/1.6-noethers-theorem.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.6 Noethers Theorem.md</guid><pubDate>Tue, 03 Feb 2026 00:00:00 GMT</pubDate><enclosure url="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExazY1ZmxteGt1MDNleHZvbmgzdjR2aGEwamgzY2k1MWxncWFlcTJyaCZlcD12MV9naWZzX3NlYXJjaCZjdD1n/cJziKDR993eBoOMMHW/100.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExazY1ZmxteGt1MDNleHZvbmgzdjR2aGEwamgzY2k1MWxncWFlcTJyaCZlcD12MV9naWZzX3NlYXJjaCZjdD1n/cJziKDR993eBoOMMHW/100.gif"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.8 Measurement and Multiple States]]></title><description><![CDATA[Any quantum transform can be realized with only permutations plus a Fourier transform on (Hadamard gates) (though this is not efficient)
This basically says that you can realize a universal gate set with SWAPs, Hadamards, and ancillas
Definition 1.14.3 ((Approximate) Universal Gate Set). A finite gate set is approximately universal if for any , there exists such that For a smaller , you'd just apply more gates from the set arbitrarily.
Where That is to say, the error is smaller than our resolution of measurement.
Shatton Infinity Norm, or the biggest eigenvalue in the operator.
An example can be found in <a data-href="#^9dfc33" href="#^9dfc33" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^9dfc33</a><a data-href="#^9dfc33" href="#^9dfc33" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.4 (Clifford + T Gate set)</a> <br>Is this related to <a data-href="../../Misc/The Haar Measure#^76f667" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^76f667</a><a data-href="../../Misc/The Haar Measure#^76f667" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 12 (Schur-Weyl Duality)</a> ?Quantum computation is just classical reversible computation but with the ability to change basisFor quantum systems there are infinitely many quantum measurement operations
The easiest example is in the computational basis, we check the probability of a given bitstring via each amplitude
<br>We can use <a data-href="../../Misc/The Haar Measure#^14aa94" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^14aa94</a><a data-href="../../Misc/The Haar Measure#^14aa94" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 8 (Orthogonal Projector)</a>'s to perform measurement. Definition 1.13.1 (Von Neuman Entropy).
A measure of how much uncertainty there is in regarding which pure state that we have. It also can be used as a measure of entanglement between two particles. Definition 1.2.2 (Entropy of the Source).
The expectation value of the self information <br>Well what is the entropy of a quantum state? ? ?<a data-footref="1" href="#fn-1-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[1]</a> It depends on the basis! Can we just diagonalize the density matrix
Well then we're just perfectly aligned with its state, it has no entropy within it's basis.
Two subsystems (qubits, registers) They live in their Hilbert spaces . Let bases
The composite system is . We can describe the qbits in the joint system as is entangled if it can't be written as a product of two other states
Definition 5.1.1 (Bell States).
States that we can use as a basis to make quantum bits in superposition, seperable We can represent the measurement of individual qubits as Where the projector only applies to the first qubit.
Then applying that to This is hinting at a correlated effect between the states for us!If I have a Bell state where the outcomes are directly linked like , for an orthonormal basis is the representation also going to be that the measurement outcomes are the same?<br>This above is never possible. <a data-footref="2" href="#fn-2-5a0cc07a5f4a5a2d" class="footnote-link" target="_self" rel="noopener nofollow">[2]</a>Degeneracy is not obtained through replication, we can't get repetition codes. <br>We can construct our <a data-href="../../Quantum Computing/Summer QC/Lab Notes/Day 12- Uncertainty in Tomography#^112acf" href="school/physics/quantum-computing/summer-qc/lab-notes/day-12-uncertainty-in-tomography.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Summer QC/Lab Notes/Day 12- Uncertainty in Tomography &gt; ^112acf</a><a data-href="../../Quantum Computing/Summer QC/Lab Notes/Day 12- Uncertainty in Tomography#^112acf" href="school/physics/quantum-computing/summer-qc/lab-notes/day-12-uncertainty-in-tomography.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1 (General Density Matrix)</a>! Where is the probability we prepare a state . Pure states have .
Then the density matrix can be computed as the outer product of these things. <br>We're actually maximized at not <a href="#fnref-1-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br><a data-href="../../QIS/Notes/1.5 The Coin Problem and Cloning#^eaca57" href="school/physics/qis/notes/1.5-the-coin-problem-and-cloning.html#^eaca57" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Notes/1.5 The Coin Problem and Cloning &gt; ^eaca57</a><a data-href="../../QIS/Notes/1.5 The Coin Problem and Cloning#^eaca57" href="school/physics/qis/notes/1.5-the-coin-problem-and-cloning.html#^eaca57" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.5.1 (No Cloning Theorem)</a><a href="#fnref-2-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
<br><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/3.2 Mixed Quantum States" data-href="../../Quantum Computing/Semester 1/3.2 Mixed Quantum States" href="school/physics/quantum-computing/semester-1/3.2-mixed-quantum-states.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.2 Mixed Quantum States</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/3.2 Mixed Quantum States" data-href="../../Quantum Computing/Semester 1/3.2 Mixed Quantum States" href="school/physics/quantum-computing/semester-1/3.2-mixed-quantum-states.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">3.2 Mixed Quantum States</a><a href="#fnref-3-5a0cc07a5f4a5a2d" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
]]></description><link>school/physics/quantum-error-correction/notes/1.8-measurement-and-multiple-states.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/1.8 Measurement and Multiple States.md</guid><pubDate>Mon, 16 Feb 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.2 Mixed Quantum States]]></title><description><![CDATA[
Measure qubit in arbitrary orthonormal basis <a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Orthonormal Bases</a><a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Orthonormal Bases</a>, Measure pure qubit state as projection matrix Represent a randomly prepared qubit as a mixed state.
Recognize the properties of pure and mixed quantum states.
Given the below qubit state, prep in IBM QX, measure in R/L basis. What are the expected probabilities of the two possible outcomesRecall thatThen make the two equivalentThen we set , to get our unitary as <br><img alt="Pasted image 20240319173746.png" src="supplemental-files/images/pasted-image-20240319173746.png" target="_self">Using the above table as reference, we can see that if we apply a Hadamard, and an S gate, we measure in the R/L Basis.Setup<br>
<img alt="Screenshot 2024-03-19 at 3.58.35 PM.png" src="supplemental-files/images/screenshot-2024-03-19-at-3.58.35-pm.png" target="_self">Results:<br>
<img alt="Screenshot 2024-03-19 at 3.59.19 PM.png" src="supplemental-files/images/screenshot-2024-03-19-at-3.59.19-pm.png" target="_self"><br>(Review!)<a data-tooltip-position="top" aria-label="3.1 General Qubit States > Forming an Orthonormal Basis" data-href="3.1 General Qubit States#Forming an Orthonormal Basis" href="school/physics/quantum-computing/semester-1/3.1-general-qubit-states.html#Forming_an_Orthonormal_Basis_0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Forming Orthonormal Basis</a><a data-tooltip-position="top" aria-label="3.1 General Qubit States > Forming an Orthonormal Basis" data-href="3.1 General Qubit States#Forming an Orthonormal Basis" href="school/physics/quantum-computing/semester-1/3.1-general-qubit-states.html#Forming_an_Orthonormal_Basis_0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Forming Orthonormal Basis</a>Prepare a qubit in the state And measure in this basisUnitary is To get our desired unitary operator, we just do The dagger will take us back into the digital basis, and this acts as a new unitary
To put this new operator into the IBM we need a corresp. unitary, can use this identity<br>
<a href=".?query=tag:Identity" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Identity">#Identity</a><br><a href=".?query=tag:PracticeQuestion" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#PracticeQuestion">#PracticeQuestion</a> : Finish working through this and write it out
his imperfection?If you setup a simple not gate on the qubit, which should only derive the outcome, experimentally you can still end up getting a wrong measurement<br>
<img alt="Screenshot 2024-03-19 at 4.15.33 PM.png" src="supplemental-files/images/screenshot-2024-03-19-at-4.15.33-pm.png" target="_self">These qubits have some kind of noise, how do we represent tIf we represent a qubit with some kind of implicit preference for a basis, then we can represent a state to a probability.
We can describe an imperfect qubit as a randomly prepared qubit<br><a href=".?query=tag:Question" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Question">#Question</a> How does this differ from superposition?
If you superposition H and V in a DA beamsplitter, you'll get the D result
if you send a H photon simultaneous to the V photon (random preparation), they both behave 50-50 Can be written as a single ket (a superposition of basis states), no probabilities for preparation
Pure state has a Bloch vector equal to 1 Where A pure state can be represented by the outer product of We can then represent the probabilities in the digital basis, as the diagonals!
Density matrix : Exercise 3.2.1 (Prepare with probability and with probability ). Exercise 3.2.2 (Prepare with probability and with probability ). If you are giving the density matrix of a basis, you will by the definition of bra and ket, end up with a scalar multiple of identity
We might not always measure in a basis! What if it was with 50% prob, with 50% prob
Example 3.2.3 (Find the Density matrix with the given table). The Trace must always equal 1**
Consider the following two states, each are half H half V
Maximally Mixed state of Superposition state of , i.e, when we send 100% diagonally polarized photons^dfe90d
This means our density matrices are different. Where in we had a easy 50-50, always regardless of applied operator, in we have items in the off diagonal\]]></description><link>school/physics/quantum-computing/semester-1/3.2-mixed-quantum-states.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/3.2 Mixed Quantum States.md</guid><pubDate>Mon, 16 Feb 2026 20:33:24 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.4 Quantum Observables]]></title><description><![CDATA[<a data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Quantum Gates</a><a data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Quantum Gates</a>Definition 2.4.1 (The Unitary Matrix). A single qubit matrix can be written with he three parameters in the form Find the unitary parameters for each member of the Pauli groupFor every operation on a Bra, there's a corresponding operation on the ketThe probability of a measurement of the "0" outcome is The probability of a measurement of the "1" outcome is If you have some wave-function, and you want to see what the probability of measuring it in horizontal and vertical basis', you write it in terms of the basis you want to measure in, and square the amplitudes of each components to get the probabilities.What is the probability of the measurement zero?what is the probability of measurement outcome "1"
Steps
Rewrite in the form of linear combinationWe then want to square the complex exponential termGiven , apply this to our exponential:What you could have also recognized, is that any complex exponential form is just a complex vector with length 1. That just means that it's complex magnitude is also 1!<br><a data-href="Drawing 2024-02-15 16.02.02.excalidraw" href="supplemental-files/images/excalidraw/drawing-2024-02-15-16.02.02.excalidraw.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Drawing 2024-02-15 16.02.02.excalidraw</a><a data-href="Drawing 2024-02-15 16.02.02.excalidraw" href="supplemental-files/images/excalidraw/drawing-2024-02-15-16.02.02.excalidraw.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Drawing 2024-02-15 16.02.02.excalidraw</a>We can measure in different bases, for measurements in the basis, use linear sum from before.
For basisComplete Basis measurement.
Prepare and measure <br>
Single State measurements would be done using an inner product (<a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Bra-Ket Notation</a><a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Bra-Ket Notation</a>) between the basis and the quantum state
*For Example, if , then the measurement of on the H basis is Where N is the number of bases in the quantum system. This is simply the generalization from earlier.The more we measure out of the quantum system, the more we destroy it.
Demolition Measurement- Game over, photon Absorbed i.e Complete basis measurement
Example: BB84 Eve, if Eve measures a quantum state, Alice's original is destroyed, and Eve just has to guess what Alice originally had to pass it along
Non Demolition Measurement- State collapses to the measured state.
We can physically rotate the polarizing beam splitter to go from H/V basis to D/A. But that's really annoying, hard to do mechanically or reliably.Instead, we can use a Hadamard gate! It's a unitary, so the vector length isn't changing.<br>
<img alt="Pasted image 20240215162018.png" src="supplemental-files/images/pasted-image-20240215162018.png" target="_self" style="width: 200px; max-width: 100%;"><br>
<a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Orthonormal Bases</a><a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Orthonormal Bases</a> Basis: It's just a set of ways to measure to uniquely determine the state.
Changing measurement basis is literally just redefining your axis, moving the axis but leaving the points on it just change how you describe the points. They haven't moved.
Math of the above!
Then when we apply our logic of applying gates, the Hadamard just gives us a change of basis!Given , what matrix can we use to map it to ?
We'd want a gate such thatDoing this let's us make the amplitudes of horizontal the amplitude of one target basis, and the amplitude of vertical the amplitude of another target basis.Given an orthonormal Basis We can form a unitary matrix U=
Then performing a measurement is just <br>Given that and are <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvectors</a> of A (or <a data-tooltip-position="top" aria-label="../Definitions/Orthonormal Bases" data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Orthonormal Bases</a><a data-tooltip-position="top" aria-label="../Definitions/Orthonormal Bases" data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Orthonormal Bases</a>), then we can write A as a projection sum<br><img alt="Pasted image 20240215164148.png" src="supplemental-files/images/pasted-image-20240215164148.png" target="_self">Perform the first 3 steps of the measurement protocol from the previous section for the following observables. We have the standard wave function summation X,Y,Z<br>
<img alt="Pasted image 20240215164742.png" src="supplemental-files/images/pasted-image-20240215164742.png" target="_self" style="width: 200px; max-width: 100%;"><br>
NOTE:it's given what the <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvectors</a> for these matrices areE]]></description><link>school/physics/quantum-computing/semester-1/2.4-quantum-observables.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/2.4 Quantum Observables.md</guid><pubDate>Thu, 15 Feb 2024 06:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.9 Creation and Annihilation Operators]]></title><description><![CDATA[Midterm March 5thWrapped up what we did in <a data-href="1.8 Rotation" href="school/physics/quantum-3/notes/1.8-rotation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Rotation</a><a data-href="1.8 Rotation" href="school/physics/quantum-3/notes/1.8-rotation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.8 Rotation</a>, and then introduced creation and annihilation operators! Also seen in my notes as <a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/1.10 Harmonic Oscillation > ^dbc3f4" data-href="../../Quantum 1/Notes/1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">raising and lowering operators</a><a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/1.10 Harmonic Oscillation > ^dbc3f4" data-href="../../Quantum 1/Notes/1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">raising and lowering operators</a>.Definition 1.1.1 (Group (Algebra)).
A non-empty set along with a binary operation (symbolically for us ) (taking two elements from the set in and returning another element in the set)
A group has the following properties : Identity A singular and unique element s.t Every element has an inverse: where . Associativity , Closure : Abelian: ommutativity is not guaranteed! Rotations in 2DThe group of matrices which describes rotation matrices is .
It is the orthogonal group It's special if . All matrices in it satisfy . <br>By this definition <a data-href="../../Quantum Computing/Semester 1/2.4 Quantum Observables#^500f42" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#^500f42" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/2.4 Quantum Observables &gt; ^500f42</a><a data-href="../../Quantum Computing/Semester 1/2.4 Quantum Observables#^500f42" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#^500f42" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.4.1 (The Unitary Matrix)</a> would be Definition 1.9.1 (Unitary Representation o f).
We can represent our rotation matrix as a complex exponential with the single parameter as Can we apply the same definition of special to ?
There's no matrix to get a determinant of so he doesn't think so
What about ? Well we describe it with !
If we have 3 dimensions, our rotations are no longer Abelian!
Can we find a representation of our 3D rotations ? The answer is always yes!
How can we enforce the unitary condition?<br>
<a data-href="../../Misc/The Haar Measure#^2aa6d0" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^2aa6d0</a><a data-href="../../Misc/The Haar Measure#^2aa6d0" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3 (Unitary Group )</a> Our way of constructing the Unitary Matrix would be as an exponential where . Then we expandUnitary means . This is unitary if It seems like we packed an extra dimension into the complex number bit.<br>It kind of seems like we packed the extra dimension from into the scalar for . Can I keep doing that? Like is there a <a data-tooltip-position="top" aria-label="https://math.stackexchange.com/a/1784171" rel="noopener nofollow" class="external-link is-unresolved" href="https://math.stackexchange.com/a/1784171" target="_self">triternion</a> which puts another dimension into my scalar so that I can represent this entire algebra with a scalar?<br>
"The group SU(2) is <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Isomorphic" rel="noopener nofollow" class="external-link is-unresolved" title="Isomorphic" href="https://en.wikipedia.org/wiki/Isomorphic" target="_self">isomorphic</a> to the group of <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Quaternion" rel="noopener nofollow" class="external-link is-unresolved" title="Quaternion" href="https://en.wikipedia.org/wiki/Quaternion" target="_self">quaternions</a> of <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Quaternion#Conjugation,_the_norm,_and_reciprocal" rel="noopener nofollow" class="external-link is-unresolved" title="Quaternion" href="https://en.wikipedia.org/wiki/Quaternion#Conjugation,_the_norm,_and_reciprocal" target="_self">norm</a> 1, and is thus <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Diffeomorphic" rel="noopener nofollow" class="external-link is-unresolved" title="Diffeomorphic" href="https://en.wikipedia.org/wiki/Diffeomorphic" target="_self">diffeomorphic</a> to the <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/3-sphere" rel="noopener nofollow" class="external-link is-unresolved" title="3-sphere" href="https://en.wikipedia.org/wiki/3-sphere" target="_self">3-sphere</a>." at <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Special_unitary_group#The_group_SU(2)" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Special_unitary_group#The_group_SU(2)" target="_self">wiki</a> In NRQM we have observables which are operators
We have commutation relationships for non-classical behavior
Particles are permanent
QFT on the other hand is not magic. We're going to change our thinking to ask "how many particles are in a given state"Definition 1.9.2 (Fock Space).
A fock space describes a more general structure formed by Hilbert spaces, allowing us to create and destroy given particles. Each state is represented by values teling us how many particles exist in a space
Example 1.9.3 (Particle confined to a ring). My particle is a discrete momentum state where . We then use the de Broglie relation to find the momentum is .
The hilbert space describes the possible momentum of a given particle , and can tell the possible states of a particle in a system of several particles via the superposition property.
The system of many particles, I have slot for every Where particles have momentum , as and at . [!question]+ So can the values in those kets only be real because we're just using them for counting can they only be integers?
YEP! YIPPEEEEE. I f.w fock spaces
<br> But what happens if one of my particles is in a <a href=".?query=tag:superposition" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#superposition">#superposition</a> between two states? Like half the amplitude is in one of the states and half the amplitude is in the other.
if that happens with a superposition, we can switch the basis to be something which uses the superposition as a basis, or measuring another quantum property. When we're counting, it's the number of physical particles regardless of their quantum state. In QFT entanglement can be good for everything.
If we start with a vacuum stateWe'd like to create some new particle in some state : To create a particle in state we will make an operator labelled to act on the operator describing the system to create our particleThe vacuums state is the lowest, so we can't lower through the floor without murdering that amplitude. Definition 1.9.4 (Number Operator). gives our original state times a constant! Exercise 1.9.5 (Find the value of ).
Try . if why does it matter if is different? if ]]></description><link>school/physics/quantum-3/notes/1.9-creation-and-annihilation-operators.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.9 Creation and Annihilation Operators.md</guid><pubDate>Thu, 12 Feb 2026 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.15 Bell's Inequality]]></title><description><![CDATA[is the antidiagonal state and diagonal analogous to bosons and fermions?If there is one thing that distinguishes people who are qualified to give colloquia is that they think high of themselves. Clauser set the bar, that man's ego filled the room]]></description><link>school/physics/quantum-2/notes/2.15-bell's-inequality.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.15 Bell's Inequality.md</guid><pubDate>Fri, 11 Apr 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.7]]></title><description><![CDATA[How do deal with memory leaks once we have deleted threads when it comes to freeing things up. With the above diagram, mov $100, %fs-32 will. But we wanna know how big the thread local area isThe tls has a label __tls_start at the beginning, and __tls.end at the end hello. All we need to do is take the difference o f the start and the end and we get the size of the tls.
That's thanks to our PC pointing there
Because this is always aligned, we can think of it as an array of longs and just iterate over it. There might be a memcopy in machine.s. He'll share one with us
1extern uint64 __tls.start__;2extern uint64 __tls.end__;
The loader script file will define this for us, so by the time we get to the program this is resolved.
The thing is that tlw doesn't really contain the beginning of that place, it is the beginning of that place. C will give us the 8 bytes back, but we want the address of it, so we need to use the %. Subtraction to get the size will give us the number of uint64 between them, not the number of bytes between themFreeing the tls has no given test which tests for it, but we can in our testcase do things which test for that. ]]></description><link>school/cs/cs-439/notes/1.7.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.7.md</guid><pubDate>Thu, 05 Feb 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[5.3 Degenerate Fermi Gasses, Blackbody Radiation]]></title><description><![CDATA[The pauli exclusion principle is what makes it hard to compress a metal. This is the degeneracy pressure.
Why doesn't all matter just collapse? All the forces we know create attractive interactions. The degeneracy pressure is why I don't fall into the EarthThen with blackbody radiation, we solve the ultraviolet catastropheIf the UV catastrophe assumes all degrees of freedom have <a data-tooltip-position="top" aria-label="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses > ^e0a880" data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses#^e0a880" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^e0a880" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">equipartition</a><a data-tooltip-position="top" aria-label="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses > ^e0a880" data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses#^e0a880" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^e0a880" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">equipartition</a> proportional energies, then why is it not uniform in that prediction? Isn't it dubbed as such because we go to infinity?
It's because the number of accessible states that we can exist in goes up with higher frequencies. But if you constrained to one dimension, it would be uniform and still infinite, because the rectangle's width is infinite
We can then bring this back to the CMB! ]]></description><link>school/physics/statistical-mechanics/notes/5.3-degenerate-fermi-gasses,-blackbody-radiation.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/5.3 Degenerate Fermi Gasses, Blackbody Radiation.md</guid><pubDate>Mon, 08 Dec 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[5.1 Quantum Statistics]]></title><description><![CDATA[6 zombie questions on the final, it would be worthwhile to make the cheatsheet just every single possible question and it's solution?
Email Loveridge asking about exam solutions for exams 1 &amp; 2
1 cheatsheet to use
The grand canonical ensemble assumes particles can move between along with heat
<a data-tooltip-position="top" aria-label="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble" data-href="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble" href="school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Canonical Ensemble</a><a data-tooltip-position="top" aria-label="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble" data-href="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble" href="school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.6 Canonical Ensemble</a>Definition 5.1.1 (Gibbs factor).
The relative probability that a particle is in a possible state, given that particles are also allowed to move in groups to a state Definition 5.1.2 (The Grand Partition Function). The combination of these two gives us the probability distribution of being in a certain state asWhat's the name of the partition function if energy, volume, and particle to change
Because energy and particle are grand, just energy is cannonical
Adsorption means particles get added to the surface of a material (absorption means we are added to the volume of it)
1kT
Theorem ( Boltzman Factor - The probability of a subsystem at a given probability). ]]></description><link>school/physics/statistical-mechanics/notes/5.1-quantum-statistics.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/5.1 Quantum Statistics.md</guid><pubDate>Wed, 03 Dec 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.8 Average Vaue]]></title><description><![CDATA[<a data-href="../../Quantum Computing/Semester 1/3.3 Density Matrices#^150ee1" href="school/physics/quantum-computing/semester-1/3.3-density-matrices.html#^150ee1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/3.3 Density Matrices &gt; ^150ee1</a><a data-href="../../Quantum Computing/Semester 1/3.3 Density Matrices#^150ee1" href="school/physics/quantum-computing/semester-1/3.3-density-matrices.html#^150ee1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Expectation Value of Density Matrix)</a><br>
<a data-href="../../Quantum Computing/Semester 1/2.5 Calculating Observables#^fb01a4" href="school/physics/quantum-computing/semester-1/2.5-calculating-observables.html#^fb01a4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/2.5 Calculating Observables &gt; ^fb01a4</a><a data-href="../../Quantum Computing/Semester 1/2.5 Calculating Observables#^fb01a4" href="school/physics/quantum-computing/semester-1/2.5-calculating-observables.html#^fb01a4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.5.2 (Expected Value)</a> Definition 4.6.1 (Thermodynamic Identity). Exercise 4.8.1 (AT HOME: Calculate the efficiency of this cycle). <br><a data-href="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble" href="school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble</a><a data-href="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble" href="school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble</a>
There are probability distributions which are normalized, but who have moments which go to 1. Those are distributions where the CLT fails.
The spectral lines of an atom (as described by the heisenburg), doesn't have finite moments. Hiding underneath the spectra lines distribution, is a distribution with infinite moments. It's described better by a generalization of CLT as opposed to teh CLT itself. THATS WILD???]]></description><link>school/physics/statistical-mechanics/notes/4.8-average-vaue.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.8 Average Vaue.md</guid><pubDate>Wed, 12 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.7 Boltzman statistics]]></title><description><![CDATA[The partition function for the hydrogen atom isThe resolution to the paradox is that at the higher and higher energy states, those energy states occupy larger and larger volumes. We know from the Bohr model that the radii go by . A hydrogen atom in a box is constrained because the maximum volume is the box. The size of the orbitals become the size of the box.Wouldn't that still mean that our probability of being in the ground state is proportional to the volume of the box?
The idea is that we just can't calculate the partition function for large value of . The relative likelihood is still completely valid though. Theorem ( Boltzman Factor - The probability of a subsystem at a given probability). The Boltzmann distribution is the distribution which maximizes the information entropy subject to the constraint that the average value of the energy is fixedCan I get a distribution similar to boltzman in a different kind of entropy
We should think of entropy and the other entropies as a measure of how mixed up a distribution is. There's a mathematically precise way of formulating that notion. There's a notion of "more mixed" or "less mixed" states, which you can order based on how mixed they are. You're trying to find the "most mixed" state. Any function which reflects how mixed the state is, will yield the same answer. This is called "Majoriziation"
Changing the entropy won't yield another distribution, changing the constraints will ]]></description><link>school/physics/statistical-mechanics/notes/4.7-boltzman-statistics.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.7 Boltzman statistics.md</guid><pubDate>Mon, 10 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.6 Boltzman Weighting]]></title><description><![CDATA[Theorem ( Boltzman Factor - The probability of a subsystem at a given probability). We're talking about cases where possible states occur at different probabilities
last time we talked about how we have phase transitions occur in thermodynamic systems
\This is showing us that a mixture of liquid and gas has a higher entropy than a pure state. It's not thermodynamically favorable to be like viscous water, How do we find the analogous pairs of quantities to map our phase diagram system to? Black holes have charge and electric potential, gasses have pressure and volume
Ask what are all of the attributes which determine the energy of the system?Identify any variable that has an effect on the energy . One entity in the pair will be that (charge in a black hole effects it's mass energy). The second quantity would be the derivative of energy with respect to that quantity . Then the paired quantities with the derivatives.
Definition 4.6.1 (Thermodynamic Identity). What are those pieces of information in quantum information? What is the "thermodynamic identity"?Ask aaronson about quantum information and statistics
Is ther]]></description><link>school/physics/statistical-mechanics/notes/4.6-boltzman-weighting.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.6 Boltzman Weighting.md</guid><pubDate>Fri, 07 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.2 Entropy]]></title><description><![CDATA[<img src="supplemental-files/images/pasted-image-20251001114144.png" target="_self">At equilibrium, temperature is defined as<br><img src="supplemental-files/images/pasted-image-20251001112216.png" target="_self">
Above is a graph of our energy change as a function of the energy in A. Notice that when in conjunction with , there is a local maxima which maximizes entropy. When we have two systems and compute a system with a. certain amount of energy but also a volume, we can compute the number of micro-states which satisfy that much entropy and energy. We'd calculate the entropy as a function of energy. For a system we'd typically have . When we have a non-isolated system we can then use it! We know that <br>This can then be plugged into <a data-href="#^10fd7b" href="#^10fd7b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^10fd7b</a><a data-href="#^10fd7b" href="#^10fd7b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.2)</a> if we wanted to calculate the energy of the total system <br>This relates us to the equipartition principle! If we have a relation , <a data-href="#^663937" href="#^663937" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^663937</a><a data-href="#^663937" href="#^663937" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.1)</a>, and then the
Sackur–Tetrode equation Definition 2.2.1 (Sackur–Tetrode Equation).
This equation defines the energy associated in an ideal gas <br>Proof of <a data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses#^e0a880" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^e0a880" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses &gt; ^e0a880</a><a data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses#^e0a880" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^e0a880" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.3.7 (Equipartition Principle)</a>. □
Note that the above proof is only one case, but we've never proved it formally and we finally did!<br>
To be able to tell whether there is no runaway entropy effect when two systems of different monetary preferences (from first graph) interact, you just use <a data-href="#^10fd7b" href="#^10fd7b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^10fd7b</a><a data-href="#^10fd7b" href="#^10fd7b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.2)</a> with the second derivative test.]]></description><link>school/physics/statistical-mechanics/notes/2.2-entropy.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/2.2 Entropy.md</guid><pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.8 Entropy]]></title><description><![CDATA[
Some measure of the number of micro-states
The measure of disorder The loss of usable free energy The enthalpy is thenThe change in enthalpy is equal to the heat if pressure is equivalent to heatChanges in enthalpy will tell us about heat exchange
We want to compute the amount of work . 298K and 1 atm
To compute the work done on the system, we know
We're approximating that the final volume of condensed water is approx. 0 at room temp
We can get the volume from via the <a data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses#^540949" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^540949" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses &gt; ^540949</a><a data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses#^540949" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^540949" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses &gt; ^540949</a> <br>Continuing from <a data-href="#^42361b" href="#^42361b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^42361b</a><a data-href="#^42361b" href="#^42361b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^42361b</a> adding in <a data-href="#^60942d" href="#^60942d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^60942d</a><a data-href="#^60942d" href="#^60942d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.6)</a> <br>In <a data-href="#^1e3a73" href="#^1e3a73" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^1e3a73</a><a data-href="#^1e3a73" href="#^1e3a73" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.5)</a>, we're making an assumption on it being quasistatic.<a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=orPaIjFa7LQ" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.youtube.com/watch?v=orPaIjFa7LQ" target="_self"> But remember in The Martian, it blew up!</a><br>
There's a super cool connection between entropy and <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Huffman_coding" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Huffman_coding" target="_self">huffman encoding</a>
Multiplicity is the number of micro-states belonging to a macro-stateThe multiplicity of a given state would then be the probability asThermodynamically, a two state system gives a good description of a paramagnet]]></description><link>school/physics/statistical-mechanics/notes/1.8-entropy.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.8 Entropy.md</guid><pubDate>Fri, 12 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.3 Ideal Gas Law]]></title><description><![CDATA[This is a lot like <a class="original-internal-link" data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses.md" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html" target="_self" rel="noopener nofollow" style="display: none;">1.3 Kinetic Theory of Ideal Gasses</a><a class="internal-link mathLink-internal-link" data-href="../../QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses.md" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html" target="_self" rel="noopener nofollow">1.3 Kinetic Theory of Ideal Gasses</a>Do you want someone to distract u/cheer you up
Do you want it active or articles to read or
active
can it be over text or should it be here
either is good<br>
<img src="supplemental-files/images/pasted-image-20250829111548.png" target="_self">If we increase the temperature by 1˚, you get an increase in the height of . We want to know the radius of the thermometer. given . We're told that is approximately constant over this range.
Solving this is just a matter of plugging into the volume of a cylinder]]></description><link>school/physics/statistical-mechanics/notes/1.3-ideal-gas-law.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.3 Ideal Gas Law.md</guid><pubDate>Fri, 29 Aug 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.4 Classical Correcting Codes]]></title><description><![CDATA[Today we discussed more of the original theory designed for classical correcting codes, namely for linear codes. We talked about messages, encoded messages, the set of correctable errors, and the logical errors Messages encoded messagfes set of correctable errors logical error
What makes a good code?
For now we're saying it's the code distance! the code distance is high and so is the encoding rate
We map into registers registers, or independent components.
Ex is how many bits (all values in registers are )
Then for what happens? He'll tell us later but we might not get to it
Every message is a direct product of . or in our case We're restricting to to finite weight errors. and that acrt on components of the message
The errors can only act locally on our registers!
The weight of the error is how many local errors there are. In the repetition code, with , the weight of is 2!
This model works well even with non-local errors thanks to approximations when for BEC
When BSC when is small! A good error rate would be The likely hood of each event happening over our channel goes down for the behavior of our error channel! The larger that the weight that the error is getting, the less likely it is to happen. This might mean I have a faulty error model? I'm assuming all qubits get errors but not the case where it's random they do
This comes from the binomial distribution <a data-href="../../QIS/Modern Physics/Notes/1.1 Fundamentals of Probability#^d3af67" href="school/physics/qis/modern-physics/notes/1.1-fundamentals-of-probability.html#^d3af67" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Modern Physics/Notes/1.1 Fundamentals of Probability &gt; ^d3af67</a><a data-href="../../QIS/Modern Physics/Notes/1.1 Fundamentals of Probability#^d3af67" href="school/physics/qis/modern-physics/notes/1.1-fundamentals-of-probability.html#^d3af67" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.1.6 (Binomial Distribution)</a> If we can create codes which can correct up to errors, then we're claiming that we can correct any errors. That's because everything above is exponentially down in probability so we're throwing it out. Definition 1.4.1 (Distance (Error Correction)). where then the distance is How large of an error does it take to get from one codeword to the other, and take the smallest of those distances The computational complexity of our code has the easiest algo to find of Ideally we want our codewords to be very dense in a small space, so the trivial direct looped comparison for the codewords is pretty shit. For classical settings you can get it in via the representation of the matrix. For quantum codes, people have to put bounds on these things probabilistically.
"Easy for Classical, Hard for Quantum".Described by 3 params, is the number of radix registers is 2^ the number of codewords is the distance of the code
Wait does this uniquely describe all codes?
No there are many codes which have the same parameters but are different codes. Might be true classically but def not quantumly
We also care about the rate of a code, which is also large. (). between that and the distance those are our "goodness" measuresA classical code of distance can
Correct errors Our decoder can always correct within that radius Correct erasures This is why we like to convert to erasure problems because the code becomes twice as powerful Detect errors on components We can go twice as far and know that we're not on a codeword Encode messages with blocks of bitsWith possible messages, components of vector space Encode messages into codewords ("words") where these are elements of a vector space
The question is now how to map from the two sets. Promised . We're turning these into vectors, and something that pads me into .
The dumbest encoding is just to not use the additional bits to do anything.
Our additional bits are called our parity check bitsEach of the must obey linearly independent checks.
These define our parity check vectors which just collect our parity bitsWhich has a defined constraint of that . The inner product between each parity bit and the codeword has to be zero.
Combine to get parity check matrixAs an example, = 111, , the dot product (remember mod 2) is zero!<br>
The <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/4.5 The Dimension of a Vector Space > ^1ebfab" data-href="../../../Math/Linear Algebra/4.5 The Dimension of a Vector Space#^1ebfab" href="school/math/linear-algebra/4.5-the-dimension-of-a-vector-space.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">rank</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/4.5 The Dimension of a Vector Space > ^1ebfab" data-href="../../../Math/Linear Algebra/4.5 The Dimension of a Vector Space#^1ebfab" href="school/math/linear-algebra/4.5-the-dimension-of-a-vector-space.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">rank</a> of this matrix is just A linear code with parity checks. consists of the vectors such that is a subspace of Additive closure so ; \
Multiplicative closure: , , What this tells us is that is always a codeword! Because of that, the parity of a codeword becomes our distance to zero!
The dimension of the code space, . This gives us the number of basis vectors (). There are many potential codewords, but we only need a linear number of basis vectors to get them all!
If we can find the basis, we can construct the generator matrix. It's a matrix with Example 1.4.2 (Repetition Code).
If you want to communicate a message then you repeat it .
With 3 repetitions, , [!bug] Notice that addition in this matrix multiplication is a cartesian product
Our repetition code is then represented as Example 1.4.3 (Conncattenated Repetition). it's generator would be i should stop answering questions i get confused and then want to jump off the pma
Remember that each of these vectors has a dot product equal to zero
]]></description><link>school/physics/quantum-error-correction/notes/1.4-classical-correcting-codes.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/1.4 Classical Correcting Codes.md</guid><pubDate>Sat, 31 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.16 Exam Review]]></title><description><![CDATA[ is the total spin, and then is the total orbital angular momentum of the atoms. The total values of The big is gotten from summing over all the spins
remember that this is a vector summation, so the directions are relevant. When you have a filled shell, all spins add to zero. If we want to have a larger net spin, then you need different s. The rules for is that it's bounded betweenFinding the values of are important because won't change but has to change by 1.
The einstien A coefficient
dThe Einstien A coefficient determines the number of particles between moving to If it's a large number the particles decay fast, if it's a small number then the transition might be forbidden. We know , and We can interpret this to see if our selection rules are permitting the transition or forbidding it
You can also have a stimulated emission, which takes us from to . That depends on the number of photons exciting the state. For more information see <a data-href="1.17 Transitions in the Atom#^4f0623" href="school/physics/quantum-2/notes/1.17-transitions-in-the-atom.html#^4f0623" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.17 Transitions in the Atom &gt; ^4f0623</a><a data-href="1.17 Transitions in the Atom#^4f0623" href="school/physics/quantum-2/notes/1.17-transitions-in-the-atom.html#^4f0623" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.17.6)</a> is the frequency of the photon which excites the state
Ground state is the one which has no nodeslibration HCL : An angular vibration]]></description><link>school/physics/quantum-2/notes/2.16-exam-review.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.16 Exam Review.md</guid><pubDate>Mon, 14 Apr 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.17 Transitions in the Atom]]></title><description><![CDATA[We did things and stuff and sleepExam content is everything up till today.Electrical forces are so much stronger than magnetic forces, that most things end up being electrically neutral. Now we're introducing a time dependance to the electric fieldFor a perturbing electric fieldOur selection rules then come from the angular parts. It would save us a lot of time if we knew what is <a data-href="#^46f770" href="#^46f770" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^46f770</a><a data-href="#^46f770" href="#^46f770" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.17.2)</a> nonzero.We know the dipole vector goes by the below components after analysisWith components asThis results in our selection rules to know which transitions are allowed.If we're at a state , if we ignore spin orbit coupling then the levels are degenerate so it won't move across it's levelNotice that the 2 state is a forbidden transition. It can also emit two photons! In the electric dipole transition process the transition is forbidden.If the transition is forbidden, how does it decay at all?
Well there are other processes which would trigger a transition, like an electric quadrupole process
Equilibrium is now between matter AND radiationEinstein imagined that particles were oscillating between the two energy states from top to down, but also they could absorb energy and move to a higher state! is spontaneous emission, the rate we fall from high to low.quantum mechanics then shows us that there is a probability of going from via a radiation field who's intensity if (how bright is it). - is the probability we move up through quantum effects
You can interpret the similar to the that we already know about. It's just the expectation value between the states
Our first term can get arbitrarily large if is large uncontrollably, which is how we get our subsequent term. We can't have more particles at state than state since that's not energy equilibrium.
There had to be a process where using driving radiation to move up, there had to be a process which drove the energy level back down. This was .
This contribution is what made lasers possible!At equilibrium we can solve for to get<br>From statistical mechanics we then know below via <a data-href="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble#^540daa" href="school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html#^540daa" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble &gt; ^540daa</a><a data-href="../../QIS/Modern Physics/Notes/1.6 Canonical Ensemble#^540daa" href="school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html#^540daa" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.6.1 (Boltzman Factor - The probability of a subsystem at a given probability)</a> <br>We see that stimulated absorption and stimulated emission have to be equal! Additionally by matching up terms between <a data-href="#^67206a" href="#^67206a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^67206a</a><a data-href="#^67206a" href="#^67206a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.17.7)</a> and <a data-href="#^0aa942" href="#^0aa942" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^0aa942</a><a data-href="#^0aa942" href="#^0aa942" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.17.9)</a> we get: is a rate coefficient, so is the lifetime of the excited state. To do that we then just need the expectation of the angular moment between the two states .Just knowing the wave-functions of a hydrogen atom, we can calculate the lifetimes of an excited state!The correct interpretation of the spontaneous emission, is that it's stimulated by the vacuum.]]></description><link>school/physics/quantum-2/notes/1.17-transitions-in-the-atom.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.17 Transitions in the Atom.md</guid><pubDate>Mon, 24 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/xDyB4KAU7Y6qc.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/xDyB4KAU7Y6qc.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.5 The Coin Problem and Cloning]]></title><description><![CDATA[Notes discussing performing statistical tests with quantum computers, quantum cloning, and the utilities of <a data-href="#^eaca57" href="#^eaca57" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^eaca57</a><a data-href="#^eaca57" href="#^eaca57" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.5.1 (No Cloning Theorem)</a>. There are things in real life we don't want copied, like SSN's.Given a coin, our job is to find if it's a fair coin or biasedIn stats, we'd just flip the coin a crap ton, and then use a confidence test on the mean to know if we're within valid range.How many times do we need to flip the coin to determine the value of to some confidence?But how much memory do we need?
Need to remember the number of flips, the number of heads-tails
Naive strategy is writing out the whole string of information, which takes bits.
If we just store the two integers of number of runs, and number of tails, it's . This is just because we're representing information in base 2. To represent in base 2, the number of bits is the natural log.
What if we instead built a FSM, where one heads moves right, tails goes left, and halts at a bound. If it's fair, then we should land on heads and tails at the boundary equally. If it's even slightly skewed, it would bias the halting far more.
Hellman-Cover 1970 proved this is optimal
Can we find a way to record the information in a single qubit?
The qubit becomes an analog counter. Repeat N = times Does this not smuggle in a counter to keep track&gt; It does! But how do we avoid this? See step 3! If coin lands apply to the qubit (rotate the qubit counter clockwise) If tails, apply To avoid smuggling in more memory to count where we are, each step has probability of halting that is .<br>
If the coin is fair, we expect the coin to end up at , as this is just a <a data-tooltip-position="top" aria-label="../Modern Physics/Notes/1.2 Random Walks > ^bad78a" data-href="../Modern Physics/Notes/1.2 Random Walks#^bad78a" href="school/physics/qis/modern-physics/notes/1.2-random-walks.html#^bad78a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">unbiased random walk</a><a data-tooltip-position="top" aria-label="../Modern Physics/Notes/1.2 Random Walks > ^bad78a" data-href="../Modern Physics/Notes/1.2 Random Walks#^bad78a" href="school/physics/qis/modern-physics/notes/1.2-random-walks.html#^bad78a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">unbiased random walk</a> <br>Basically we still have a finite state machine, but the extra memory of what position you're in is held in the universe, over your actual bit. More interestingly, this won't tell you how you're biased. If you get a measurement, it's totally possible that you had a negative amplitude. This is just like <a data-href="../../Quantum Computing/Semester 2/0.1 Introduction#^850aad" href="school/physics/quantum-computing/semester-2/0.1-introduction.html#^850aad" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 2/0.1 Introduction &gt; ^850aad</a><a data-href="../../Quantum Computing/Semester 2/0.1 Introduction#^850aad" href="school/physics/quantum-computing/semester-2/0.1-introduction.html#^850aad" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 0.1.2 (Deutsch’s Algorithm)</a> Why is this only using one qubit? Don't you need several runs to get a confidence interval?
The idea is that is the number where the tail ends of the normal distributions are far enough apart, that one measurement has the confidence baked in.
Theorem 1.5.1 (No Cloning Theorem).
Given a qubit , there is no operator which will produce two copies of the state. The above is impossible. We can't apply an operator to any qubit system to duplicate a state Given two vectors In our copying case below, this means our expected value is then For the same unitary and vectors, the transformation can't change the inner product. Unless unless . Nothing in quantum-mechanics increases inner-productsIf given and you KNOW , nothing stops you from cloning. You can just find some one-qubit unitary and make a factory.
What it does say, is that if you don't know this you can't make the double.This literally makes us a bell-state, which means a measurement of one qubit is a measurement of another. Invented by Steven Wiesner, who was the son of JFK's science advisor. Br. wrote a paper on this, submitted it and they rejected it. Instead of coping and rewriting, the guy LEFT PHYSICS became a manual laborer, and waited till 1983.His idea was, if quantum states really have this one-off measurement, there are two points of view. It sucks, we're limited in our view of the world
IRL there are a bunch of things that we don't want to be copied, LIKE CASH. SOCIAL SECURITY NUMBERS.
Blochchain mentioned, maximum buzzword tolerance reachedDefinition 1.5.2 (Wiesner's Quantum Money).
Each bill has a standard serial number which is any number of bits.<br>
The bank has a secret mapping from these public serials to bits. The states then encode the hidden strings . In order to tell if the bill is genuine, you have to bring that bill to the bank, and they will need to measure your bill, which destroys the money. This is literally <a class="original-internal-link" data-href="../../Quantum Computing/Semester 1/1.2 Quantum Key Distribution.md" href="school/physics/quantum-computing/semester-1/1.2-quantum-key-distribution.html" target="_self" rel="noopener nofollow" style="display: none;">BB84</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum Computing/Semester 1/1.2 Quantum Key Distribution.md" href="school/physics/quantum-computing/semester-1/1.2-quantum-key-distribution.html" target="_self" rel="noopener nofollow">BB84</a>, but asymmetric instead of symmetric. ]]></description><link>school/physics/qis/notes/1.5-the-coin-problem-and-cloning.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.5 The Coin Problem and Cloning.md</guid><pubDate>Thu, 12 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.7]]></title><description><![CDATA[Today we're doing a QM overviewSuccessful RQM accepts spin
Works with our particle's spin and with momentum and as wave-functions
We define spin up as spinning counterclockwise. "Spin" is an intrinsic property of an electron like mass.
<a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/1.2 Stern Gerlach and Dirac Notation cont." data-href="../../Quantum 1/Notes/1.2 Stern Gerlach and Dirac Notation cont." href="school/physics/quantum-1/notes/1.2-stern-gerlach-and-dirac-notation-cont..html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.2 Stern Gerlach and Dirac Notation cont.</a><a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/1.2 Stern Gerlach and Dirac Notation cont." data-href="../../Quantum 1/Notes/1.2 Stern Gerlach and Dirac Notation cont." href="school/physics/quantum-1/notes/1.2-stern-gerlach-and-dirac-notation-cont..html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.2 Stern Gerlach and Dirac Notation cont.</a> experiments are classic ones which show us that spin is quantized along the axis of measurement with I didn't take as many notes from today as it was a lot of review! Introduce density matrices firstWe were talking about this in class and I know about it for QIS so I'm sketching out how to explain it
then entanglement stuff with tensoringNow let's say (and for now ill skip the setup that does this) I make the two qubits interact with each other in a way which forms this stateThe density matrix isMy question for you, is does there exist any basis where I can just measure and always get one outcome. Not a 50-50 shot.
You'll find the answer is know, it's always 50-50! That means on it's own seems to obey a classical probability distribution<br>Proof of <a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a>.
Let's move forward in time from ^784f42
Then we wanna evaluate this
Definition 1.6.2 (Schrödinger Equation). Also written as The only condition you need to solve this equation, is Where is a Unitary, is the identity, and is the hamiltonian of the Hamiltonian Evaluate . First write out what is.<br>Then plugging it back in to <a data-href="#^784f42" href="#^784f42" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^784f42</a><a data-href="#^784f42" href="#^784f42" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^784f42</a> □
Wait nonlinear QM doesn't have global phase invariance... it needs to be homogenous.]]></description><link>school/physics/quantum-3/notes/1.7.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.7.md</guid><pubDate>Thu, 05 Feb 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 Stern Gerlach and Dirac Notation cont.]]></title><description><![CDATA[More work on mathematically describing the Stern-Gerlach Experiment, now using spin operators!Last time we introduced In the sense that they provide the same quantity of information but with a transformation.
Additionally, we showedFor now, we're only assuming pure states
Given the below eigenvalue problemWe make the following assumptionsDefinition 1.2.1 (Kronecker Delta Function).
The kronecker delta function is defined, by the below statement More specifically, the area over the infinitesimal region at is 1. The kronecker delta function is the derivative of the step function In our current case, the usage of the Kronecker delta is only used because the vectors are either the same , or they are <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces > ^a83314" data-href="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^a83314" href="school/math/linear-algebra/6.3-orthogonal-and-orthonormal-spaces.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">orthogonal</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces > ^a83314" data-href="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^a83314" href="school/math/linear-algebra/6.3-orthogonal-and-orthonormal-spaces.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">orthogonal</a> Definition 3.3.1 (Born Rule for Mixed States).
The measurement outcomes are just a sum of other probabilities. Write out the sum
Then expand by the definition of the magnitude operations on a vector. is constant through the sum, and is a scalar so it is communative. Factor out and put further inside Above is Born's rule, which defines the probability of an event offering in terms of the inner product of an eigenvector with itself.Any vector in the Hilbert space can be written as a linear combination of the basis-vectors.Using the Kronecker delta definition from earlier, we getThere is only one case when , which is , so Below then, is our completeness statementThe sum of all the outer products of the eigenstate of the observables
with themselves, is the identity matrix.
This effectively means that all the eigenvectors of a quantum state, spans a Hilbert space
<br>Theorem 3.3.1 (Pauli Matrices and Density Matrix).
Any pure/mixed state can be written in terms of <a data-tooltip-position="top" aria-label="../Definitions/Pauli Matrices" data-href="../Definitions/Pauli Matrices" href=".html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Pauli Matrices</a><a data-tooltip-position="top" aria-label="../Definitions/Pauli Matrices" data-href="../Definitions/Pauli Matrices" href=".html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Pauli Matrices</a>. This is just like our previous basis Is this at all related? I know that the density matrix is a linear combination of rotations toward identity? is ?
Definition 1.1.1 (Stern-Gerlach Experiment). Assume you have a medium heated up, filled with dipoles. Their magnitude is fixed with heating. The dipoles have magnetic moment and the large dipole has magnitude . . We're also going to make this field modellable as only changing along the Z direction, so Because we're only having a changing field on the direction, the energy is The issue that comes in for , is that the magnitude of can orient in any range of directions classically.
We don't see this, we see two distinct points on the screen instead. on each point. Definition 1.2.2 (Spin). Where is the elementary charge. Spin is measured through angular momentum In reference to how this exists physically
"Why do I do this? None of your business"
Fischler in reference to why he defined spin this way
<br>Proof of <a data-tooltip-position="top" aria-label="^8ac0da" data-href="#^8ac0da" href="#^8ac0da" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">the unit of spin</a><a data-tooltip-position="top" aria-label="^8ac0da" data-href="#^8ac0da" href="#^8ac0da" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">the unit of spin</a>.
How do we get the units of spin for our experiment? In the Stern Gerlach, we only care about the z-component. So we rewrite toFrom our formula of a moving charge in a magnetic field, we can calculate as We then substitute these units into the above expression, to getTherefore, spin has the units of angular momentum
□From the experiment it tells us thatBecause both sides must be identical, has to have angular momentum Theorem 1.2.3 (). Which has units of , Angular momentum has units of Energy*time, so the above means that planks constant measures angular momentum
Imagine we're back at the experiment, and at the beam deflecting up or down, we put an orthogonal magnetic field afterward. We then write asThe state written in the state, is a combination of the states of the observable. But what are the values of Substituting in our expression for to the measured identity, we getWe know that is orthogonal to , so it's inner product is zeroNow we do the same with , to get the same thingWe add the complex component to represent some unknown phase which transformed the vectors.For notation purposes, we're just redefining to throw out the complex phase for The same steps get repeated, in the same fashion for to get us the pair of states. Note that we have to prove the identity later for the phase, since only loops in For notation now, we're going to redefine to include that constant Are still orthogonal if we wrap that phase in?
Yep! See the below diagram Keep in mind that we've rotated in a complex component, but it's still orthogonal. To a vector in multiple spaces, there is a whole plane which is orthogonal. Redefning just rotates it to a new position on that plane for the two outcomes to Stern-Gerlach.<br>
If we repeat the same beam-splitter but with the <a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Quantum Gates" data-href="../../Quantum Computing/Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">$Y$ observable</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Quantum Gates" data-href="../../Quantum Computing/Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow"> observable</a>.This is true due to the completeness of the spaces. If it is an appropriate analogy to compare this to polarized, light, there is. an observable where all of goes one direction, and none the other? What's the observable for this?
I think given the implied orientation of the experiment, it would be the observable, as the charge would move parallel to the magnetic field lines. Because we can represent this as a pure state, we know that there is an observable where it is an eigenvector.
Now the question is, how can we gather more information from this system?How do we find ? Well we know that Still though, how do we find the phases ?
We know that From here, we're going to use the fact that any phasor times it's complex conjugate, should be zeroWhy is a phasor*complexconj = 0?This gives us the phase associated with the observable!From here, we can define <br>Now we're going to redefine to wrap in the main complex phase! This is technically making a new vector, but it's okay because of <a data-tooltip-position="top" aria-label="^385fe5" data-href="#^385fe5" href="#^385fe5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">the answer to our phase question</a><a data-tooltip-position="top" aria-label="^385fe5" data-href="#^385fe5" href="#^385fe5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">the answer to our phase question</a>.How to do the same for ?Exercise 1.2.4 (AT HOME Perform the same process for ).Definition 1.2.5 ( represented in the basis). ]]></description><link>school/physics/quantum-1/notes/1.2-stern-gerlach-and-dirac-notation-cont..html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.2 Stern Gerlach and Dirac Notation cont..md</guid><pubDate>Tue, 03 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.4 Threads]]></title><description><![CDATA[Today we begun to talk about Threads. Threads are purely a software concept constructed by the OS to implement concurrencyA good test case doesn't just tell you that you failed, it gives you instructive information
The report isn't the type of thing you want to do last minute. By answering the questions in the report you can do the assignment betterWhat we have so far is that we have more comprehensive bootstraping, there's a spot in system main which runs global initialization, calls core main to run all the cores.
We got an incomplete heap implementation m but he wants to get to know us
With the heap, we can now use our first abstraction. Ideally our first abstraction is the ability to abstract away from the cores.A thread is a pure software concept. We hear about hardware threads a lot, but we will call the core a unit of parallelism. The threads are units of concurrencyHardware threads -&gt; Things that can run in parallel physically
Software Threads -&gt; Units of concurrencyIn the next assignment, we'll see that kernel_main() will be called by exactly one of the cores. It runs exactly one activity, or exactly one thread.
The other cores are inside an event loop, waiting for something to happen so that they can do it. Once a thread is accessible, they grab it!We're waiting for the one thing running to create a new thread! We need the mechanism to create a second thread
We're gonna add a function which somehow, dispatches a new thread. That means.We want to give a piece of work to another port of software to be forked on.
But how do we tell the thread what to work on? Well we can pass inside a function pointer. 1kernel_main(){2	...3	thread(f)4	...5}6void f(){7	...8	...9}10/But then what is the type of the function pointer?1void thread (void (*p)()){2	...3	...4}We're gonna implement thread together! We need to implement the thread function so that code is handed out to the other cores.
In general whenever we have a data-structure which describes something, we call it a thread control block (TDB). File is file control block FCB. Work...........f()TCB is gonna be a box with p inside of it, some kind of structure. Now we need to find a way to issue it to a core.
The event loop is the code running inside a core which allows it to sit there and look for something.
We will refer to this as the ready-queue. It doesn't have to be a FIFO queue necessarily, but it's always the best way to start.
We call FIFO queue round robin scheduling. If the cores aren't ready, we just put our current item at the end of the list and check the next one up.header ofqueueTCPTCPTCP
The event loop just grabs the next thing in the queue and updates it.
We need to have some way to protect the ready queue with like a spin lock or atomic.
Every time you have a mutable global data structure, you need to think about race conditions.1void thread (void (*p)()){2	...3	tcb = new box{p}4	readyq.add(tbc)5	...6}This function returns really quickly and f runs pretty quickly concurrent to whoever called f. How do we make our functions process inputs and produce outputs?
Oh well invention time
We're going to invent operative threads. They are threads that are well behaved, who don't hog the CPU. Like what if someone had a while loop that never ends? The OS will give a program a millisecond to finish, then if it doesn't it'll move away for some time before coming back
We want to figure out how to implement imstuckinaloop(). We don't want to enter the function from the start, and we want it to be suck that, when we run it, we save the state of the thread in such a way that when someone wants to come back to the work they can start where we left with the state of the variables.
We need to keep track of where we stopped, where the PC was at returning, teh values of all the registers, the local variables values.
We don't need to preserve our local variables. By that point we assert that all threads share global variables
We have to have this as a dynamically sized struct too. Everything we need to save is either in a register, or on a stack. If we can push them all on the stack, all we need to do is preserve the state of the stack!
If you don't want to pass things around or move them around, you can have a dedicated stack for each thread. Each thread will get it's own stack! Then to save your context you just push your registers to your stack. Then the stack pointer for our current stack state gets tossed in the TCB, and the state is preserved.
But like what if the stack gets really big? Like if there's no contiguous block in memory we can use?
Oh dummy the stack grows inward not outward
We're gonna write pieces of the code for this together!
We want to find out if there's some other thread that is ready to run, but is not running. And if such a thing exists, we want to give it a chance to run!Everytime you find yourself observing a data structure and then modifying a state based on that observation, danger. The structure can mutate in between your steps. Read-Modify-Write is DANGEROUS with a shared data structure. You need to worry about race conditionsThe easiest thing is to never really ask if it's empty and then get the element. Get a remove method which locks and somehow both tells us that we can um we can we can um we camnai
tells us if its empty and if not returns something1void yield(){2	auto next = readq.remove();3	//`auto` tells the compiler it can figure 4	//the type from the returned function5	if(next = nullptr): return;6	// what if it's not null? You need to switch to7	auto me = current_thread();8	assert(next!=me);9	//put self in ready queue, mark next one as current thread10	// then the save things11	//readyq.add(me);12	//WE'RE NOT READY YET THOUGH! We need to atomically switch,13	// because tehre's a brief delay where we're still running14	// but in the queue15	//current_thread = next;16	context.switch(...)17	18}X18 in ARM and %fs in x86 are registers we can use as the operating systems, that no on else has access to as a programmer
Throw in as many assertions as you can, its a huge time saver.
We can have a mechanism of the thread after you to add you to the ready queue so that there's no issue with concurrencyHas to be written either in assembly, or using inline assembly. 1global context_switch2context_switch:3	//save callee saved registers into the stackRunI have every right to expect the function will preserve the callee registers, and no right to assume they will save the caller saved registers. We just need to look at the document detailing which registers are which. then we save the stack pointer in the TCB. At this point, we have saved our context. Load stack pointer from other TCB. PLEASE DUDE CLASS ENDED 5 MINUTES AGO
Restore callee saved registers from thread B]]></description><link>school/cs/cs-439/notes/1.4-threads.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.4 Threads.md</guid><pubDate>Thu, 22 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.6 TLS System]]></title><description><![CDATA[In these notes we discussed how to implement Thread Local Storage, which is information inherent to a given thread which it has unique access and information over. That leads to lambdas and thread local variables!
Most of my notes today were done in the projectEvery context swutchi might start from the entry, or right from the middle. if we try to do anything after switching contacts, we have to do it at the beginning if its starting or the end.
switch_context has to be identical in to those in entry, then we do the post.switch() tasks. We do whatever we want after the switch (check for stack overflow, etc)We have to implement thread local storage, but it's considered an advanced feature. None of the testcases use them, but we might do it and then implement a testcase for it.
Global variable int a=10 There is another modifier which lets us keep a variable confined to a given thread. If you put threadlocal, it has infinite lifetime, but there's a unique copy of it for each possible thread in the system. Each thread gets it's own copy of a. Then the threads can use that to store private data.
fsbaseTLSatls grows up
The compiler uses negative offsets from fsbase to get to our tls variables
Every-time we make a thread we need to copy the values from the global variables to the tls areaIf you want to make a thread, you say Thread::create(f). The function needs an environment to run in to give copies of maybe contextual variables or input parameters. A closure is a function+environment. A closure is a pointer to a piece of code, plus some environment (plus a bunch of variables) which need to be available to the function 1Thread::create([ ]{2	//code3	//kprint, SAY, etc4	5})6The advantage of this is that we can also keep the function anonymous
Let's say we want to make the threads in a loop!1for(i=0;i&lt;1e10000;i++){2	Thread::create([i]{3 // this makes a COPY of i4 //code5 //kprint, SAY, etc6 SAY("thread is here?\n",i);7	})8	// can the thread access something in it's environment??9	// the default C++ behaviro is that we have to list everything we're caching in brackets10}11The compiler generates this data structure for us!
Smarter to focus on closures and lambdas over MM stuff. The only problem is that the cpmputer has generated the above structure. It's hard to know what the type of the object is. It forces us to do generic programming (templates in C++)]]></description><link>school/cs/cs-439/notes/1.6-tls-system.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.6 TLS System.md</guid><pubDate>Tue, 03 Feb 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.5 x86-64 Assembly Introduction]]></title><description><![CDATA[<a data-tooltip-position="top" aria-label="../../CS 429/Notes/6.4 Instruction Set Arch" data-href="../../CS 429/Notes/6.4 Instruction Set Arch" href="school/cs/cs-429/notes/6.4-instruction-set-arch.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">6.4 Instruction Set Arch</a><a data-tooltip-position="top" aria-label="../../CS 429/Notes/6.4 Instruction Set Arch" data-href="../../CS 429/Notes/6.4 Instruction Set Arch" href="school/cs/cs-429/notes/6.4-instruction-set-arch.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">6.4 Instruction Set Arch</a><br>
<a data-tooltip-position="top" aria-label="../../CS 429/Notes/6.3 Instruction Set Architecture" data-href="../../CS 429/Notes/6.3 Instruction Set Architecture" href="school/cs/cs-429/notes/6.3-instruction-set-architecture.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">6.3 Instruction Set Architecture</a><a data-tooltip-position="top" aria-label="../../CS 429/Notes/6.3 Instruction Set Architecture" data-href="../../CS 429/Notes/6.3 Instruction Set Architecture" href="school/cs/cs-429/notes/6.3-instruction-set-architecture.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">6.3 Instruction Set Architecture</a>There are a few relevant registers ,named purely for historical reasons1%rax2%rdx3%ex4%rbx5%rsi6%rdi7%rbp8%rsp9%r810...11%r15the register pointing to the stack pointer for x86 is %rsp
What is the linker convention? Caller vs callee saved
Callee saved are the last 4 (r12-15) along with rbx and rbp
Everything else is either needing to be clearly maintained on return, used to pass arguments, or caller saved.
The first 6 arguments are passed in registers, if more than 6, put them in the stack
rbp is the frame pointer (which points to the bottom of the current function that's running).
There are also FP and vector registers. All architectures have been including more registers to do fancy things and and operations as they get more sophisticated.
We're compiling for SSE2
There are 16 vector registers
The carry flags (NXCV stuff) are in %rflags)
Also contains more specific things added to the system which a kernel can access but not a user
This week we don't have to worry about things, the kernel has a compiler flag which only uses general purpose registers
There are a bunch of other registers which we're calling the control registers
%cR0,cr2,.... We will pretend, this week, they don't exist. We also have 6 magic registers!
The Segment Registers1%cs2%ds3%ss4%es5%fs6%gsThese are apparently very odd. %fs and %gs are what is relevant for us this week.
Each one of them describes a range of memory. Each of them represents a pair of values. Each one has a:
A base
A limit (this is always infinity so we can ignore it)
Os the limit being infinity exclusive to the fs and gs registers, or all of them? If all of them, why do we need it?
Legacy reasons, back with 32 bit it was important but with 64 no one ever hit all that memory space.<br>
Read <a data-tooltip-position="top" aria-label="https://wiki.osdev.org/Segment_Limits" rel="noopener nofollow" class="external-link is-unresolved" href="https://wiki.osdev.org/Segment_Limits" target="_self">this</a> later
The basic instruction in x86 ASM has a destination accumulating in a source (with general purpose registers). It is a two operand architectureThe assembly for x86 is weird because the destination is on the right, not the left.
The most general addressing mode is (in the ATT syntax) very complex. We get some segment register fs (optional), with a displacementEffective Address = fsbase+displacement+reg(b)base+reg(i)*scaleIf we put no segment register, then it'll work implicitly
We use index and scale for array indexing. We put the location of the start of the array, the index of what we want to access, and the scale is how big each element is!
fsbase is used for the special case when we want to access a place in memory with a special property
Stacks always have alignment requirement, in ARM it was 16 byte alignment. That's be cause typically the prologue in saving will save pairs of registers.x86 says before you call a function, the SP has to be divisible by 16x68 has a call instruction. It doesn't have a link register. The call instruction will instead push it on the stack over saving the link register. This is just doing the saving on our behalf.
Call subtracts 8 from SP
The return instruction will then instead pop our value from the stack then return. This adds 8 from SP
Just make sure the stack pointer is 16 byte aligned before calling the function, and then the compiler will handle the alignment issues since it knows what it'll cause. This is the code from p1, and he'll write parts of the code with us and his code will only work on single cores. First thing we should do is get t2 working on multiple cores given his code, sine his code works on 1 core.
The initialization sequence has changed.
There's a function core_main invoked on each core during initialization
fs points to anything unique to a thread.
gs represents things unique to a core. gs might have the data structure telling me the identity of my core
When we're cycling looking at the ready queue when a given thread's process has ended, put imstuckinaloop() so that it's optimized.
We may never have any variables named about any of these things, this. is just for us to thinkTestcases should never use the impl namespace'
in C++, new will malloc the right quantity of memory and then appends it to the constructor.
There's a switch from someone who is going form running to ready and the oppositeIf I was doing multithreaded, I can make a new function which adds me to the queue and runs the new process. You can't directly add to the readyQueue because you're not ready yet, context hasn't switched.
FODOWhen you wanna do actual context switching, assembly to save, then put the pointer to it's TCB in the fs register. He won't do it here but in the assembly code.We then save our stack pointer at the location of our TCP
Line 98 is what holds our most useful information when it comes to saving the stack pointer.What happens though if B is a brand new thread! We're assuming it's going to be valid, but we shouldn't When we make a new thread, we ned to set it's state up and fake it in such a way that it seems to have already gone through the processWe have to actually manually allocate the stack in the first plae. A stack is just san array if 64bit quantities.]]></description><link>school/cs/cs-439/notes/1.5-x86-64-assembly-introduction.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.5 x86-64 Assembly Introduction.md</guid><pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.5]]></title><description><![CDATA[From last time, we wanted to figure out which representation of our generator
Example 1.4.3 (Conncattenated Repetition). it's generator would be i should stop answering questions i get confused and then want to jump off the pma
Remember that each of these vectors has a dot product equal to zero Why pick the second over the first? Well I think it's because our codewords are also easier for us to construct our generator matrux There's a smaller number of zeros in the later matrix, versus computationally less of our physical bits need to participate in the computation. requires less physical gates and operations to construct <a data-href="../../Misc/The Haar Measure#^4ba324" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^4ba324</a><a data-href="../../Misc/The Haar Measure#^4ba324" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 11 (Permutation Operators)</a> ! If our code space is just then The denser the is the lower the distance of the codeJust as beforeWe want to be able to make the codewords in a weigh that always allows us us to determine whereAnd is the hamming weightOur primitive form is to ! The issue is that this doesn't work in ngeneral. The general is not bijective, it just tells us to go from the codespace to the error spaceProblem, with message , the codeword is , then an error outside the space is , then attempting to decode with the inverse gives usThe other way we can do is that errors of long chains are probably unlikely, so we just raw compare our result given to us against the entire code-space. This is the maximum likely-hoodThis result is a function of the error we had and our codeword<br>We can use the parity check matrix <a data-href="1.4 Classical Correcting Codes#Linear Codes" href="school/physics/quantum-error-correction/notes/1.4-classical-correcting-codes.html#Linear Codes" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.4 Classical Correcting Codes &gt; Linear Codes</a><a data-href="1.4 Classical Correcting Codes#Linear Codes" href="school/physics/quantum-error-correction/notes/1.4-classical-correcting-codes.html#Linear Codes" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.4 Classical Correcting Codes &gt; Linear Codes</a> We know that the definition isWhen we apply to our modified vectorThis only has a result of being dependent on our error! That's why syndrome measurement works!! A parity check matrix gives us no information about the actual state so measurement over it is safe!<br>
But how do we identify ? From <a data-href="#^86b22b" href="#^86b22b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^86b22b</a><a data-href="#^86b22b" href="#^86b22b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.5)</a> , we can't recover exactly because is never invertible. <br><a data-tooltip-position="top" aria-label="../../QIS/Notes/2.11 Fault-Tolerant Computation" data-href="../../QIS/Notes/2.11 Fault-Tolerant Computation" href="school/physics/qis/notes/2.11-fault-tolerant-computation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.11 Fault-Tolerant Computation</a><a data-tooltip-position="top" aria-label="../../QIS/Notes/2.11 Fault-Tolerant Computation" data-href="../../QIS/Notes/2.11 Fault-Tolerant Computation" href="school/physics/qis/notes/2.11-fault-tolerant-computation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">2.11 Fault-Tolerant Computation</a>
If we have some parity check matrices
We've received and we know that though we don't know if it's . If then we get a logical errorChose this probabilistically based on the weight of errors.
Pick with probability <br>
For the <a data-tooltip-position="top" aria-label="1.3 Channel Capacities and Classical Error Correction > Binary symmetric channel" data-href="1.3 Channel Capacities and Classical Error Correction#Binary symmetric channel" href="school/physics/quantum-error-correction/notes/1.3-channel-capacities-and-classical-error-correction.html#Binary symmetric channel" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">binary symmetric channel</a><a data-tooltip-position="top" aria-label="1.3 Channel Capacities and Classical Error Correction > Binary symmetric channel" data-href="1.3 Channel Capacities and Classical Error Correction#Binary symmetric channel" href="school/physics/quantum-error-correction/notes/1.3-channel-capacities-and-classical-error-correction.html#Binary symmetric channel" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">binary symmetric channel</a>, where bits flip with prob . The probability we have a given weight is The issue here is that a shitty code can make it so that our result is equidistant from two codewords. As it turns out being equidistant doesn't promise that we can't decode!! Those are called degenerate codewords. Nearest Neighbor Decoding has a high computational cost because of the exponential space size. Either do an initial lookup, or do it on demand<br>The set of all syndromes <a data-href="#^86b22b" href="#^86b22b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^86b22b</a><a data-href="#^86b22b" href="#^86b22b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.5)</a> are in the image of . Because it's a subspace, we now have a group. That means we can now find cosets of our larger space () with . Definition 1.1.4 (Cosets of a Group). If is a subgroup of . Given , the cosets of are all the sets of the form Its like vectors multiplied by scalars I think is the coset leader. It's the argmin wt( where )
The coset leader is the smallest weight leader to escape from that coset
We know that our received vector appears in . This tells us that thenWe know already thatThenWe know any two codewords added together is another codeword!<br>Wherever is, is also where it's error is! If ends up in one of the buclets in <a data-href="#^4132e6" href="#^4132e6" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^4132e6</a><a data-href="#^4132e6" href="#^4132e6" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.8)</a>, then the most likely error is the coset leader !]]></description><link>school/physics/quantum-error-correction/notes/1.5.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/1.5.md</guid><pubDate>Wed, 04 Feb 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.1 Math Summary]]></title><description><![CDATA[Today we're covering all the necessary algebra and math required for this course. It's a speedy recap, so if I'm curious maybe look in other files or textbooks.
The Algebra section is probably worth looking more into since this is my first time seeing it properly. Homework gets released next Monday, but gets due the subsequent FridayDefinition 1.1.1 (Group (Algebra)).
A non-empty set along with a binary operation (symbolically for us ) (taking two elements from the set in and returning another element in the set)
A group has the following properties : Identity A singular and unique element s.t Every element has an inverse: where . Associativity , Commutativity is not guaranteed! Example 1.1.2. Claim: This is a group. To prove this we just check if this holds. Identity 0 is the identity Inverse , Associativity this is promised in addition We might wonder if the integers with multiplication is a group. We might satisfy the second and third conditions if we can identify the first, but we'll find that we can't.
What if 1 is the id? Well we have a problem with zero, as it does not work with every element in the group
I am not concussed! I am totally acute and aware and not spacey at all!Other examples of groups: p is prime
Set of all invertible matrices is a group
Set of permutations on elements is a group with composition
Exercise (AT HOME: Think through why the above might be true). Definition 1.1.3 (Sub-Groups).
A nonempty set is a subgroup of if itself is a group under the same operation Definition 1.1.4 (Cosets of a Group). If is a subgroup of . Given , the cosets of are all the sets of the form Its like vectors multiplied by scalars I think
Cosets define equivalence classesExample 1.1.5 (, ). would be all the multiples of within the integers Cosets of -- :
- - - - - Notice that there's only 4 unique cosets! This is true all the time for cosets, that there is a finite quantity of disjoint cosets. both map to the same thing, so in this subgroup there is an equivalence between . This comes up with syndrome attraction between ECC's
Definition 1.1.6 (Field).
A field is a set with two operations (which we will call here) with the properties: is a group itself with identity 0 is associative on both is distributive () has a multiplicative identity of is commutative has multiplicative inverses Some examples of the above are For reference, In all the fields we care about, all the operations would behave exactly how we expect addition and multiplication to act
With finite numbers of elements, people often denote a table of their operationsI will make it through an hour and a half class !Definition 1.1.7 (Vector Space).
A set is a vector space over a field if there are maps (functions) with the following properties Scalar Multiplication: Vector Addition: , With Properties of the elements as: , With row vectors we have no defined multiplication, but we do have defined addition We're most familiar with the vector space on Example 1.1.8 ( is a vector space, where:). This is trivially extended to so I'm not typing it out. future azal if you needed that, uh cope?Definition 1.1.9 (Orthogonality in a Vector Space is orthogonal to if ).All associated links to Orthogonality in ma notes. Maybe later reverse these links so they link here over the reverse
<a data-href="../../Misc/The Haar Measure#^14aa94" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^14aa94</a><a data-href="../../Misc/The Haar Measure#^14aa94" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 8 (Orthogonal Projector)</a> <br><a data-href="../../Misc/The Haar Measure#^14aa94" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^14aa94</a><a data-href="../../Misc/The Haar Measure#^14aa94" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 8 (Orthogonal Projector)</a>
<br><a data-href="../../Quantum Computing/Definitions/Orthonormal Bases#^506716" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Definitions/Orthonormal Bases &gt; ^506716</a><a data-href="../../Quantum Computing/Definitions/Orthonormal Bases#^506716" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1 (Orthonormal Basis)</a> <br><a data-href="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^9ceba6" href="school/math/linear-algebra/6.3-orthogonal-and-orthonormal-spaces.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces &gt; ^9ceba6</a><a data-href="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^9ceba6" href="school/math/linear-algebra/6.3-orthogonal-and-orthonormal-spaces.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 6.3.2 (Orthogonal Subspaces)</a>
<br><a data-href="../../../Math/Linear Algebra/7.1 Quadratic Forms and Orthogonal Matricies#^3bc9f8" href="school/math/linear-algebra/7.1-quadratic-forms-and-orthogonal-matricies.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/7.1 Quadratic Forms and Orthogonal Matricies &gt; ^3bc9f8</a><a data-href="../../../Math/Linear Algebra/7.1 Quadratic Forms and Orthogonal Matricies#^3bc9f8" href="school/math/linear-algebra/7.1-quadratic-forms-and-orthogonal-matricies.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 7.1.1 (Orthogonal Matrix)</a>
<br><a data-href="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^a5e804" href="school/math/linear-algebra/6.3-orthogonal-and-orthonormal-spaces.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces &gt; ^a5e804</a><a data-href="../../../Math/Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^a5e804" href="school/math/linear-algebra/6.3-orthogonal-and-orthonormal-spaces.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 6.3.4 (The Orthogonal Decomposition Theorem)</a> Definition 1.1.10 (Linear Transform).
A linear transform is a function from one vector space to vector space so that Matrix multiplication is an example of this
Definition 1.1.11 (A subset of of is a subspace of if is a vector space, ).We're only really interested in two relevant subspaces, the kernel and image of our transformation Definition 1.1.12 (Images and Kernels).
If is a linear transform then The image of , An image is just a shadow
Definition 1.1.13 (Basis of a Vector Space).
A set of vectors form a basis for a vector space if Definition 1.1.14 (Dimension of a Vector Space).
The size of a vector space's basis
Example 1.1.15 (The Basis of ). is a basis (This is the identity matrix's rows) Example 1.1.16 (The Basis of ).
This is just the set of bit strings, and it's the same basis as before! Our tweaked definition of arithmetic in this field is what saves us here
i am not with concussion i am not with concussion. thank fucking god this is just linalf
Relevant Material
<br><a data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues &gt; ^2a6704</a><a data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5.1.2 (Eigenvalues)</a> <br><a data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues &gt; ^ab6240</a><a data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5.1.1 (Eigenvectors)</a>
<br><a data-href="../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography#^29be59" href="school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html#^29be59" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography &gt; ^29be59</a><a data-href="../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography#^29be59" href="school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html#^29be59" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Pauli Matrix)</a> <br><a data-href="../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography#^917569" href="school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html#^917569" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography &gt; ^917569</a><a data-href="../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography#^917569" href="school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html#^917569" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.1 (Pauli Matrices and Density Matrix)</a> Definition 1.1.17 (Eigenvalues and Eigenvectors).
Let be a linear transform. Then for a non-zero vector, , this is an eigenvector of with eigenvalue if If is a matrix, What we want here in classical and quantum error correction, is that some states are invariant under transformations. We want to operate on quantum information, I need something we know will be the same that I can reference against. (Our true transformations, the ones we do not the environment). We want to be able to record information via the eigenvalues and eigenvectors to give us information on what the "true" state was. What we can measure the eigenvalues, so our ECC procedure uses this fact. ]]></description><link>school/physics/quantum-error-correction/notes/1.1-math-summary.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/1.1 Math Summary.md</guid><pubDate>Wed, 14 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.1 Spherically Symmetric Potentials]]></title><description><![CDATA[Today we covered solving for the spectrum of a spherically symmetric hamiltonian, then later we solved the special case of a particle in a sphere. Today we're starting with a non-relativistic hamiltonian, which is radius dependent.(This hamiltonian is true for all non-relativistic particles in a spherically symmetric potential)We want to know the energy states (obvi)We know already that the hamiltonian commutes with the angular momentum. This is obvious because the Hamiltonian is composed of two scalar terms, and rotating a vector on a radius, yields a result still on the radius. More information on this comes from We also knowOur energies will then beWhere is another quantum number.To solve for our energies, we can solve through a position projectionWe are going to define the following equality, which can be easily checkedExercise 3.1.1 (AT HOME:Check the above).Plugging this into <a data-href="#^leftOff" href="#^leftOff" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^leftOff</a><a data-href="#^leftOff" href="#^leftOff" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.6)</a> Using an existing radius momentum commutation rule, which saysWe then reduce to<br>Plugging into <a data-href="#^rpepsilonTerm" href="#^rpepsilonTerm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^rpepsilonTerm</a><a data-href="#^rpepsilonTerm" href="#^rpepsilonTerm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.8)</a> This means we can now solve for <br>Plugging back into our hamiltonian <a data-href="#^radiusDepHam" href="#^radiusDepHam" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^radiusDepHam</a><a data-href="#^radiusDepHam" href="#^radiusDepHam" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.1)</a> Notice two things, Lack of angular dependance
Dependance on the quantum number. (This would imply asymmetry in the -direction)<br>
Now to solve for our energies from <a data-href="#^leftOff" href="#^leftOff" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^leftOff</a><a data-href="#^leftOff" href="#^leftOff" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.6)</a>, using <a data-href="2.6 Spherical Harmonics#^3398f1" href="school/physics/quantum-1/notes/2.6-spherical-harmonics.html#^3398f1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.6 Spherical Harmonics &gt; ^3398f1</a><a data-href="2.6 Spherical Harmonics#^3398f1" href="school/physics/quantum-1/notes/2.6-spherical-harmonics.html#^3398f1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.6.1 (Spherical Harmonics)</a> WE HAVE TWO 's, one is the mass, one is the quantum number.It's the end of my career, and I'm getting out if here FASTFuture Azal, the potential from the hamiltonian got thrown back in at the end because he forgot to use math with itNow we're going to do a change of variables, and claim the result. We're deep in the weeds here, so he's making this another take home.Exercise 3.1.2 (TAKE HOME: Perform this substitution yourself).Notice how it looks like a 1D Schrödinger equation!
Definition 1.6.2 (Schrödinger Equation). Also written as The only condition you need to solve this equation, is Where is a Unitary, is the identity, and is the hamiltonian of the Hamiltonian Now we're going to define the following conditionsOur problem is thenThis makes our differential equation becomeStarting with our quantum number , Just from intuition, we know that<br>So then in <a data-href="#^sol1" href="#^sol1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^sol1</a><a data-href="#^sol1" href="#^sol1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.20)</a><br>That makes our normalization constant. Additionally, we still need to impose our boundary conditions at <a data-href="#^boundaryCondition" href="#^boundaryCondition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^boundaryCondition</a><a data-href="#^boundaryCondition" href="#^boundaryCondition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.17)</a>More generally, we'd use Spherical Bessel Functions]]></description><link>school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/3.1 Spherically Symmetric Potentials.md</guid><pubDate>Tue, 12 Nov 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.8 H2+ Cont]]></title><description><![CDATA[ Fo the variational treatment of , what is the relative contribution of the Direct and Exchange terms?
Both the direct and exchange terms lower the energy is actually exactly separable in "confocal-elliptical coordinates". That means we can break it out into the product of 3 one dimensional DE's.
With the hydrogen atom, our unperturbed energy just goes by . That's because of our spherical symmetry. However, this is not true for diatomic hydrogen! We broke the angular symmetry along the axis collinear of the two protons.
Without any variational parameter, the energy was found as .
With one variational parameter when we allow an adjustable gets us . That's way better! Experimentally it's OOH OR DRUNKEN NOODLES I WANT CHINESE FOOD I SHOULD COOK IT
Dark soy sauce
soy sauce
Oyster sauce
—-
Chinese spinach, bell peppers
Chicken/egg/meat
When we wanted to get the bonding wave-function in <a data-href="2.7 H2+ Ion#^ff22ff" href="school/physics/quantum-2/notes/2.7-h2+-ion.html#^ff22ff" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 H2+ Ion &gt; ^ff22ff</a><a data-href="2.7 H2+ Ion#^ff22ff" href="school/physics/quantum-2/notes/2.7-h2+-ion.html#^ff22ff" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.7.2)</a>, we did a positive superposition of the two hydrogen 1s states. What does it mean to make it a negative superposition?Turns out the wave-function is our anti-bonding orbital. One wave-function went down (bonding orbital), while the other went up.Is this saying that the electron is most likely to be inside the nuclei of the molecule? They're separated by in the diagram, which is the peaks. If you actually went to do the probability calculation, you'd need your spherical jacobian. . The radius term in the jacobian goes to zero at those points faster than the exponential blows up. There's a hole right ontop the nucleii
Notice that the anti-bonding wavefunction goes to zero at the center! They're unshielded in that state. Being in the higher energy configuration is a higher energy, which makes senseWhat's the difference between a ion, and ? They both have the same particles: 2 protons 1 electron.
You no longer have the proton-proton repulsion term gets "eaten up by the neutrons" What does that even mean?
Strong force stuff?? ]]></description><link>school/physics/quantum-2/notes/2.8-h2+-cont.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.8 H2+ Cont.md</guid><pubDate>Wed, 26 Mar 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/e0M9JUv3T7rqDSv7Dz.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/e0M9JUv3T7rqDSv7Dz.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.8 Gauss' Law]]></title><description><![CDATA[
Electric Flux
Gauss' Law
Applications <a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Electro Exam ⏳ 2025-02-17 🔺 🆔 PHY352K
Last time we've covered charge distribution stuff, to determine the electric field. In principle we're dine, so we have all we need for any electrostatic problem.
While that approach is always true, it's not always feasible. We're going to learn about how to solve in other ways, which simplify problems greatly.Gauss' Law relates the flux to the charges.Definition 1.8.1 (Electric Flux). To find the flux, you need to calculate a normal vector to the surface so that you can take the normal.
If the surface is curved, then you need to divide the surface into infinitesimals and integrate over all those normals. (Calculate the normal vector for every point on the surface, then surface integral) Where is the normal at any given point
Above is the flux through an open surface, but it need not be open! <br>Definition 1.8.2 (Electric Flux through a Closed Surface). For a closed surface, the area (the normal) points outwards. Positive flux enters the surface, and negative flux leaves the surface. If there are no charges on the interior of the shape, the net flux is obviously zero. What comes in is balanced with what leaves. If there are charges inside, then the flux changes according to <a data-href="#^50c460" href="#^50c460" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^50c460</a><a data-href="#^50c460" href="#^50c460" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.3 (Gauss' Law)</a> Definition 1.8.3 (Gauss' Law).
The net flux of the electrostatic field in a vacuum, is Our flux is directly proportional to our enclosed charge. Gauss' Law is fundamental to electrostatics.
4. It allows us to determine the electric field for a given electric field when there is a nice symmetry, via a distribution of charge. Why's the symmetry important? well once you've identified the symmetry, you can exploit that symmetry when calculating your electric field.
- You might have spherical symmetry. In that case, when applying Gauss' Law we know that the electric field is solely proportional to the radius since flux is preserved.
- With cylindrical symmetry, your gaussian surface is coaxial cylinders
- With infinite planes your gaussian surface is a pillbox which straddles the surface. Like a cylinder perpendicular to the surface and through.
- [0] Wow it really is a straight up called a pillbox colloquiallyAfter class.U should look into the doctors appointment because I keep forgetting. Prob wanna make my stress listNo crashouts this timeExample 1.8.4 (Let's say you have a sphere with a charge distribution on the surface. How do we get the electric field outside?).
Make a gaussian surface outside the sphere, with a radius The flux at our second point is For the flux inside the sphere, the electric field can still only be radially dependent. In this problem, the electric field has to be zero inside.
NOTE: Zero flux doesn't imply no electric field. We can have a source and a drain.
What happens when we make the sphere dense? This just changes a piecewise condition on the interior, since the charge now scales against the radius. If you work it out, the field increases linearly as you increase the radius until you exit the sphere and then it drops by . Remember though that in this case, we'd need to perform a volume integral to get the enclosed charge in a sphere. ]]></description><link>school/physics/electrodynamics/notes/1.8-gauss'-law.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.8 Gauss' Law.md</guid><pubDate>Wed, 05 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/BzCLJGxXQbwH09jzq0.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/BzCLJGxXQbwH09jzq0.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3 Laplace's Equation]]></title><description><![CDATA[The direct approach to solve for induced charges on the surface of a conductorLast time we covered the method of image charges, which exploits the uniqueness of the uniqueness theorem to Poisson's equation. You just want to find the charge which produces identical opposite effects at the surface of the conductor. Other than watching the lecture notes, Griffiths 3.1.4 does a great job explaining this!What happens if the sphere is not grounded, but isolated? Because then the system can't draw an arbitrary amount of charge and we must maintain conservation.If the sphere was not grounded at a potential , then super-position tell us that the previous solution should still be valid.
It would be the previous solution, Another note is that electric field lines have to be normal to our conducting surface.The other way to solve this is through separation of variablesFirst we make a trial solution through separation of variables
Solve the ODE for each variable and construct by linear superposition of a class of solutions Apply boundary conditions to determine your specific system Plug this into Laplace's equation to getThen divide by The solution then becomes some combination of exponentials<img src="supplemental-files/images/pasted-image-20250224104457.png" target="_self">
Then we just went through 3.5 in Griffiths]]></description><link>school/physics/electrodynamics/notes/2.3-laplace's-equation.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/2.3 Laplace's Equation.md</guid><pubDate>Mon, 24 Feb 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.3 Channel Capacities and Classical Error Correction]]></title><description><![CDATA[Today we introduced the channel capacity model with examples, and introduced ECC's finally!Where the entropy of our system is thenWhat's the entropy of the distribution for what Bob gets?
Well when we add everything up, it's all the combinations of the possible products based on the information definition of entropy If we know what is sent by Alice then we just have the entropy injected by the channelWe want to know how good or bad this channel is.
The channel capacity determines if we can successfully determine the error rate of the channel.
To get the capacity we need all the entropies al along the way
The other quantity we need is from <a data-href="1.2 Information Theory#^879d73" href="school/physics/quantum-error-correction/notes/1.2-information-theory.html#^879d73" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.2 Information Theory &gt; ^879d73</a><a data-href="1.2 Information Theory#^879d73" href="school/physics/quantum-error-correction/notes/1.2-information-theory.html#^879d73" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.2.5)</a> Then to find our maximized values, we can consider the extreme bias case , where 100 messages sent 95 are 1, 5 are 0In the middle we start ignoring completely what was occurring with Alice! THIS IS RELATED TO THE CODEWORD STUFF WITH THE 3 QUBIT CODE
Wait this is exactly that case
this channel is destroying bias as <br>
<img alt="../../../../Supplemental Files/images/Pasted image 20260128135031.png" src="supplemental-files/images/pasted-image-20260128135031.png" target="_self">
Oh duh that peak is just if I perfectly set a message and something happens along the way, there will be more uncertainty with what happens probabilistically. When is ? : the distribution Bob gets is exactly what Alice gets. I can work this out manually if needed Alice starts with a uniform distribution in the first place. We're already scrambled as much as we can going in, can't scramble more When finding the maximum of the channel capacity, we want to maximize the quantity , there's a case when the channel is never able to transmit information, and that's the case.
This means Where is nothing. We added a symbol!The original entropy isEnd goal is then gotten through our last line withthen our channel capacity is maximized when , making our channel capacityThis means that unlike our previous situation when we have complete information destruction
Compare this to the Binary channelWe'd much rather have an erasure channel to a channel than a flipping channel, because then we can just query until we get the right answerThe Source: The set of messages we really want to send
Encoding Procedure: Transformation from message to codeword by putting ourselves into a larger space.
Noise that actually effects it: Transformation on encoded information, out of our control
Two kinds Single unified channel means that we put al the errors right at the end with a given model
Many Channel More accurate version is when you put intermediate errors throughout the computation and gates
Decoding Information Transformation of received encoded information into a message. Our noise will move us around the target space, and we want to make sure that the code has it so that if we move a bit away from where we want to be due to errors, we can still correct. the distance keeps the words far away within the code space. A higher distance has a higher resilience.
the decoder's maps also have itself an exponentially hard problem, so there rise multiple possible issuesExample 1.3.1 (Repetition Code). Encoder (Repetition Code) , Noise flips the middle bit : , Decoder will then use majority vote! , This encoding scheme protects us from this error
Logical Error But with a diff noise source, the last two bits flipping and , the decoder now gets it wrong! , With a majority vote, with bits to encode, bits need to flip before we get the codewords get confused. More space can add us more distance. Now we're going to formalize this!Definition 1.3.2 (Error Correcting Code).
A classical error correcting code is a pair ,
Where is a map a set of correctable errors is a map where we go from the encoded information to the error space (including the case of no error), with the property that there is a map which maps me from the error space, back to the encoded space so That says is to code-space, takes me to the errors, then takes me back ut
A logical error occurs when and if two different words with two different errors, land on the same place. From the picture above, we can imagine the noise radius at one codeword colliding with that of another. a good EC has my codewords far apart, but not a lot of wasted space either. Just using a large space doesn't promise me wins. We could have two codewords too close together, or one codeword too far apart. We want our encoding map to perfectly pack our bits together.
A good decoder should be be that always maps erroneous words back into the right location. ]]></description><link>school/physics/quantum-error-correction/notes/1.3-channel-capacities-and-classical-error-correction.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/1.3 Channel Capacities and Classical Error Correction.md</guid><pubDate>Wed, 28 Jan 2026 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.1 Fundamentals of Probability]]></title><description><![CDATA[Definition 1.1.1 (Discrete Distribution).
The number of outcomes is countable and distinct. This includes examples such as rolling a dice. The sum of all the outcomes is 1.
Definition 1.1.2 (Continuous distribution).
The value be any value within a certain given range. The integral from is 1.
PDF stands for probability Density DistributionDefinition 1.1.3 (The Multiplication Rule for Independant events).
If you have two independent events, the probability of all individual events occurring together, is the product of the probability of each event.
Definition 1.1.4 (The Law of Addition).
The probability of mutually exclusive outcomes occurring one or () the other, is the sum of the probabilities
Given some experiment with an outcome, if you know the probability of occurrence, repeating trials would only give the probability as 1import matplotlib.pyplot as plt2import matplotlib3import math4import random5def simulation(N,p,samples):6	result = []7	for i in range(samples):8 heads = 09 for sample in range(N):10 11 if random.random()&lt;p:12 heads +=113 result.append(heads)1415	return np.array(result)16samples_fair = simulation(1000,.5,1000)17samples_unfair = simulation(1000,.25,1000)18plt.hist(samples_fair/1000,bins= 30,label = 'Fair Coin',histtype = 'step')19plt.hist(samples_unfair/1000,bins = 30,label = 'Unfair Coin',histtype = 'step')20plt.legend()21plt.grid()22plt.xlabel('Fraction of Heads')23plt.ylabel('Frequency')24plt.title('Distribution of Flipping Coin')25plt.show()The more coin flips we take, the lower the standard deviation there is around the meanDefinition 1.1.5 (Bernoulli Process). Has the following characteristics: Two possible outcomes, success or failure
Constant probability : Each trial has a constant probability resulting in the success criteria
Independence: Each trial is Independence from the outcome of previous trials Examples:
Flipping a coin Heads or Tails
50-50 for each throw
Flipping a coin doesn't affect the next throw Definition 1.1.6 (Binomial Distribution).
The probability of observing successes out of trials, where each trial has a success. rate is The combinatorial term is given by the number of ways to choose successes out of trials
For large values of , the binomial distribution can be modeled close to a normal distribution. You can do this modelling through Stirling's approximation. Why though. In the proof Dr. Thomas showed us a plot comparing, but why does the underlying math show it's a possible approximation?
`
]]></description><link>school/physics/qis/modern-physics/notes/1.1-fundamentals-of-probability.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.1 Fundamentals of Probability.md</guid><pubDate>Tue, 03 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 Information Theory]]></title><description><![CDATA[Sending information and there's no information corruptionAlice selects a message In error correction Alice is also Bob, where she's trying to preserve the integrity of her own information
Example:
Alice wants to tell Bob what cars pass by her window while they're on the phone and she looks out the window
She selects There is some environmental thing that is happening, the message itself is selected randomly with a probability . The messages along with this probability distribution form a measure A measure tells us that We want to quantify general behaviors, which we can do via the expectation values on functions.
<a data-href="../../Quantum Computing/Semester 1/3.3 Density Matrices#^150ee1" href="school/physics/quantum-computing/semester-1/3.3-density-matrices.html#^150ee1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/3.3 Density Matrices &gt; ^150ee1</a><a data-href="../../Quantum Computing/Semester 1/3.3 Density Matrices#^150ee1" href="school/physics/quantum-computing/semester-1/3.3-density-matrices.html#^150ee1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Expectation Value of Density Matrix)</a> <br><a data-href="../../Misc/The Haar Measure#^e4405c" href="school/physics/misc/the-haar-measure.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Misc/The Haar Measure &gt; ^e4405c</a><a data-href="../../Misc/The Haar Measure#^e4405c" href="school/physics/misc/the-haar-measure.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5 (Expected Value over the Haar Measure)</a> An important function we care about is the self information function. Definition (Self Information Function). is just which gives the amount of information associated with a specific message Example 1.2.1 (Coin flipping).
Heads and tails are equal in probability. The expectation value is Then we calculate the information from observing each outcome, We see it takes one bit to encode the information from heads.
But what happens if to ?
The extreme case i s, so . Flipping the coin means we get no information, which makes sense. We get no useful information about the coin because we knew it was a trick coin ahead of time. Definition 1.2.2 (Entropy of the Source).
The expectation value of the self information <br><a data-href="../../QIS/Notes/1.13 Interpretations of Quantum Mechanics and Entanglement#^858417" href="school/physics/qis/notes/1.13-interpretations-of-quantum-mechanics-and-entanglement.html#^858417" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../QIS/Notes/1.13 Interpretations of Quantum Mechanics and Entanglement &gt; ^858417</a><a data-href="../../QIS/Notes/1.13 Interpretations of Quantum Mechanics and Entanglement#^858417" href="school/physics/qis/notes/1.13-interpretations-of-quantum-mechanics-and-entanglement.html#^858417" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.13.1 (Von Neuman Entropy)</a>
This entropy quantifies how much uncertainty is there over our measure.
We're maximized at the maximally mixed state. The more certain we are that an event would be happening, the less information we get from an event when it does
The majority of communicates: Transfer bits not words. if we have entropy . If a source has entropy , it requires bits to communicate is the number of bits in the bitstring representation of the word \ref huff
Entropy bounds the number of bits we need<br>The expected length of our message is within 1 of our entropy. This tells us how big the code needs to be in the average case <a href=".?query=tag:huffmancoding" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#huffmancoding">#huffmancoding</a> <br><a data-tooltip-position="top" aria-label="../../Statistical Mechanics/Notes/1.8 Entropy" data-href="../../Statistical Mechanics/Notes/1.8 Entropy" href="school/physics/statistical-mechanics/notes/1.8-entropy.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Entropy</a><a data-tooltip-position="top" aria-label="../../Statistical Mechanics/Notes/1.8 Entropy" data-href="../../Statistical Mechanics/Notes/1.8 Entropy" href="school/physics/statistical-mechanics/notes/1.8-entropy.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.8 Entropy</a>
Example 1.2.3 (Alice+Bob+Colors). 8 elements
Our encoding scheme needs to map us form one word to another. We can just start counting from zero here and go up! It takes 3 bits. We're in the maximal entropy state
This works great without noise, but not well with noise since the spacing between words is really close
Not Equally Distributed We know our entropy must go down. It's We must use at least one bit, but that makes little intuitive sense. This is saying Alice can come up with a code where Alice can send one bit to bob and It'll convey the color. That makes sense! The bit just maps to if it's red, or not. That covers of cases (87.5%).
Another Example Unnecessary to use 3 bits. We need to come up with an encoding scheme that lets Bob see what color it is exactly.
For our example [!question]+ Will there be the implicit information that the message has terminated or do we need to worry about prefix codes?
We will assume for now that we get that information for free and then find it later
But because im extra I did just use an online calculator for huffman coding<br>
<img alt="../../../../Supplemental Files/images/Pasted image 20260121140152.png" src="supplemental-files/images/pasted-image-20260121140152.png" target="_self">
The expectation value for our message length goes out to 2.65 which is def less than 3
We're closer to the ideal uniform encoding of bits. This opens up our space a lot better, to get the fewest number possible. How do we know a code is the perfect one?
He's not a theorist
In quantum hardware perfect codes aren't good because in practice we can only interact with what we're talking too adjacently. Perfect codes are good from an information theoretic standpoint but not a practical one. With our previous model, we haveBoth selections from each set are finite. We care about the joint probability distributions .
"It's the probability that Bob receives and Alice sends "The last two conditions are just tracing out the probabilities.
Then to calculate the entropies in this distributionEntropies: Bob can only ever see , he looks at exactly one piece of information. Ideally Bob can decipher exactly what was based on what is. We need conditional probabilities for what is received by bob given what he was sent from Alice. Our important numbers are and We can determine these vyWe want to evaluate the quality of a channel at scrambling information based on how a code is constructed. IS A DENSITY MATRIX JUST A CONDITIONAL PROBABILITY MATRIX?Example 1.2.4 (Noiseless Channel).
Back to the noiseless channel, can we recover it back when there's no noise?
Bob gets exactly the message sent by Alice .<br>
From <a data-href="#^d7dcd4" href="#^d7dcd4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^d7dcd4</a><a data-href="#^d7dcd4" href="#^d7dcd4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^d7dcd4</a> we know that If we know one thing, then he knows the first thing. The message is always perfectly interpreted and determined by the information of what was sent.
If we know that is true, we know the individual entropy's information The joint entropy is the same entropy as what was sent by Alice! The number of bits we require will only depend on the information from the initial source messages
Example 1.2.5 (Uncorrelated Channel).
Bob will select something independently from regardless of what Alice sends. Charlie is just completely tossing all the useful information. Charlie and Bob's communication is basically an independent noiseless channel, and functionally doesn't care about about Alice. Bob thinks what he's getting is correlated to what Alice sends.
The joint entropy of the distributions is just the sim of both entropies Bob basically can never correlate what he gets to what Alice sends, he's just guessing
When do i need to wakl to docotr apptmt, 7 min..?
Bounds on EntropyTheorem 1.2.6 (Bounds on the Entropy Sent over a Noisy Channel). As long as we're within these bounds we can correct our code with some quantity of information.How much information will Bob gain by measuring a specific outcome from the noisy channel. Ideally it's a nontrivial quantity. Definition 1.2.7 (Mutual Information).
How much information Bob gains from a specific measurement/received message If I observe, for example 10 how much do I learn about the original information sent by Alice. Do different messages carry diff amounts of information? Yes
We'd like to give our information over the whole set, so Interpreting it happening as though there's no noise, This means that our information is Our quantity is actually 0! Because we just learned the message given exactly what we were given, nothing else was learned. ]]></description><link>school/physics/quantum-error-correction/notes/1.2-information-theory.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/1.2 Information Theory.md</guid><pubDate>Wed, 21 Jan 2026 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.5D More on Threads!]]></title><description><![CDATA[We continued off from <a data-href="1.5 x86-64 Assembly Introduction" href="school/cs/cs-439/notes/1.5-x86-64-assembly-introduction.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.5 x86-64 Assembly Introduction</a><a data-href="1.5 x86-64 Assembly Introduction" href="school/cs/cs-439/notes/1.5-x86-64-assembly-introduction.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.5 x86-64 Assembly Introduction</a> with Geith in the first half, then TA's talked about how the quizzes went. correction from yesterday, the first argument from a function gets pushed to rdi not rsi. rsi is the second inputTo finisht the assignment completely we need to generalize functions to lambdas. To get going though we only need pointer to a function
A brand new thread should be 6 blocks from the bottom, since it'll pop different values for it's incoming registers. But what to set? Well we don't care! It can be anything, as long as we survive the sequential pop'ing 6 times.
But what do we want the brand new thread to do for the return register? Put the pointer for func so that we return to it/call it. But now what happens when the function returns? The thread should terminateWhat we're thinking instead is to define another function which does the thread entry logic, and then stops the thread for us1[[noreturn]] thread.entry(){2	tcb *me = (TCB) readfsbase()3	ASSERT(me!=null);4	ASSERT(me.self == me);5	//sanity check on the TCB given a sentinel we know should exist6	//stackpointer shouidl point in the middle fo where our stack is7	//really difficult to debug these things, so it's really good to do this8	func();9	Thread::stop10	}This is also a great place to debug things and put breakpoints! But how do we know what the function is if we can't take an input? Well from our diagram we can just read fsbase and then find the function pointer.
Everywhere we read from fsbase, we need to deal with it in a special way since we could be a bootstrapping functionIs there a way that we can wrap that extra logic in a macro or a function? Do not force ourself to do things the way he does them. Other techniques might make more sense to me. We need to update the constructor of TCB to do the right things, like make that function wrapper for entry, fill the last 6 elements in the stack, etc.
The noreturn instructions are very important since it helps use our compiler to debug
two ways of making things stop in this world, we just have to call the shutdown function somewhere in your test. This wont always work, since you can't edit tests.
The other assignment requirement is that if the system gets itself in a state with no threads that have any hope of running in the future, it should auto shutdown. What does no hope mean? In p3 we're implementing a sleep function which might be too long, that's no hope Do we know have to implement that check? No it's with the coming assignment We have to check for leaks in the heap, and tests will check for that. There is a function in the heap called leak, which tells the program that a given data-structure might leak by design (like )He'll talk about getting up to the closure stuff by Tuesday along with thread_local variables
Shoud be able to get through phase 1 by Tuesday!
The TLS should be sitting right above the TCB given the fsbaseHow do I know what big enough is? The size is only available at runtime
Once we get TLV's working, we can really put everything there. Registers, function pointer, rsp, etc.
Do phase 1 by TuesdayAlways loading a specific sector to memory as the kernel, advantage and disadvantageAdvantage: Fast because no additional verification was needed!
Disadvantage: No security checks, cant load a kernel over a sector, no choices, etc.We cant do everything without atomics/ Atomics guarantee some sort of ordering to our execution. Cache coherency would let us load in an address and store, but we don't know what happened in-between. The ad of cache coherency is that it's faster than atomics, atomics has a high overhead to ensure overhead. Explain why atomics have a higher overhead
They are open to regrades here since they know that the wording on the question wasn't great.
those are preferred 1 week after grades get released This is wrong because we can have
C1 goes critical, core 3 runs and unlocks, then other cores can enter the critical section, then core 1 wrapsp1 array versus 10 array heap
What if instead we did the 10 small arrays, advantage and disadvantage Advantage: faster heap operations
Disadvantage: Cant malloc large amounts of memory anymore. ]]></description><link>school/cs/cs-439/notes/1.5d-more-on-threads!.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.5D More on Threads!.md</guid><pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.5 Klien Gordon]]></title><description><![CDATA[Klein Gordon introduced relativistic quantum mechanicsI have an equation. Do you have one to?
Dirac to like, everyone apparently unironically
whoops kismet schedule
Monday assignment has been pushed back to Thursday. Short assignment due Monday!Definition 1.6.2 (Schrödinger Equation). Also written as The only condition you need to solve this equation, is Where is a Unitary, is the identity, and is the hamiltonian of the Hamiltonian We have the Shrodinger equation for us, there's an incorporated. With a relativistic particle with no mass that would be mad. We have time and space derivatives treated differently
We're around 1926 with Klein Gordon , after Rutherford scattering, after radioactive decay. People are building tiny accelerators
<a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Cockcroft%E2%80%93Walton_generator" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Cockcroft%E2%80%93Walton_generator" target="_self">Cockcroft–Walton generator</a>before we started with a string of 1D oscillators connected to each other by springs with to the ground by springs .Stepping back form the end of last timeDefinition 1.5.1 (De Broglie Equation).
All free quantum particles can be described by plane waves (like photons!) such that We can write this compactly as<br>where and is a <a data-href="1.2 Special Relativity#^0d82c4" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^0d82c4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.2 Special Relativity &gt; ^0d82c4</a><a data-href="1.2 Special Relativity#^0d82c4" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^0d82c4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.2.8 (Four vector)</a>
This implies(because remember the magnitude of the 4 momentum is the mass squared)<br>
We showed the <a data-href="1.4 Least Action#^a4a4c9" href="school/physics/quantum-3/notes/1.4-least-action.html#^a4a4c9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.4 Least Action &gt; ^a4a4c9</a><a data-href="1.4 Least Action#^a4a4c9" href="school/physics/quantum-3/notes/1.4-least-action.html#^a4a4c9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.4.2 (Euler Lagrange Equation)</a> for this ishas solutions of the wave equation or a Where<br>We see that <a data-href="#^2a4c17" href="#^2a4c17" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^2a4c17</a><a data-href="#^2a4c17" href="#^2a4c17" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.3)</a> can be connected to our EL equation. That means we just replace in <a data-href="#^3a21e4" href="#^3a21e4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^3a21e4</a><a data-href="#^3a21e4" href="#^3a21e4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.5)</a> with our mass term
The of a field who's excitations (waves) correspond to a particle with mass is Definition 1.5.2 (Klein Gordon Equation). It's good for the soul to prove some dirac delta identities
Andeen
If we have two real scalar fields , we can write the Lagrangian in one go<br>We then combine with the <a data-href="#^ea4a7d" href="#^ea4a7d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^ea4a7d</a><a data-href="#^ea4a7d" href="#^ea4a7d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.5.2 (Klein Gordon Equation)</a> to get two independent EL equations for two independent fieldsIf we have two particles with the same mass, we can profit now from this combination!
We get foreshadowing to particles and antiparticles! 1936 Anderson
We then describe a superposition of our two scalar fields as
<br><a data-href="../../../Math/Linear Algebra/1.9 The Matrix of a Linear Transformation#^25fe4c" href="school/math/linear-algebra/1.9-the-matrix-of-a-linear-transformation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/1.9 The Matrix of a Linear Transformation &gt; ^25fe4c</a><a data-href="../../../Math/Linear Algebra/1.9 The Matrix of a Linear Transformation#^25fe4c" href="school/math/linear-algebra/1.9-the-matrix-of-a-linear-transformation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.9.2 (Rotation Matrix)</a><br>
With we have as our mass term, which results in no change in the physics when plugged back into <a data-href="#^77c11a" href="#^77c11a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^77c11a</a><a data-href="#^77c11a" href="#^77c11a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.7)</a>. Nifty!
"Almost like there's some sort of invariance between a particle and antiparticle..."
We can express our 2 fields as just 1 complex scalar field with Then this gives us our EL's which can be solved separately, which I'll skip writing down, gives <br>A complex number is more than just a pair of real numbers though, there's an associated algebra to it. Why can we also introduce that algebra and be the same?
We have symmetry from <a data-href="#^59fe7d" href="#^59fe7d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^59fe7d</a><a data-href="#^59fe7d" href="#^59fe7d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.5.9)</a>, So then that gives us the complex numbers.
Example 1.5.3 (AT HOME: For , find the waves phase speed . The KG requires . Use this to determine ). What is Well this should be a scalar So I just take a derivative right... What is ?
For this we can raise it with the metric tensor and then work our way back like we did above What is What is ?
What is the group velocity go prove to self that ]]></description><link>school/physics/quantum-3/notes/1.5-klien-gordon.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.5 Klien Gordon.md</guid><pubDate>Thu, 29 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.11 Fault-Tolerant Computation]]></title><description><![CDATA[We wrapped up math behind error-correction, and introduced the idea of fault-tolerant qubits. Additionally, we broadly talked about quantum hardware!All errors can be reduced to a bit-flip, a phase-flip, or both a bit-flip and phase flip.
One qubit can behave like two classical bits. Error correcting codes subsequently have to be more complicated. Shor gate this first example of a detecting and correcting code.<img alt="../../../../../Supplemental Files/images/Pasted image 20241205140850.png" src="supplemental-files/images/pasted-image-20241205140850.png" target="_self">
We need explicit circuits for how to encode a qubit, and how to decode it.Why do I need to do a literal measurement over a CNOT? (I did ask this in FRI, but I think there wasn't good time to get into it)
In the real world, all the extra syndrome qubits are also evolving their own error. By keeping everything it's a bit like how the qubits are in a superposition of being in a superposition of an error or not. By measuring, we force nature to make up it's mind. This forces the hand of nature. Quote
A man calls 911 and says "Help! I think my friend is dead!"
The operator says "Okay, first make sure he's really dead."
BANG
The man gets back on the phone and says "Okay, now what?"
This code represented into the explosion of a whole new world of theory.
We went from 9-qubits-&gt;7 qubits -&gt; 5-QubitsPeople learned how to generalize this, and give quantum analogs for just about anything. We can design codes to protect against multiple errors and everything using stabilizers.How would I then CNOT a logical qubit? Do I just put the node on the original physical qubit?A big question is "How can we implement a quantum computer which implements the identity operator"With classical computers, back in the 1950's there were people saying that classical computers were never going to get big.
This talk provoked John Von-Neumann into proving a theoremTheorem 2.11.1 (Von Neumann (1950): You can build an arbitrary reliable circuit from unreliable AND,OR,NOT gates as long as:). the failure probabilities are independent
Below some constant failure probability The easiest solution is just having a repetition code with a majority vote But to compute the majority of different bits, then I need a circuit! You might just keep making things worse and worse. While that tree does look exponential, he also proved that the overhead to correct bits, then We want our physical error rate to be below this linear trend. We want it to be a net win to physically correct. VonNeumann showed that this function is actually a non-linear function!
Tragically, right after this we got the transistor which basically never fails. Then the field came to a screeching halt. This is what gets us Quantum Fault-Tolerance! This was an incredibly fast jump.Theorem 2.11.2 (Threshold Theorem Aharanov &amp; Ben-Or 1996 , Zurek,...). s.t can do an arbitrary reliable quantum computation, even if at every qubit, at every time needed to apply one gate (time-step), suffers from independent noise . Assume you can perform measurements in the middle of the computation and react to them We can perform extremely fast, errorless classical computation This in particular is a bit of a challenge! The quantum-errors happen in nanoseconds We have plenty of fresh qubits that we can utilize. Used in the event that we need to throw something out We can perform parallel operations Meaning I can perform gates on all the qubits at the same time. This is needed because we're assuming errors can happen everywhere in parallel What all of this mean thermodynamically, is that our quantum-computer is now an open system which generates heat. "If nature was a demon, and went HMM I wanna pick 1% of errors to screw with, that kills this" No one knows how to do QC fault tolerance in the face of correlated noise Gil Kalai is a famous mathematician who insists that the independence of errors is a damming assumption. 5 years ago, Google implemented a circuit Aaronson and his student proposed in 2011.
They applied 1000 random gates to those 50, then measured. They did a bunch of shots.
using a classical supercomputer, you can calculate what the probability of any output should have been.
Whoops a few years later, people improved the classical algorithm and denied it
This is a two-sided fight, quantum did it too Tragically, we did make a claim that we found something supremacy, but to prove it we need unlimited memory. Without it, we'd need years, which means we can't actually prove it.
The most useful thing we learned from the Google experiment, was thanks to the independence of errors. Because every gate is subject to constant noise, the final state should be close to the maximally mixed state . The data then gives us a density matrix ofWith enough shots, you can recover In Google's original experiment, . 99% of their stuff was garbageWhat Google found was that (Where ) is the number of gates. The error is proportional to the number of gates! This means the errors are independent, and building a quantum computer is just an engineering challenge.What does need to be for error correction to kick in<br>When <a data-href="#^c3d22b" href="#^c3d22b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^c3d22b</a><a data-href="#^c3d22b" href="#^c3d22b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.11.2 (Threshold Theorem Aharanov &amp; Ben-Or 1996 , Zurek,...)</a> was originally proved, they assumed that the gates were only 99.9999% accurate (TECHNICALLY A CONSTANT)
2 ways to fix this:
Hardware When Google did this experiment, they got their gates up to 99.5% fidelity.
This year, Google, QUera, and Quantinium was that they reached 99.9% fidelity Error Correcting 99.9999% 99.99% 99.9%
(We brought this number down by coping with less rigor)
Which means we met in the middle! Google, Microsoft, and blah blah are now all investing billions is that these numbers have finally collided. A few months ago, Google did an experiment with 103 qubits and a few thousand gates. As they increased the size of the code-word, and the code-distance, the logical qubit stays alive for longer and longer. Going to a bigger code survives for longer. This implies that error was going down! By some remarks, Google has made the first error-correcting qubit.I'm getting a journalist calling me everyday and I'm like "yeah it's good!"Internally their definition of a logical qubit is if they can do operations on it, which means an error rate of .Pr. Shankar at ECE teaches a whole graduate course on quantum computing hardware. A bunch of companies are hedging their bets in different places, with no obvious winner
Superconducting qubits basically use currents in superposition of two directions. The chips themselves are filled with relatively huge qubits. The chip looks like a normal chip, with wires feeding into classical control electronics Each qubit can do a 2-qubit operation on it's neighbor. The advantage is that they are fast as hell, and they can use standard fabrication techniques
Disad; Qubits are fixed in place
How would I go about doing a non-local operation if you can only work with neighbors?
You'd have to use CSWAP on each qubit along the road Well then how do you get parallelism if every qubit needs to be subsequently teleported
With a lot of difficulty and layers Fixed ion Computing : Literally atomically sixed with Ytterbium nuclei, and you're manipulating their spin. Moving them close to each other has a Columb interaction you can use to engineer a gate This is incredibly slow (1000x slower than superconducting), but you can move the qubits around (Quantinium, IonQ) Neutral Atoms : QuEra, Atom Computing (Up to 400 qubits)
Photonics: PsiQuantum (#1 billion in venture capital, but they did no demos), Xandu So they're shooting for the moon without like, any intermediate
Photons have incredibly good coherence. The issue is getting two photons to interact. Do they not need to worry about error correctipn then?
Their measurements then entangle two photons, but doing their measurements then induce errors. Aaronson doesn't see any clear winner, but there might be some approaches with a very high startup cost that we're only just now seeing people start spending. ]]></description><link>school/physics/qis/notes/2.11-fault-tolerant-computation.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.11 Fault-Tolerant Computation.md</guid><pubDate>Thu, 05 Dec 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.3 Index Acrobatics]]></title><description><![CDATA[Box problem solutions are at smwviewer.pomona.edu
Password on the canvas page
it's only accessible at a certain time
Chapter 4 reading is due Thursday
Homework problems due next Monday are posted today
Shoutout Kristina for asking that we have the HW problems given before that so we can be ready for office hours
Our favorite theory of interactions is QED, which describes the interactions between electrons, positrons, () and photons The question is how to use the tools given to calculate this. We want to calculate an amplitude for QM, which needs to be probabilistic.
Our goal is to find the amplitude for processes that takes a state from the initial to the final In QFT, we're doing this by calculating a power series expansion in terms of our constant for the amplitude The tool we're using to do this is a Feynman diagram
In Feynman diagrams, time goes up, they're great pictures but calculation tools. The power series part of this comes from the number of vertices inside our diagram. Inside QED, there always has to be two electrons and one photon line. Each vertex gives you an accumulated value of Exercise 1.3.1 (Come up with the rest of the 4 vertex Feynman diagrams based on Figure 1.1c in the text). I'm realizing that there's really just any possible combination of these diagrams. There's more than I put down
Is there a good way to know the maximum quantity of diagrams before we set out to draw them?
Nope, entirely dependent on the problem
Most of the time in our class we'll stop at the two vertex diagrams for sanity's sakeWhen someone produces high energy particles to irradiate tumors in a child for example, you'd also need to describe them relativistically. We need a QM description of relativistic particles.The way we're gonna add relativity to this is that for relativity we are using:
The laws of physics can be derived from symmetry principles Today we're using the principle of Relativity from Lorentz Invariance
This chapter is essentially wind sprints. Practicing scales, it's trying to build up these tools
One tool is a <a data-tooltip-position="top" aria-label="1.2 Special Relativity > ^0d82c4" data-href="1.2 Special Relativity#^0d82c4" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^0d82c4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">four vector</a><a data-tooltip-position="top" aria-label="1.2 Special Relativity > ^0d82c4" data-href="1.2 Special Relativity#^0d82c4" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^0d82c4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">four vector</a> introduced before. A tensor is an object with components that transforms in a specific special way using the <a data-tooltip-position="top" aria-label="1.2 Special Relativity > ^609e19" data-href="1.2 Special Relativity#^609e19" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^609e19" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">LT</a><a data-tooltip-position="top" aria-label="1.2 Special Relativity > ^609e19" data-href="1.2 Special Relativity#^609e19" href="school/physics/quantum-3/notes/1.2-special-relativity.html#^609e19" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">LT</a>.
This matrix form is unwieldily and we can improve, so index notation Definition (Index Notation). where is a four vector
The Lorentz transformation where is the row and is the column (Ex: = )
A LT is described as Which comes from the dot product operation between the rows when doing matrix multiplication for the four vector.
The notation then comes from the fact that because is a free variable, The sum is implied! We also have the Metric TensorDefinition 1.3.2 (Metric Tensor ).
We're looking at cartesian space, tells me where the minus signs go ]]></description><link>school/physics/quantum-3/notes/1.3-index-acrobatics.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.3 Index Acrobatics.md</guid><pubDate>Tue, 20 Jan 2026 00:00:00 GMT</pubDate><enclosure url="https://imgs.xkcd.com/comics/2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://imgs.xkcd.com/comics/2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.3 Core Coordination]]></title><description><![CDATA[Today we're talking through the code that he gave us todayHe'll always warn us about bugs if they're there We need to find a way to coordinate the activity of cores somehow.
Lets say we have a global variable, and two parallel activities with accessThe question becomes what are the possible values of x after this finishes
This becomes1ld x14, x2add x14, x14, 13st x14, xIf another core is doing the same thing, it's refering to a different x141ld x14', x2add x14', x14', 13st x14', xWe don't know how those instructions will show up in real time. All we know is that per core, instructions maintain the illusion of sequential instruction processing <a data-tooltip-position="top" aria-label="../../CS 429/Notes/11.4 SEQ to PIPE-" data-href="../../CS 429/Notes/11.4 SEQ to PIPE-" href="school/cs/cs-429/notes/11.4-seq-to-pipe-.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">11.4 SEQ to PIPE-</a><a data-tooltip-position="top" aria-label="../../CS 429/Notes/11.4 SEQ to PIPE-" data-href="../../CS 429/Notes/11.4 SEQ to PIPE-" href="school/cs/cs-429/notes/11.4-seq-to-pipe-.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">11.4 SEQ to PIPE-</a>. There's a sequential dependency between the load and the add instructions. Nothing we can do should change that. Notice that there's no dependency arrows between both of the cores. Nothing says that one instruction has to be run before or after another between cores.
Because of this lack of explicit dependency, nothing has promised that our cores executed. When a program is nondeterministic, it generates an "answer set". In this case, it's . IFWe do promise that if the are "naturally aligned". we will only get one or the other possible answersx86 has an accumulator style instruction set, so many instructions only have two operands.
By having a simpler command logic for x86, we just shift the command logic to the fetch and decode cycle, as it's now way more complicated for them, where in ARM it's spelled out. We can add prefixes to instructions in x86, one called the lock prefix. When you do that, you ask the hardware to do this instruction atomically. This guarantees that only that instruction is run atomically. How the fuck do you decode a variable length instruction? It's just hardware at that point How do I know if. feature is apart of a compiler directive?The most obvious choice for in our higher language flagging our code, is a flag (maybe a bool). 1int x = ...;2bool b_is_busy = false;Then when someone is accessing x, we stop it.
While x_is_busy, we do nothing (that's called spinning). The process will have some trouble with a branch predictor though. The branch predictors IRL are smart, and it'll aggressively keep predicting that we keep taking the while loop.
revving. Always put stuckinaloop if we're stuck in a loop and waiting for a process to finishOur race condition switches from being on x to being on the flag, as now the flag is the shared resource. We need something more fundamental<br>There is a software implementation to enable mutual exclusion, called the <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Peterson's_algorithm" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Peterson's_algorithm" target="_self">Peterson algorithm</a>
In his code, we replace the while(bool) code, he has an atomic exchange instruction. atomic_exchange(&amp;x_is_busy,true) basically says that if we have some memory, there is a value sitting in memory. In the core is another value. This method will atomically swap the two elements. Now thanks to atomic exchange we're safe! Won't going out to memory slow down our current core, and thus make us slip out of phase?
We don't mind that here since we have locking functional!
This pattern where1while(_atomic_exchange(&amp;var_is_busy,true)){2	stuckInaLoop3	}4x=x+1;5x_is_busy = false;C++ has a nice thing where we get "zero cost" abstractions. At runtime all this overhead disappearsCan we reference our old MM Lab implementation for this assignment?There's a lot of good information out there, and a lot more bad information
On the memory bus, there used to be exactly one wire on it called "lock". in 1981 if you're doing a load or just an add, if you put the atomic prefix in front of it, one core would set hte lock line on a 1. Then any other core would look at the lockline and if it was 1, it would not access any memory until the line was zero.The answer to how the modern system works is related to how caches are structured. We want to keep our L1's separate, because their efficiency is associated to how tightly connected it is to the core
A write-through won't save us here, early on this is what stopped people from having multiprocessors and shared memories. Caches were thought to be the death of multiprocessing.
The solution is to have a cache coherence protocol.
Some way of building the system so we don't allow the caches to disagree with each other. This is what gets implemented in personal computing systems.
The solution is a snoopy busBut what makes the snoopy bus faster? Well we want to minimize the number of messages communicated over the channel.
We also need to filter traffic and only sent the bare minimum needed to send. That means we have to keep more state within the cache. This is the MSI protocol. Each cache block can be in 1 of three states within a cache. We check if the block is in the modified state, or the invalid state When two people are reading x, they will see it's in the shared state
Below is a line by line diagram for how the snoopy bus works!But then how do we add atomicity? One of the ways to achieve this, is to introduce another state, called the a state for atomicStick volatile in front of variables that I think will be shared, but are not atomic. ]]></description><link>school/cs/cs-439/notes/1.3-core-coordination.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.3 Core Coordination.md</guid><pubDate>Tue, 20 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 Special Relativity]]></title><description><![CDATA[Today we introduced the fundamentals of special relativity, and associated equations governing it's motion. The first HW assignments are now due Monday in the middle of the night (Yay ?). We get the whole weekend to take the shot at it. The book's trying to get us to actively read
I should probably expect about an hour there
I wanted to ask about how you form a bound state with your own anti-particle in a meson.
The box problems are 1 for trying and minimal effort. 2 is for good effort. There's no correctness points
We're gonna look at 3 box problems in class and work on in groups
In the future the box problems are due at 9am Monday so that he has enough time before class to look over the stuff
The homeworks are about the same effort as the box problems ("less tedious but more comprehensive"-Connie the LA)The good news is that for a particle physicist. even at the highest energies we can collide a particle, is that we're a long long way from GR coming up There's really one good way of doing this, and not very many other waysExercise 1.1.1 (Box 1.1 in the text:What is the smallest increment of energy you can add to the E field which you can add to a box with length .2). The wavelength is We went over the above box problem in class!<a data-tooltip-position="top" aria-label="https://arxiv.org/pdf/1808.02927v1" rel="noopener nofollow" class="external-link is-unresolved" href="https://arxiv.org/pdf/1808.02927v1" target="_self">Particle physics began with the observation of cosmic rays by Hess. Everyone thought that radiation came from the earth, so seeing more radiation as you increased altitude was huge!</a> The title of this paper is hilarious: On the Observations of the Penetrating Radiation during Seven Balloon Flights
A lot of people died in balloon experiments (That was cutting edge)
Definition 1.2.1 (Principle of Relativity).
The laws of physics are the same in all inertial reference frames
Definition 1.2.2 (Inertial Reference Frame).
One in which a free object moves at a constant velocity
The relationship between quantities
When things are the same, that's an example of a symmetry. Oh no natural unitsDefinition 1.2.3 (Natural Units).
Setting (Making them unitless), and combining our distance, energy, time, and charge units. The base unit is thus GeV
Distances becomes , time also becomes We like energy as our base unit because it's conserved.
Intrinsic scales allow us to make better approximations when we try to compare our results to experiment.Why is it okay to say they're all 1?
They're all constants. We made the speed of light the way it was because we live on Earth and wanted to relate it to that. Do we lose the usefulness of dimensional analysis
No! It becomes more useful as we'll see in the below problem
Exercise 1.2.4 (Box 2.2).
We want to calculate the Planc energy, which is the energy where we need to take into account the energy of gravitational interactions 1import numpy as np 2matrix = np.array([3 [3,2,1],4 [-1,1,0],5[-2,1,-1]6]7)8joules = [2,1,2]9# invert U and times j10U_inv = np.linalg.inv(matrix)11solution = (U_inv@joules)12print(solution)Run
This gives us an expression of does this really answer my question, because we had distinct units for each constant in here
Ultra high energy cosmic rays clear this threshold so that's why we study them so hard! Exercise 1.2.5 (Box 2.7).
We're now taking Newtonin momentum is not conserved in GR. Conserve 4 momentumcan we just talk about 4-momentum for all momenta?
No! In a lot of QM you use 3 momentum. The trick is figuring out which to use when
We use Lorentz Transformations in relativity to determine how our positions evolve in different reference frames.
Consider 2 inertial framesWe describe this as "boosting" the reference frame by Definition 1.2.6 (Lorentz transformation).
A principle of relativity gives us the Lorentz Transformation (LT), which describes the relations between the 4-vectors of an object in two reference frames ( and ) The transformationality of is the velocity, in natural units as . Then we have as The LT matrix mentioned above is a special case for a boost in . There is a box problem which walks us through his as to why it looks the way it looks. (I think it's Box 2.3)The LT is a system of linear equationsFrom this we can find the spacetime interval . That is the separation between two events.Why is time positive in this relation? Like, not just that it acts different to spaceWe also define a Proper timeDefinition 1.2.7 (Proper Time ).
The time experienced or felt by an observer "riding" with the particle. We then use this for velocity!Definition 1.2.8 (Four vector).
Any 4 component quantity, whose components transform according to the LT's for an inertial frame
A dot product for a a four vector ]]></description><link>school/physics/quantum-3/notes/1.2-special-relativity.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.2 Special Relativity.md</guid><pubDate>Thu, 15 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 C++ Intro and Code from an OS]]></title><description><![CDATA[Today we're walking through how code works for operating systems in our classWe don't need to memorize what he's gonna show us, it'll be posted in ed. All the code we look at will also be shared with us directly.
I wish he'd have given it to us earlier so I could annotate it tho
gheith/work/cs439_s26_pi{eid} is the naming scheme the Github usually usesWe all have our own dedicated repositories which he hosts, and it automatically runs the tests. We can push as many times as we want, and it'll auto-compile and report back the results to us
This is cool!
I think it's cool he hosts his own git repos too
When we submit, our tests run on everybody's tests. The tests are not secret, and we can look at them on a separate repo (unless there's like a really possible specific case where you could bypass a test)We need to compile with the C++ compiler, but it's evolving. Lots of compilers exist, some have bugs some have extensions, and we are running in a bizzare environment where there's no standard environment and we're restricted on features. We want to be running the same copy of the compilerThe compiler on the cs machines is ancient (8 years old) and lacks features that we'd want to use. This means we'd need to use the copy of the compiler that he uses
To do that, we need to add his compiler to the PATH! Which is a great chance for us to learn about the PATH.
The shell will reference the PATH for commands that it doesn't recognize.
Is the command he's giving us only going to persist for the current session? Yeah, but you can just add this to the .profile or .bashrc
$PATH is for executables
It is wise to only add things to the PATH when I'm running my assignments. If I put it in my ,profile, I'd forget to remove things for it. I'd be stuck still picking this c++ compiler, so it could be picky
LD_LIBRARY_PATH is for shared libraries
We are using C++23
PATH = ~geith/public/tools26/bin:**$PATH**
We're building an operating system kernel, you want to be running directly on the hardware so we need a machine without an operating system. He doesn't want to give us one, and even if we bought a raspberry pi to do it we won't be able to debug.
We're running our code in an emulator. The emulator is so good we might forget that it's close enough to the hardware. But it's not perfect, and there are moments when the emulator differs from real hardware. Either in function or performance. He will point out to us where the emulator fails
If we find ourself stuck in a loop waiting for something to change (bad idea because you have wasted cycles) then there's a function called imstuckinaloopThe emulator is just qemu-system-x86_64. With arm it's also easy but it's aarch64How does this emulator even...work?How does QEMU not just step on the operating system's toes while it works?The outcome inside qemu should be identical to hardware To bootstrap, we need to compile a kernel first. And we don't have a filesystem yet. The main entry point to the kernel is going to be the test cases we're running. The kernel will come up, run the test case, and go down. Later we will run a loader which will prevent it from going down. The kernel directory is what we really care about
The build directory is where all the outputs go
The limine folder is the boot loader we're going to be using. We don't need to even look at this code. He will tell us exactly what we need to know about it as we go
The tools subfolder we don't care about at all
The root of the project has a bunch of interesting files. The important ones for us are the test files. The root will have tests.
Our test are going to be a function kind of like main, but called kernel_main. That's the entrypoint into the program. This is not the first thing that gets called. For our concern, this is the beginning. Any logic we want goes in there.
He will give us code, and give us some tests. Ignore the tests he gives us at first. Copy them into another file named after your eid (any .cc file gets interpreted as a test), then start form fresh. The test cases in here would be the best for implementing features
He does have a makefile running in there, we don't have to look in it but it will help to just see how the system is being done. In our current implementation we have to build a unique kernel for each test we use.
The two important files for us are the .kernel
​(kernel executable)
Editing and viewing ti aren't very useful, but there are tools we can learn to take a peek into them
You can use the dflag with objdump and convert it to a disassembler (The far left will say the value of the PC at which that command runs) the object dump will let us see what part of the file we failed on via the PC!The image file built is the most important. It's a disk image for us to run QEMU on. This is cool, the makefile builds our image. Wait so how did we do this?
Oh wait he shows us! I won't type it out all here, he said "I cannot type this code myself". He put a comment with a citation
sgdisk is a command line tool which does disk partitioning! That's actually very useful cause going to every computer and having to find something with an interface is a huge pain. "You don't need to memorize any of this, it'll be common code."Once we have the image file, we're ready to hang the file to the emulator "Hey you! Pretend to be a computer connected to a disk which contains this stuff!"
To do this, he gave us a shell script which saves us time on this ./run_qemu {testcaseName}. This runs make on our behalf. Debugging can be helped by reducing the optimization flag
The 3 stars will indicate lines which should be considered as part of the output and thus be graded so we can do debugging.
Printing with SAY(..) means that output will be detected for correctness
Printing with kprint will make our output not be recognized for correctness
is there a way to make it so that our program only runs once despite the number of cores?
Well, we haven't invented threads yet. To have parallelism
When things aren't working, it's a good idea to set the number of cores to 1 to identify if we have a concurrency issue. he made it so SAY runs in the critical section. Say will break parallelism but maintain concurrency. Things will try to run in parallelism if you don't stop them.Wait how do I stop someone else from running a path of code at the same time?KPANIC is like kprint, you're giving up, and it prints an error message and then shuts down the system. It doesn't run in a critical section. How do I tell the other cores that they can't run SAY
There's a mutual exclusion policyu. The fact that I'm speaking stops others from speaing. There are mechanisms for doing that. One is called a "spin lock". That's a flag. If it's false, you're welcome to go, if it's true you can't. But what if we hit the flag at the same time? Race condition! We want that operation to be "atomic". Meaning, it's indivisible. We want to have an operation that says "check the value and set it to one without anyone interfering with me". Architectures have ways to do this. "change in x96" does this. By carefully using atomic operations, you can implement those critical sections. He has a file called atomic.h full of nice C++ classes, one is called "spin-lock": which gives us a way to sue those mechanisms. You don't want to think about this in every line of code, most of the time you're not sharing anything with anyone. It's only when you do any sharing do you need to do any managing. We only have one format string : ?. The compiler can then figure that al out at compile time.
As a note though, the kernel will only want to print hex inside SAY. To have it print in decimal, wrap your number in the function Dec(num).What happens with a counter though? WAIT WAIT WAIT BUZZ I KNOW THIS
<a data-href="../../../Physics/Misc/CoDaS HEP/Parallel Programming with OpenMP" href="school/physics/misc/codas-hep/parallel-programming-with-openmp.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Physics/Misc/CoDaS HEP/Parallel Programming with OpenMP</a><a data-href="../../../Physics/Misc/CoDaS HEP/Parallel Programming with OpenMP" href="school/physics/misc/codas-hep/parallel-programming-with-openmp.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../../Physics/Misc/CoDaS HEP/Parallel Programming with OpenMP</a>
How do we make a splitting between the cores so that they access different points of a datastructure without false sharign?
We will invent the core identity so that the cores become aware of themselves
<br>For simple operations,<a data-tooltip-position="top" aria-label="https://en.cppreference.com/w/cpp/atomic/atomic.html" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.cppreference.com/w/cpp/atomic/atomic.html" target="_self"> we don't really need a lock.</a> The way we expose the variable in our world to be atomic in it's operations, is that we declare it as being atomic.1int count=0;2Atomic&lt;int&gt; count{0};Notice that above we're working with generic types, atomicity works with any types.It's different in lots of ways than it behaves in C.
We're basically telling the compiler to reserve some space in the global memory access. Because we're trying to access something shared, when that occurs we want to temporarily break parallelism. Try and break parallelism for as little time as possible. We're always better off not using anything Atomic at all. If you use a lock, the spin lock is sitting in a lop trying to access the variable which isn't great, but next week will invent a better kind of lock.We still haven't gotten things to print out in the correct order though. This is the use of the spin lock. We want to combine the incrementing of the value, with printing it. The spin lock fixes the printing conflict, the atomic fixes the segmentation fault from the simultaneous access. In our case, we can abandon atomic.
We instantiate an object of a spinlock, lock the lock, increment the count, and unlock the lock. Idealty we don't nest locking though. That can lead to all sorts of bad scenarios, including a deadlock. Example 1.2.1 (Deadlock).
I'm holding lock A, and you're holding lock B. You want to get A, you want to get B. Well now no one can get anything. It'll never end
If i want things to be different baed on the different internal ID, does the parallelism need to be broken for the entirety I need to reference that core ID?
Yes! The easier way to work around that is to implement a switch. That way parallelism is broken for as little as possible The kernel needs to have a heap, so he will give us an incomplete heap implementation. It will have malloc, but not have free. The reason he's givign us that is two-fold:
The heap is magical, and he wants us to see how the heap is realized and comes form
We only have one heap, but we have four cores competing for the heap, so they can't malloc or free at the same time. We need to somehow sort that out. Probably a spin-lock, but it's about finding the right place.
Then just write your own test case
make -s will make things quieter
To check if your test case passed, each test case has their own 'ok' file which is the correct output (for the things with stars in front of them)
testname.cc is code
testname.ok is the correct output
BOTH OF THE ABOVE NEED TO BE MADE ONCE BY ME AS I WRITE
testname.out is the output to see if it was correct
testname.raw is the raw output with all the debug information, not just the ones with stars
testname.time tells you how long it took to run. (The grading system looks at this to see how long it takes to run and all of that) While we're doing this, we should run qemu. The boot loader is driven by a config file, which tells the boot loader what to do. That config file sits in the root directory. Most of the time we have no need to change it.
If you're debugging and want to experiment with different kernels, we can edit that in the config file! That would be convenient.
Once the boot loader starts running, to tries to load the kernel executable into memory, it needs to have an entrypoint.
That is the system_main.cc file, it is the entrypoint. There's exactly one core running at this point. This is a boot loader dictated rule. You need to nudge them to make them wake up. At the beginning, the system is completely uninitialized. If you cal malloc before initializing the heap, all bets are off. The core before malloc is carefully written to avoid calling malloc. (Line 82 of system_main.cc)After that, the global constructors. If you have any global variable with a constructor, you put it in the chunks line 88. Strategically placed after initializing the heap (because those constructors might use the heap). ]]></description><link>school/cs/cs-439/notes/1.2-c++-intro-and-code-from-an-os.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.2 C++ Intro and Code from an OS.md</guid><pubDate>Thu, 15 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.1 Overview]]></title><description><![CDATA[We did a general discussion of the field we're covering in the course along with some box problems<img alt="../../../../Supplemental Files/images/Pasted image 20260113114654.png" src="supplemental-files/images/pasted-image-20260113114654.png" target="_self">
Its an open question on why theres exactly 3 generations of quarks and leptons, why there's two heavier copies. That's WILD<br>
<img alt="../../../../Supplemental Files/images/Pasted image 20260113115220.png" src="supplemental-files/images/pasted-image-20260113115220.png" target="_self"><br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Sterile_neutrino" target="_self">https://en.wikipedia.org/wiki/Sterile_neutrino</a>TOP QUARKS HAVE THE MASS OF A GOLD ATOM?? WHAT
"We're pretty sure it gets it's mass from the higgs mechanism"
Cool asf<br>Wait are 's and 's both composed of the same fundamental particles? How are they distinct? The table on the screen seemed to suggest that they were bound states of up and down quarks with their antiparticles.
<a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Rho_meson" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Rho_meson" target="_self">"The rho mesons can be interpreted[3] as a bound state of a quark and an anti-quark and is an excited version of the pion"</a> A Unified framework that describes the matter and interactions of particles
Two Parts: "Fundamental" particles (in quotes because that's as far as we know)
The Interactions (Forces) Does not describe gravity SM is based on Relativistic Quantum Mechanics (#QFT)
There's two parts from here: Non relativistic Quantum mechanics (Quantum 1) In relativistic quantum mechanics, we had stable particles! This is not the case IRL. Relativistic QM (This class): We can create and Destroy particles
QFT All particles are "excitations" of a field
Examples:
For EML photons are the quantized excitation of the EM field
Electrons are the quantized excitations of the electron field (really clever naming y'all)
Interactions - How the fields interact
Examples
The electrons + EM fields are interactions are described by QED (We do this first)
Includes a term in the field's energy density () which depends on the below information Any time where the fields are non-zero, there is an extra energy density beyond what each field brings individually. That's what a particle is!
<br><a data-href="../../Quantum 2/Notes/1.6 Fine Structure in the Hydrogen Atom" href="school/physics/quantum-2/notes/1.6-fine-structure-in-the-hydrogen-atom.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 2/Notes/1.6 Fine Structure in the Hydrogen Atom</a><a data-href="../../Quantum 2/Notes/1.6 Fine Structure in the Hydrogen Atom" href="school/physics/quantum-2/notes/1.6-fine-structure-in-the-hydrogen-atom.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../Quantum 2/Notes/1.6 Fine Structure in the Hydrogen Atom</a>
Exercise 1.1.1 (Box 1.1 in the text:What is the smallest increment of energy you can add to the E field which you can add to a box with length .2). The wavelength is Exercise 1.1.2 (Box 1.2). Exercise 1.1.3 (Box 1.3 Why is the proton stable?).
The color based interactions win out in terms of speed. We're told "Color interactions only rearrange quarks and/or create or destroy quarks"
Exercise 1.1.4 (box 1.4 Two torques are 0).
We know already taht as they are an action adn response ]]></description><link>school/physics/quantum-3/notes/1.1-overview.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/1.1 Overview.md</guid><pubDate>Tue, 13 Jan 2026 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.1 What is an Operating System]]></title><description><![CDATA[We answered the title question, and roadmapped our time in the course!Caching is such a big deal, adn we're going to continuously reinvent caches perpetually. The L1 and L2's existence doesn't matter much to us because the hardware takes care of it.
We're recalling how a system worksWe're not calling the CPU a CPU. The C comes from a time when the CPU was singular. We're going to drop the term. It's not descriptive anymore. We're calling it a core
<a data-href="../../CS 429/Notes/11.4 SEQ to PIPE-" href="school/cs/cs-429/notes/11.4-seq-to-pipe-.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../CS 429/Notes/11.4 SEQ to PIPE-</a><a data-href="../../CS 429/Notes/11.4 SEQ to PIPE-" href="school/cs/cs-429/notes/11.4-seq-to-pipe-.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../CS 429/Notes/11.4 SEQ to PIPE-</a>
When we design a system, their cores are hardware resources. They might not all be active concurrently, so two might sit idle or be off. The multitude gives us OPTIONS
<br>We want to have the registers interior to the core to run very fast, so we keep it at a small number. The multiplexers and decoders become shallower as well so we only have to wait a cycle or two for register access. Those have the <a data-tooltip-position="top" aria-label="../../CS 429/Notes/7.1 Operands and Data Processing > Register Operands" data-href="../../CS 429/Notes/7.1 Operands and Data Processing#Register Operands" href="school/cs/cs-429/notes/7.1-operands-and-data-processing.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">program counter</a><a data-tooltip-position="top" aria-label="../../CS 429/Notes/7.1 Operands and Data Processing > Register Operands" data-href="../../CS 429/Notes/7.1 Operands and Data Processing#Register Operands" href="school/cs/cs-429/notes/7.1-operands-and-data-processing.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">program counter</a>
Each core has it's own caches, and we never ever share caches.
We try to have all of our information in our cache within the same layer. Ideally we never have to leave the chip adn enteer the outside world to the DRAM. This asks the question about hwo we resolve access inconsistencies. This is the cache coherence problemDefinition 1.1.1 (The Cache Coherence Problem).
If two caches are accessing the same value at the same time, how do we keep track of the order?
CoreCaches and all thatSystem Busregsall running in parallelL1L1L1L1Cache Coherence Bus
We do this via the cache coherence bus, which typically works so well that we never realy need to worry about this beyond the loss of parallelism
<br>The coherence bus will be accessed first, and our given core asks <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Bus_snooping" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Bus_snooping" target="_self">if any other cache has the value of our register before going out to the memory controller. </a>
<br><a data-href="../../CS 429/Notes/13.4 Cache Structure and Management" href="school/cs/cs-429/notes/13.4-cache-structure-and-management.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../CS 429/Notes/13.4 Cache Structure and Management</a><a data-href="../../CS 429/Notes/13.4 Cache Structure and Management" href="school/cs/cs-429/notes/13.4-cache-structure-and-management.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../CS 429/Notes/13.4 Cache Structure and Management</a> <a data-href="../../CS 429/Notes/13.3 Structure of Caches" href="school/cs/cs-429/notes/13.3-structure-of-caches.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../CS 429/Notes/13.3 Structure of Caches</a><a data-href="../../CS 429/Notes/13.3 Structure of Caches" href="school/cs/cs-429/notes/13.3-structure-of-caches.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../CS 429/Notes/13.3 Structure of Caches</a>
Parts of our address spaces are I/O devices feeding information to a location in memory
Inside the IO space, there are places where writing will run a speaker, change a screen, move a motor, etc.
The bridge will handle figuring out if a specific memory address is memory or an IO address!ROM is a piece of memory with some bits, put in by whoever designed the system, which are non-volatile. There is fixed data burned into the system.The PCI-E bus is slower than DRAM. As we move further away from the CPU, the slower things get. You can basically rotate the above diagram 90˚ and guess about the speeds.Your USB lanes are sharing the lanes with your mouse and keyboard and all other things. A portable hard drive has write speeds then constrained by that bus's usage. That's why direct drives are more expensive, they manage dedicated lanes. Why did we never have to think of these things? The operating system managed it!
Asking someone to program to this model would let us have three programers basically. We've abstracted everything away to be handled by the OS
We need something that makes this complicated thing simpler, and safer.
Simpler: Managing sectors is beyond the programmer, they just want to open a file
Error handling: Someone was shaking the ground next to the disk, and the head might miss a line on a hard drive.
Operating systems are what manage these complexities which keep them convenient and safe
Definition 1.1.2 (Operating System).
Operating systems do the following: Abstraction: Makes the complex management of hardware, simple. Makes different things seem like the same. Plugging a disk via USB or NVME should look the same to the user. Keyboards should all act the same
Make things up! A disk doesn't have a hierarchal namespace, only a linear array of addresses. The operating system is what manages the file structures. Resource Management Allocating loads to cores proportionally, multiplexing resources, etc. Give the perception to the user that when a program is run in memory, it's a process Protection There's nothing a process can do which effects another one, the illusion of isolation of state needs to be maintained Communicate Sometimes we want to be able to share data to a concurrent process or stream to multiple processes. This is an OS from the point of view to the programs.
The other perspective, which is provided to humans, is the UX. It's the GUI
We are completely ignoring the user experience of an operating system. That's only the last 3 weeks except for the last 3 weeks.
The nature of an operating system is strictly software. The OS is the thing which makes it convenient for programs to run, but the OS itself is a program. The OS has to deal with every complexity to manage the other programs. It takes the burden of the hard problems, so no one else has to. We're going to specifically prevent ourselves from using exceptions in C++! Exceptions need OS's to workWhen you try and run it, the program gets it's own space in memory, allocates it's resources, and then starts running it.
A program becomes a process by loading it in memory, initializing that memory, and pointing the PC at that point to run. The OS does that!
The operating system needs to get memory, and then tell it to run it to the right point. This is the bootstrapping problem. There has to be something magical acting at the early operating system point which loads the operating system to memory.
This is the firmware! (It's not hard, it's not soft, it's firm)
It has to be the thing that no one has to write it in memory, which is on a ROM! The ROM is the firmware's home. Whoever manufactured the system, and went into memory to put the firmware down.
Typically we will use flash memory for this, with NOR flash so it's byte addressable.
The oldest kind of firmware is the BIOS. The BIOS does some self checks, and once it's happy with the hardware it loads the OS.Then it scans the disks, and scans the disks to see if there's anything that looks to be an operating system.
How does it know what an operating system looks like? It doesn't! It just needs something in the memory to say "I have an operating system in me". It can lieWe think about a disk as an array of swectorsAbove is an example of what it looks like for us to tell the BIOS that there is a BIOS present in memoryIf any sector 0 contains an MBR, we say that it is what knows how to run an OS.
What if multiple claim to have an OS?
Used to be undefined, but now we give people a menu
If the last two bytes in the first sector are FF, AA, then we interpret it as an MBR. What if your disk has that byte-string by accident? Sucks, don't do that.
Then the remaining 510 bytes is the operating system512 BFFAARAM0x7C00
Now we jump to this address at 0x7C00 and the operating system has been loaded into the BIOS. You better fit your operating system in 510 bytes. We're bootstrapping the system slowly, that stuff will load slowly, that stuff will load more stuff, etc etc until we have a full system. Putting your OS on a disk means that you better put 510 bytes that know how to load in the rest of your system.
At this point, we need to look inside the filesystems of the disks to find the operating systems. The stage 1 thing loads the boot-loader over the operating system directly.
The boot-loader does the harder stuff, scanning the disk and finding all the operating systems which are possible to use in the disk. This software is more complicated.The bootloader we will use is called LimineThe first thing loaded from the bootloader is our KERNEL. That is the heart of any operating system
By the time we get to the Kernel, it's running by itself and the other two processes are killedIn order, the system starts and runs the memory in ROM. That is the BIOS. That then searches disks for the MBB based on the FF AA criteria. The 510 bytes above the 0xFFAA are responsible for loading your bootloader. Then the bootloader searches for operating systems.
HWBIOSS.WStage 1BootloaderKernelLimine0xffff800000Kernel SpaceUser SpaceMusicEmailssh....BrowserLPDCritical System ProcessesOS
There has to be someone who finds the system (because it's written to do this), it goes "Im the first program to be started like this here, the other processes are dead, I am responsible for this land"
The kernel sits there going "What is my job in life"
we can try to multiplex between programs so that they aren't al in the CPU A subset is running in actual parallel at a given time defined by the number of cores we have. So how did single core systems have an OS? Don't we need to keep it always running if it manages the programs?
At some point the kernel might realize it's not needed software, as it's an interface without someone using it. The kernel then loads the first program into memoryBut then at one point we might want a GUI, so those are actually implemented as user processes.
Our class will spend the bulk of our time in the kernel. It is the most important part of the operating system, but it is not the whole thing. We will spend so much time on the kernel the others might be forgotten.For next time walk through the linker]]></description><link>school/cs/cs-439/notes/1.1-what-is-an-operating-system.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.1 What is an Operating System.md</guid><pubDate>Tue, 13 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2D Discussion Section Week 1]]></title><description><![CDATA[There's a cool<a data-tooltip-position="top" aria-label="https://www.cs.utexas.edu/~gheith/cs439_s25_p1.html" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.cs.utexas.edu/~gheith/cs439_s25_p1.html" target="_self"> reference matrix</a> which shows us how well we're doing on texts
Just because we're passing on the matrix doesn't mean we're race condition free. The concrete way to confirm if it works is to run it locally a large quantity of timeIdeally pass as many test cases as much as possible
By the testcase deadline, we need to be passing at least t0 or some existing testcase thresholdgdb with multiple cores running is a nightmare apparently, and will sometimes induce bugs that are gdb specific. Print statement debugging will be helpful in this class. If you don't exit gdb when you are done, the process will be kept alive and I can't Volatile operations come from a flaw in compiler optimization, where sequential instructions with the same value are cached before going back to storing.
The issue is that if I have multiple cores, not sending the value back frequently might make it so that it has mutated since, but the parallelism is overwritten by each core. One core might pull an earlier instance of a variable with no work yet done on it
He says this is a common thing as a bug so to watch out for it
Core speeds are non-deterministic
The volatile keyword will introduce those extra load and store commands to entire that our cores sync more often
As a code example
1#include &lt;stdio.h&gt;2int main() {3int hi = 4;4 hi++;5 hi--;6}The above compiles to1main:2 movs r0, #03 bx lrCompare this to volatile, which keeps the loads and stores1#include &lt;stdio.h&gt;2int main() {3volatile int hi = 4;4 hi++;5 hi--;6}71main:2 sub sp, sp, #83 movs r3, #44 str r3, [sp, #4]5 ldr r3, [sp, #4]6 adds r3, r3, #17 str r3, [sp, #4]8 ldr r3, [sp, #4]9 subs r3, r3, #110 str r3, [sp, #4]11 movs r0, #012 add sp, sp, #813 bx lrThis still won't solve all the problems. To fix it, we require a stronger condition. Think about it as an atomic operation which guarantees that our operations happen without any interruptions. Atomics make sure that nothing else is capable of in parallel executing an operation on a given point in data.
You're still not protected from atomics happening in different atomics happening out of order. You're only promised it will be executed eventually and not parallel.
Atomics don't block normal operations, they block other atomic operations.
Atomics have a max size they can operate on, so it wont work for massive data structures. It's a 64bit max, so you'd need to break up the data structure. uint64 is a good default datatype. A lot like generics in Java which lets me parametrically define variables passed into a data structure. The lab machine error thing with make test is not my fault but the one im using]]></description><link>school/cs/cs-439/notes/1.2d-discussion-section-week-1.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/1.2D Discussion Section Week 1.md</guid><pubDate>Fri, 16 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Syllabus is <a data-tooltip-position="top" aria-label="../Class Official Files/syllabus_s26_439.pdf" data-href="../Class Official Files/syllabus_s26_439.pdf" href="school/cs/cs-439/class-official-files/syllabus_s26_439.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Official Files/syllabus_s26_439.pdf" data-href="../Class Official Files/syllabus_s26_439.pdf" href="school/cs/cs-439/class-official-files/syllabus_s26_439.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a>Unix for the impatient (Book rec from Daniel)
He's aiming for 10 programming assignments. They are done individually, until we hit the final project where we form groups and do stuff together
We're basically building an OS kernel. If you don't do well in one assignment, you'll build on it.
We will have different milestones. At some point he'll give us almost working code. To clarify, the twist is to make sure we just debug? That way no one is left behind, but he says it's at most a week.
There are no slip days.
No exams, but you have quizzes every two weeks. They tend to take half of the discussion sections
You can suggest quiz questions (oh so we're tricking people)
If someone needs the optional final, it's available to them which everyone works on togetherHe wants us to type out any code we get suggested.
We're responsible for everything we submit, including explaining to any detail. He can just randomly ask us for an interview which is within 24 hours. That's not like, if you just did your work it's if he suspects. So I should be okay cause I don't plagiarize my shit. Like my main concern was like, what if i was busy cause my schedule is dense
First assignment due next week
Read the textbook
Never ask him what chapter we're on right nowThis class will be incredibly programming heavy, and it'll be in a specific style. Do we have a style guide you want us to adhere to?
All I care about is that your code is sane
We're programming in C++, so it's C with another things. "It's really C with java thingies thrown in"]]></description><link>school/cs/cs-439/notes/0.1-introduction.html</link><guid isPermaLink="false">School/CS/CS 439/Notes/0.1 Introduction.md</guid><pubDate>Tue, 13 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.10 Complexity and Error Correcting]]></title><description><![CDATA[We covered relevant complexity classes in quantum information, and ran through several open questions regarding them. Additionally, we introduced and derived Shor's 9-qubit codeDefinition 2.10.1 (Ladner's theorem).
If , then there are problems which exist that aren't in either
No one has shown how to base modern encryption on an NP complete problemTheorem 2.10.2 (Valiant-Vazerani Theorem).
If you can guarantee that a given boolean function has at least one satisfying answer, then there exists some randomized solving algorithm for it. At the same time, it's still computationally hard regardless If , and factoring , then Factoring which is a huge question.
We don't know if there are NP-Complete problems which are in .A big open question is : "What is the relationship between and ?"BBBV theorem says that if , then it can't be black box. You can't just make a total superposition over states. It has to be more tailored than that.
Theorem 2.9.1 (Bennet, Bernstein, Brassord, Vazirani (1994) - BBBV). For the problem of black box searching for an unordered list of elements, Grover's algorithm is optimal. queries needed
<a data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 What Else can Shor do, and Grover &gt; ^f2faf4</a><a data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.7.12 (Grover's Algorithm (1996))</a> Quantum simulation is something we know to be in , not is not known to be in .
Bernstain Vazerani proved that . Definition 2.10.3 (PSPACE).
A complexity class, which contains the set of all algorithms that run with a polynomial amount of memory
No one has proven Do we also have ? Yep, but Uses of QC
Quantum Simulation (Actually positive for the world)
Breaking Current Public Key encryption (Good for like nobody)
Grover Speedups (Which need to hold up against the error correcting issues) More?
Are we talking about query complexity in ?
We are. You can throw Grover at an NP complete problem to help constrain your search space, then run through your existing classical algorithm
A few different name-drops on cool new quantum algorithms
<br><a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Adiabatic_quantum_computation" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Adiabatic_quantum_computation" target="_self">Adiabatic Algorithms</a>
<br><a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/HHL_algorithm" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/HHL_algorithm" target="_self">HHL Algorithm </a>
<br><a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2204.02063" rel="noopener nofollow" class="external-link is-unresolved" href="https://arxiv.org/abs/2204.02063" target="_self">Algorithm</a> who's significance is still being determined
There is now a huge financial incentive to blow the hype up about this to anything. QC looks like analog since amplitudes are continuous. Doesn't it inherit the error issues from analog computing?
Decoherence is rough - How do you isolate these from the entire classical world to prevent it from being measured
Imagine you have a Schrödinger state If even one qubit leaks into the environment, the whole state collapses
<br><a data-href="1.5 The Coin Problem and Cloning#^eaca57" href="school/physics/qis/notes/1.5-the-coin-problem-and-cloning.html#^eaca57" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.5 The Coin Problem and Cloning &gt; ^eaca57</a><a data-href="1.5 The Coin Problem and Cloning#^eaca57" href="school/physics/qis/notes/1.5-the-coin-problem-and-cloning.html#^eaca57" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.5.1 (No Cloning Theorem)</a> 💀 HOW DO I COPY AND PASTE (without entanglement) BRO?? This answers all those given objections, but how do we design error correcting codes
To correct bits, you need of themStarting with classical error correction:
Easy way to look at this uses a cubeDefinition 2.10.4 (Hamming Cube).
Below is the example for a 3 bit repetition code. You can prove that with only 1 error, if your start points are , then the verticies that are one unit away, are disjointed And now with quantum error correction, let's try the 3 qubit codeWell this is easy to correct with some network of Toffoli's. (See quantum computing notes)But then how do we even detect phase flips?? already has a local phase that we don't know.We can design a different code just to do this.
There is an infinity of possible errors, how can we protect from this??Theorem 2.10.5 (Shor 1995).
It is sufficient to detect bit-flips and phase flips (Pauli ). If we can, then everything else is handled
Let's implement this, say that that with , an error happens to the first qubitThese 3 states span the whole subspace of states you could get from by acting on just the first qubit. Any error can be a linear combination of these.Exercise 2.10.6 (AT HOME: Prove this is the subpace).
The easiest trick is to show some linear combinations give you the pure extraction of the components. Then you can show linearly combining those is mixing and matching your error
This also works with mixed states, since that's a combination of pure states. That means this also handles measurement!Combine the bit-flip error correcting code, with the phase code.We can see how we're protected from a bit-flip error. And then to correct from a phase-flip error you just check the other two bits.]]></description><link>school/physics/qis/notes/2.10-complexity-and-error-correcting.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.10 Complexity and Error Correcting.md</guid><pubDate>Tue, 03 Dec 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Syllabus is here
Textbook is <a data-tooltip-position="top" aria-label="../Class Official Files/A Standard Model Workbook -- Thomas Andrew Moore -- 1, 2023 -- University Science Books -- 9781940380179 -- a793be7f995ee01e1119c1af22f98d18 -- Anna’s Archive.pdf" data-href="../Class Official Files/A Standard Model Workbook -- Thomas Andrew Moore -- 1, 2023 -- University Science Books -- 9781940380179 -- a793be7f995ee01e1119c1af22f98d18 -- Anna’s Archive.pdf" href="school/physics/quantum-3/class-official-files/a-standard-model-workbook-thomas-andrew-moore-1,-2023-university-science-books-9781940380179-a793be7f995ee01e1119c1af22f98d18-anna’s-archive.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Official Files/A Standard Model Workbook -- Thomas Andrew Moore -- 1, 2023 -- University Science Books -- 9781940380179 -- a793be7f995ee01e1119c1af22f98d18 -- Anna’s Archive.pdf" data-href="../Class Official Files/A Standard Model Workbook -- Thomas Andrew Moore -- 1, 2023 -- University Science Books -- 9781940380179 -- a793be7f995ee01e1119c1af22f98d18 -- Anna’s Archive.pdf" href="school/physics/quantum-3/class-official-files/a-standard-model-workbook-thomas-andrew-moore-1,-2023-university-science-books-9781940380179-a793be7f995ee01e1119c1af22f98d18-anna’s-archive.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a> Particles, Fields and The Standard ModelDalton is our entirely remote TA, in St. Paul Minnesota
He's got office hours and does our grading
We also have an undergrad LA: Connie
Class is recorded and we can listen to the lectures online
Good news bad news
Good news: He's a particle physicist
Bad News: He" really loves the material" (?)
Office hours 10.208 (his office) 2-3 PM Wednesday
We have homework due this SundayEach time we meet, there is a reading assignment. They are short, and it's basically like statmech
Reading the textbook in advance is highly recommended by him (and required)
The chapters have box problems for exercises to engage you. We're starting with a few today in class
Those exercises are due before class.
The first assignment is due Thursday at 11am
They should only take about 20 min. It's really a participation grade
Those are called "Box Problems"
Then after the homework comes back, we get the solutions For box problems, we look at the solutions and make the understanding (which them poof)
For homework we can make corrections in a different color.
Any way we want to upload to canvas for the assignment. On the corrections we should have the changes in a different color (so maybe version control)
Our end goal is the Higgs mechanism and electroweak unification. What about BYSM
We're building a strong foundation in one semester to try and get us to a point where we can do that We're guaranteed 70% ground floor of the homework if we do correctionsMidterm is a few weeks before spring break
Final exam is Saturday morning at 8am (he might try to change that cause no one wants that)<br>I can't seem to access the syllabus <a data-tooltip-position="top" aria-label="https://utexas.app.box.com/s/3tms0qnesd0k10u03lpcmbqdj92b3mcj" rel="noopener nofollow" class="external-link is-unresolved" href="https://utexas.app.box.com/s/3tms0qnesd0k10u03lpcmbqdj92b3mcj" target="_self">Box</a> link
Contents
Slides get posted, he'll try to post as much as he can. ]]></description><link>school/physics/quantum-3/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Quantum 3/Notes/0.1 Introduction.md</guid><pubDate>Tue, 13 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Syllabus linked <a data-tooltip-position="top" aria-label="../Class Official Files/sp25-qec (1).pdf" data-href="../Class Official Files/sp25-qec (1).pdf" href="school/physics/quantum-error-correction/class-official-files/sp25-qec-(1).html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Official Files/sp25-qec (1).pdf" data-href="../Class Official Files/sp25-qec (1).pdf" href="school/physics/quantum-error-correction/class-official-files/sp25-qec-(1).html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a>
Textbook linked here, it's ust Mike and IkeFirst day of class is gonna be short!
Office hours are by appointment to meet about anything
We're gonna start with intro quantum for the first few weeks, but we'll ramp up after the first few weeks
(This is like, a good thing for my physical health tbh)
The last month or so is doing paper review so that we can better understand the material
We aren't centering on theory papers all that much
It's not related to programming a QC. Perf
This year there will be more homeworks (about once every two weeks). No exams
Doesn't record lecture
I shoudl also look into what office to email about the concussion in case I need accommodations
he wants to find a balance between understanding the theory, but not being so separated that I can't talk it through
We do some numerical HPC (High performance computing), which I can look into for Aaronson.
We do a lot of simulation in this class
David Gottesman's class text is what we're aiming for
There will be a project: two parts. Everyone does the same thing, revolving around simulting ECC's. Then we take that tool we built and propose a new direction to use it on. Perf I can use this for the IS.If we're doing other QEC work can we use that for the final project
Try and do somethign enw for the cass, but don't make it an additional huge workload for yourself
List of Topics (Briefly):
Math Basics (e.g. Groups, Fields, Vector Spaces) Information Theory (e.g. Channels, Noise, Entropy, Channel Capacity) Classical Error Correction (Linear Codes, Generators, Parity Checks) Probabilistic vs. Quantum Computing
Basics of Quantum Systems (Qubits, Observables, Measurements) Error In Quantum Systems (Uniquely Quantum Error channels, representations) Quantum Error Correcting Codes (Stabilizers, Generators, From Classical Codes) Topological Codes qLDPC Codes (Maybe) Systems Topics (Decoding, Architecture, Program Synthesis)
Welcome to work in groups if we want!
Project details are not flushed out]]></description><link>school/physics/quantum-error-correction/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Quantum Error Correction/Notes/0.1 Introduction.md</guid><pubDate>Mon, 12 Jan 2026 00:00:00 GMT</pubDate></item><item><title><![CDATA[5.2 Bosons and Fermions]]></title><description><![CDATA[Cutoff to exam is till 7.2 Possible states are everything, but if fermion except where the two balls are in the same bin
The "quantum volume" is the thermal De Broglie wavelength, cubed.
We can calculate the average number of particles in a state byOr via the <a data-href="5.1 Quantum Statistics#^749626" href="school/physics/statistical-mechanics/notes/5.1-quantum-statistics.html#^749626" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">5.1 Quantum Statistics &gt; ^749626</a><a data-href="5.1 Quantum Statistics#^749626" href="school/physics/statistical-mechanics/notes/5.1-quantum-statistics.html#^749626" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5.1.2 (The Grand Partition Function)</a>
For any number of particles, we'd sum up the individual partition functions for bosons f
For the ermions, we can just take the ratios for the partition functions (since exlclusion kicks in)Fermion is plus 1, minus 1 is boson, zero is the classical case.
The general form for the expected number of particles isTheorem 5.2.1 (The Expected Number of Particles in a Given Energy State). Well why can we treat the electron gas as non-interacting? We made that assumption implicitly?
Well for electrons, we typically assume they're free electrons in a metal lattice with positive charge. On average at any point the charge is zero, so to a first approximation we can say it's accurate
You can setup a system very carefully which conserves the photon number (i thin cat qubits do this right? With their like pairity preservation thingWhat is the utility of modeling photons in an oven as a gas OH HEY IF YOU APPLY THE BOSONIC DISTRIBUTION STUFF, WE CAN MODEL THE PLANK DISTRIBUTION WHICH HELPS US FIND THE DISTRIBUTION OF ENERGIES
]]></description><link>school/physics/statistical-mechanics/notes/5.2-bosons-and-fermions.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/5.2 Bosons and Fermions.md</guid><pubDate>Fri, 05 Dec 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[Boolean Operations]]></title><description><![CDATA[<img src="supplemental-files/excalidraw/scripts/downloaded/boolean-operations.svg" target="_self">]]></description><link>supplemental-files/excalidraw/scripts/downloaded/boolean-operations.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Scripts/Downloaded/Boolean Operations.svg</guid><pubDate>Fri, 05 Dec 2025 22:19:57 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Boolean Operations]]></title><description><![CDATA[/*
With This Script it is possible to make boolean Operations on Shapes.
The style of the resulting shape will be the style of the highest ranking Element that was used.
The ranking of the elements is based on their background. The "denser" the background, the higher the ranking (the order of backgroundstyles is shown below). If they have the same background the opacity will decide. If thats also the same its decided by the order they were created.
The ranking is also important for the difference operation, so a transparent object for example will cut a hole into a solid object.
<img src="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-boolean-operations-showcase.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"><br>
<img src="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-boolean-operations-element-ranking.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">See documentation for more details:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://zsviczian.github.io/obsidian-excalidraw-plugin/ExcalidrawScriptsEngine.html" target="_self">https://zsviczian.github.io/obsidian-excalidraw-plugin/ExcalidrawScriptsEngine.html</a>*/
if(!ea.verifyMinimumPluginVersion || !ea.verifyMinimumPluginVersion("1.9.20")) { new Notice("This script requires a newer version of Excalidraw. Please install the latest version."); return;
}
const ShadowGroupMarker = "ShadowCloneOf-"; const elements = ea.getViewSelectedElements().filter( el=&gt;["ellipse", "rectangle", "diamond"].includes(el.type) || el.groupIds.some(id =&gt; id.startsWith(ShadowGroupMarker)) || (["line", "arrow"].includes(el.type) &amp;&amp; el.roundness === null)
);
if(elements.length &lt; 2) { new Notice ("Select ellipses, rectangles, diamonds; or lines and arrows with sharp edges"); return;
} const PolyBool = ea.getPolyBool();
const polyboolAction = await utils.suggester(["union (a + b)", "intersect (a &amp;&amp; b)", "difference (a - b)", "reversed difference (b - a)", "xor"], [ PolyBool.union, PolyBool.intersect, PolyBool.difference, PolyBool.differenceRev, PolyBool.xor
], "What would you like todo with the object"); const shadowClones = elements.filter(element =&gt; element.groupIds.some(id =&gt; id.startsWith(ShadowGroupMarker)));
shadowClones.forEach(shadowClone =&gt; { let parentId = shadowClone.groupIds .filter(id =&gt; id.startsWith(ShadowGroupMarker))[0] .slice(ShadowGroupMarker.length); const shadowCloneIndex = elements.findIndex(element =&gt; element.id == parentId); if (shadowCloneIndex == -1) return; elements[shadowCloneIndex].backgroundColor = shadowClone.backgroundColor; elements[shadowCloneIndex].fillStyle = shadowClone.fillStyle;
})
const borderElements = elements.filter(element =&gt; !element.groupIds.some(id =&gt; id.startsWith(ShadowGroupMarker)));
groups = ea.getMaximumGroups(borderElements);
groups = groups.map((group) =&gt; group.sort((a, b) =&gt; RankElement(b) - RankElement(a)));
groups.sort((a, b) =&gt; RankElement(b[0]) - RankElement(a[0])); ea.style.strokeColor = groups[0][0].strokeColor;
ea.style.backgroundColor = groups[0][0].backgroundColor;
ea.style.fillStyle = groups[0][0].fillStyle;
ea.style.strokeWidth = groups[0][0].strokeWidth;
ea.style.strokeStyle = groups[0][0].strokeStyle;
ea.style.roughness = groups[0][0].roughness;
ea.style.opacity = groups[0][0].opacity; const basePolygons = groups.shift().map(element =&gt; traceElement(element));
const toolPolygons = groups.flatMap(group =&gt; group.map(element =&gt; traceElement(element))); const result = polyboolAction({ regions: basePolygons, inverted: false
}, { regions: toolPolygons, inverted: false
});
const polygonHierachy = subordinateInnerPolygons(result.regions);
drawPolygonHierachy(polygonHierachy);
ea.deleteViewElements(elements);
setPolygonTrue();
ea.addElementsToView(false,false,true);
return; function setPolygonTrue() { ea.getElements().filter(el=&gt;el.type==="line").forEach(el =&gt; { el.polygon = true; });
} function traceElement(element) { const diamondPath = (diamond) =&gt; [ SxVEC(1/2, [0, diamond.height]), SxVEC(1/2, [diamond.width, 0]), addVec([SxVEC(1/2, [0, diamond.height]), ([diamond.width, 0])]), addVec([SxVEC(1/2, [diamond.width, 0]), ([0, diamond.height])]), SxVEC(1/2, [0, diamond.height]) ]; const rectanglePath = (rectangle) =&gt; [ [0,0], [0, rectangle.height], [rectangle.width, rectangle.height], [rectangle.width, 0], [0, 0] ] const ellipsePath = (ellipse) =&gt; { const angle = ellipse.angle; const width = ellipse.width; const height = ellipse.height; const ellipseAtPoint = (t) =&gt; { const spanningVector = [width/2*Math.cos(t), height/2*Math.sin(t)]; const baseVector = [width/2, height/2]; return addVec([spanningVector, baseVector]); } let points = []; step = (2*Math.PI)/64 for (let t = 0; t &lt; 2*Math.PI; t = t + step) { points.push(ellipseAtPoint(t)); } return points; } let polygon; let correctForPolygon = [0, 0]; switch (element.type) { case "diamond": polygon = diamondPath(element); break; case "rectangle": polygon = rectanglePath(element); break; case "ellipse": polygon = ellipsePath(element); break; case "line": case "arrow": if (element.angle != 0) { let smallestX = 0; let smallestY = 0; element.points.forEach(point =&gt; { if (point[0] &lt; smallestX) smallestX = point[0]; if (point[1] &lt; smallestY) smallestY = point[1]; }); polygon = element.points.map(point =&gt; { return [ point[0] -= smallestX, point[1] -= smallestY ]; }); correctForPolygon = [smallestX, smallestY]; break; } if (element.roundness) { new Notice("This script does not work with curved lines or arrows yet!"); return []; } polygon = element.points; default: break; } if (element.angle == 0) return polygon.map(v =&gt; addVec([v, [element.x, element.y]])); polygon = polygon.map(v =&gt; addVec([v, SxVEC(-1/2, [element.width, element.height])])); polygon = rotateVectorsByAngle(polygon, element.angle); return polygon.map(v =&gt; addVec([v, [element.x, element.y], SxVEC(1/2, [element.width, element.height]), correctForPolygon]));
} function RankElement(element) { let score = 0; const backgroundRank = [ "dashed", "none", "hachure", "zigzag", "zigzag-line", "cross-hatch", "solid" ] score += (backgroundRank.findIndex((fillStyle) =&gt; fillStyle == element.fillStyle) + 1) * 10; if (element.backgroundColor == "transparent") score -= 100; if (element.points &amp;&amp; getVectorLength(element.points[element.points.length - 1]) &gt; 8) score -= 100; if (score &lt; 0) score = 0; score += element.opacity / 100; return score;
} function drawPolygonHierachy(polygonHierachy) { const backgroundColor = ea.style.backgroundColor; const strokeColor = ea.style.strokeColor; const setInnerStyle = () =&gt; { ea.style.backgroundColor = backgroundColor; ea.style.strokeColor = "transparent"; } const setBorderStyle = () =&gt; { ea.style.backgroundColor = "transparent"; ea.style.strokeColor = strokeColor; } const setFilledStyle = () =&gt; { ea.style.backgroundColor = backgroundColor; ea.style.strokeColor = strokeColor; } polygonHierachy.forEach(polygon =&gt; { setFilledStyle(); let path = polygon.path; path.push(polygon.path[0]); if (polygon.innerPolygons.length === 0) { ea.addLine(path); return; } const outerBorder = path; const innerPolygons = addInnerPolygons(polygon.innerPolygons); path = path.concat(innerPolygons.backgroundPath); path.push(polygon.path[0]); setInnerStyle(); const backgroundId = ea.addLine(path); setBorderStyle(); const outerBorderId = ea.addLine(outerBorder) const innerBorderIds = innerPolygons.borderPaths.map(path =&gt; ea.addLine(path)); const allIds = [innerBorderIds, outerBorderId, backgroundId].flat(); ea.addToGroup(allIds); const background = ea.getElement(backgroundId); background.groupIds.push(ShadowGroupMarker + outerBorderId); });
} function addInnerPolygons(polygonHierachy) { let firstPath = []; let secondPath = []; let borderPaths = []; polygonHierachy.forEach(polygon =&gt; { let path = polygon.path; path.push(polygon.path[0]); borderPaths.push(path); firstPath = firstPath.concat(path); secondPath.push(polygon.path[0]); drawPolygonHierachy(polygon.innerPolygons); }); return { backgroundPath: firstPath.concat(secondPath.reverse()), borderPaths: borderPaths };
} function subordinateInnerPolygons(polygons) { const polygonObjectPrototype = (polygon) =&gt; { return { path: polygon, innerPolygons: [] }; } const insertPolygonIntoHierachy = (polygon, hierarchy) =&gt; { for (let i = 0; i &lt; hierarchy.length; i++) { const polygonObject = hierarchy[i]; let inside = null; let pointIndex = 0; do { inside = pointInPolygon(polygon[pointIndex], polygonObject.path); pointIndex++ } while (inside === null); if (inside) { hierarchy[i].innerPolygons = insertPolygonIntoHierachy(polygon, hierarchy[i].innerPolygons); return hierarchy; } } polygon = polygonObjectPrototype(polygon); for (let i = 0; i &lt; hierarchy.length; i++) { const polygonObject = hierarchy[i]; let inside = null; let pointIndex = 0; do { inside = pointInPolygon(polygonObject.path[pointIndex], polygon.path); pointIndex++ } while (inside === null); if (inside) { polygon.innerPolygons.push(hierarchy.splice(i, 1)[0]); i--; } } hierarchy.push(polygon); return hierarchy; } let polygonHierachy = []; polygons.forEach(polygon =&gt; { polygonHierachy = insertPolygonIntoHierachy(polygon, polygonHierachy); }) return polygonHierachy;
} /** * Checks if the given point lays in the polygon * @param point array [x, y] * @param polygon array [[x, y], ...] * @returns true if inside, false if not, null if the point is on one of the polygons vertecies */
function pointInPolygon(point, polygon) { const x = point[0]; const y = point[1]; let inside = false; // odd even test if point is in polygon for (let i = 0, j = polygon.length - 1; i &lt; polygon.length; j = i++) { const xi = polygon[i][0]; const yi = polygon[i][1]; const xj = polygon[j][0]; const yj = polygon[j][1]; const intersect = yi &gt; y !== yj &gt; y &amp;&amp; x &lt; ((xj - xi) * (y - yi)) / (yj - yi) + xi; if (intersect) { inside = !inside; } if ((x === xi &amp;&amp; y === yi) || (x === xj &amp;&amp; y === yj)) { return null; } } return inside;
} function getVectorLength(vector) { return Math.sqrt(vector[0]**2+vector[1]**2);
} /** * Adds two Vectors together */
function addVec(vectors) { return vectors.reduce((acc, vec) =&gt; [acc[0] + vec[0], acc[1] + vec[1]], [0, 0]);
} /** * Returns the negative of the vector */
function negVec(vector) { return [-vector[0], -vector[1]];
} /** * Multiplies Vector with a scalar */
function SxVEC(scalar, vector) { return [vector[0] * scalar, vector[1] * scalar];
} function rotateVector (vec, ang) { var cos = Math.cos(ang); var sin = Math.sin(ang); return [vec[0] * cos - vec[1] * sin, vec[0] * sin + vec[1] * cos];
} function rotateVectorsByAngle(vectors, angle) { const cosAngle = Math.cos(angle); const sinAngle = Math.sin(angle); const rotationMatrix = [ [cosAngle, -sinAngle], [sinAngle, cosAngle] ]; return applyTranformationMatrix(vectors, rotationMatrix);
} function applyTranformationMatrix(vectors, transformationMatrix) { const result = []; for (const vector of vectors) { const x = vector[0]; const y = vector[1]; const newX = transformationMatrix[0][0] * x + transformationMatrix[0][1] * y; const newY = transformationMatrix[1][0] * x + transformationMatrix[1][1] * y; result.push([newX, newY]); } return result;
} ]]></description><link>supplemental-files/excalidraw/scripts/downloaded/boolean-operations.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Scripts/Downloaded/Boolean Operations.md</guid><pubDate>Fri, 05 Dec 2025 22:19:57 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-boolean-operations-showcase.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-boolean-operations-showcase.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Box Each Selected Groups]]></title><description><![CDATA[<img src="supplemental-files/excalidraw/scripts/downloaded/box-each-selected-groups.svg" target="_self">]]></description><link>supplemental-files/excalidraw/scripts/downloaded/box-each-selected-groups.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Scripts/Downloaded/Box Each Selected Groups.svg</guid><pubDate>Fri, 05 Dec 2025 22:18:55 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Box Each Selected Groups]]></title><description><![CDATA[/*
<img src="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-download-raw.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved">Download this file and save to your Obsidian Vault including the first line, or open it in "Raw" and copy the entire contents to Obsidian.<br><img src="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-box-each-selected-groups.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">This script will add encapsulating boxes around each of the currently selected groups in Excalidraw.You can focus on content creation first, and then batch add consistent style boxes to each group of text.Tips 1: You can copy the desired style to the global state using script Copy Selected Element Style to Global, then add boxes with the same global style using script Box Each Selected Groups.Tips 2: Next you can use scripts Expand rectangles horizontally keep text centered and Expand rectangles vertically keep text centered to make the boxes the same size, if you wish.Tips 3: If you want the left and right margins to be different from the top and bottom margins, input something like 32,16, this will create a box with left and right margins of 32 and top and bottom margins of 16.See documentation for more details:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://zsviczian.github.io/obsidian-excalidraw-plugin/ExcalidrawScriptsEngine.html" target="_self">https://zsviczian.github.io/obsidian-excalidraw-plugin/ExcalidrawScriptsEngine.html</a>*/
if(!ea.verifyMinimumPluginVersion || !ea.verifyMinimumPluginVersion("1.5.21")) { new Notice("This script requires a newer version of Excalidraw. Please install the latest version."); return;
}
settings = ea.getScriptSettings();
//set default values on first run
if(!settings["Default padding"]) { settings = { "Prompt for padding?": true, "Default padding" : { value: 10, description: "Padding between the bounding box of the selected elements, and the box the script creates" }, "Remember last padding?": false }; ea.setScriptSettings(settings);
} let paddingStr = settings["Default padding"].value.toString();
const rememberLastPadding = settings["Remember last padding?"]; if(settings["Prompt for padding?"]) { paddingStr = await utils.inputPrompt("padding?","string",paddingStr);
}
if(!paddingStr) { return;
}
if(rememberLastPadding) { settings["Default padding"].value = paddingStr; ea.setScriptSettings(settings);
}
var paddingLR = 0;
var paddingTB = 0;
if(paddingStr.indexOf(',') &gt; 0) { const paddingParts = paddingStr.split(','); paddingLR = parseInt(paddingParts[0]); paddingTB = parseInt(paddingParts[1]);
}
else { paddingLR = paddingTB = parseInt(paddingStr);
} if(isNaN(paddingLR) || isNaN(paddingTB)) { return;
} const selectedElements = ea.getViewSelectedElements();
const groups = ea.getMaximumGroups(selectedElements);
const allIndividualArrows = ea.getMaximumGroups(ea.getViewElements()) .reduce((result, group) =&gt; (group.length === 1 &amp;&amp; (group[0].type === 'arrow' || group[0].type === 'line')) ? [...result, group[0]] : result, []);
for(const elements of groups) { if(elements.length === 1 &amp;&amp; elements[0].type ==="arrow" || elements[0].type==="line") { // individual arrows or lines are not affected continue; } const box = ea.getBoundingBox(elements); color = ea .getExcalidrawAPI() .getAppState() .currentItemStrokeColor; // use current stroke with and style const appState = ea.getExcalidrawAPI().getAppState(); const strokeWidth = appState.currentItemStrokeWidth; const strokeStyle = appState.currentItemStrokeStyle; const strokeSharpness = appState.currentItemStrokeSharpness; const roughness = appState.currentItemRoughness; const fillStyle = appState.currentItemFillStyle; const backgroundColor = appState.currentItemBackgroundColor; ea.style.strokeWidth = strokeWidth; ea.style.strokeStyle = strokeStyle; ea.style.strokeSharpness = strokeSharpness; ea.style.roughness = roughness; ea.style.fillStyle = fillStyle; ea.style.backgroundColor = backgroundColor; ea.style.strokeColor = color; const id = ea.addRect( box.topX - paddingLR, box.topY - paddingTB, box.width + 2*paddingLR, box.height + 2*paddingTB ); // Change the join point in the group to the new box const elementsWithBounded = elements.filter(el =&gt; (el.boundElements || []).length &gt; 0); const boundedElementsCollection = elementsWithBounded.reduce((result, el) =&gt; [...result, ...el.boundElements], []); for(const el of elementsWithBounded) { el.boundElements = []; } const newRect = ea.getElement(id); newRect.boundElements = boundedElementsCollection; const elementIds = elements.map(el =&gt; el.id); const startBindingLines = allIndividualArrows.filter(el =&gt; elementIds.includes((el.startBinding||{}).elementId)); for(startBindingLine of startBindingLines) { startBindingLine.startBinding.elementId = id; recalculateStartPointOfLine(startBindingLine, newRect); } const endBindingLines = allIndividualArrows.filter(el =&gt; elementIds.includes((el.endBinding||{}).elementId)); for(endBindingLine of endBindingLines) { endBindingLine.endBinding.elementId = id; recalculateEndPointOfLine(endBindingLine, newRect); } ea.copyViewElementsToEAforEditing(elements); ea.addToGroup([id].concat(elements.map((el)=&gt;el.id)));
} await ea.addElementsToView(false,false); function recalculateStartPointOfLine(line, el) { const aX = el.x + el.width/2; const bX = line.x + line.points[1][0]; const aY = el.y + el.height/2; const bY = line.y + line.points[1][1]; line.startBinding.gap = 8; line.startBinding.focus = 0; const intersectA = ea.intersectElementWithLine( el, [bX, bY], [aX, aY], line.startBinding.gap ); if(intersectA.length &gt; 0) { line.points[0] = [0, 0]; for(var i = 1; i&lt;line.points.length; i++) { line.points[i][0] -= intersectA[0][0] - line.x; line.points[i][1] -= intersectA[0][1] - line.y; } line.x = intersectA[0][0]; line.y = intersectA[0][1]; }
} function recalculateEndPointOfLine(line, el) { const aX = el.x + el.width/2; const bX = line.x + line.points[line.points.length-2][0]; const aY = el.y + el.height/2; const bY = line.y + line.points[line.points.length-2][1]; line.endBinding.gap = 8; line.endBinding.focus = 0; const intersectA = ea.intersectElementWithLine( el, [bX, bY], [aX, aY], line.endBinding.gap ); if(intersectA.length &gt; 0) { line.points[line.points.length - 1] = [intersectA[0][0] - line.x, intersectA[0][1] - line.y]; }
} ]]></description><link>supplemental-files/excalidraw/scripts/downloaded/box-each-selected-groups.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Scripts/Downloaded/Box Each Selected Groups.md</guid><pubDate>Fri, 05 Dec 2025 22:18:55 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-download-raw.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/zsviczian/obsidian-excalidraw-plugin/master/images/scripts-download-raw.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.11 Partition Functions and Free Energy in Composite Systems]]></title><description><![CDATA[Definition 2.2.1 (Sackur–Tetrode Equation).
This equation defines the energy associated in an ideal gas Midterm back Wednesday (Allhamdulilah)
Definition 1.13.1 (Von Neuman Entropy).
A measure of how much uncertainty there is in regarding which pure state that we have. It also can be used as a measure of entanglement between two particles. ]]></description><link>school/physics/statistical-mechanics/notes/4.11-partition-functions-and-free-energy-in-composite-systems.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.11 Partition Functions and Free Energy in Composite Systems.md</guid><pubDate>Mon, 01 Dec 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.3 Deutsch's Algorithm]]></title><description><![CDATA[Quantum operations are supposed to be Reversible
The same number of bits that go in, are the number of bits that leave.
We have both input and output qubits, and we delegate them at the beggining. Unlike digital systems, both the output and input qubits are physically preserved after an operation Quantum gates are reversible, because we preserve the number of information. Otherwise, we run into a <a href=".?query=tag:pigeonhole" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#pigeonhole">#pigeonhole</a> problem
Least significant qubit holds the inputs
A function from for qubits looks like
Which in Unitary form (which all functions must be):Where is the addition operator, denoted by or \oplus in latex.<br>
This is just the from the <a data-tooltip-position="top" aria-label="../Definitions/Quantum Gates" data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Quantum Gates</a><a data-tooltip-position="top" aria-label="../Definitions/Quantum Gates" data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Quantum Gates</a> We define any quantum function, as a truth table. Given an input, we return some-bit to with the output qubit () Definition 1.3.1 (Deutsch's Algorithm). Start out with Set output register to Apply Hadamard gates to all qubits
Apply another set of hadamards to all the qubits
Measure the input register
If the output is 0, the function is constant, otherwise it's balanced
Below is a table of the black-box of functions. Using the gates listed above, you'd make this diagram!<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240905163741.png" src="supplemental-files/images/pasted-image-20240905163741.png" target="_self">
Below is an implementation of the quantum protocol<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240905164620.png" src="supplemental-files/images/pasted-image-20240905164620.png" target="_self">
1print(.1+.2)]]></description><link>school/physics/quantum-computing/semester-2/1.3-deutsch's-algorithm.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/1.3 Deutsch's Algorithm.md</guid><pubDate>Thu, 05 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.10]]></title><link>school/physics/statistical-mechanics/notes/4.10.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.10.md</guid><pubDate>Mon, 17 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.9 Partition Function]]></title><description><![CDATA[For a given sequence we can produce a function which encodes this information through a taylor seriesThis is how you'd generate a distribution based on your moments! You get a sequence of them and taylor 'em.We can calculate the variance of our distribution through^618fd2
There's another generating functionwhich generates the variances from <a data-href="#^618fd2" href="#^618fd2" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^618fd2</a><a data-href="#^618fd2" href="#^618fd2" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^618fd2</a>!This shows us that in the thermodynamic limit, the relative size of the fluctuation goes to zero!Theorem 4.9.1 ("Fluctuation-Dissapation Relation"). ]]></description><link>school/physics/statistical-mechanics/notes/4.9-partition-function.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.9 Partition Function.md</guid><pubDate>Fri, 14 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.6 Canonical Ensemble]]></title><description><![CDATA[We can draw conclusions about the behavior of s system through the <a data-tooltip-position="top" aria-label="1.3 Kinetic Theory of Ideal Gasses > ^4b44bf" data-href="1.3 Kinetic Theory of Ideal Gasses#^4b44bf" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^4b44bf" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">principle of indifference</a><a data-tooltip-position="top" aria-label="1.3 Kinetic Theory of Ideal Gasses > ^4b44bf" data-href="1.3 Kinetic Theory of Ideal Gasses#^4b44bf" href="school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html#^4b44bf" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">principle of indifference</a>The temperature is The probability of system 1 and system 2 being at is Entropy is Let's say I have a room full of gas molecules, and I want to study the behavior of just one molecule, without knowing the micro-states of the whole room. Can use the temperature of the room to get information about one particle?
The large system (the room) is called the reservoir . We know that from the derivativeThe probability of a system 1 to be at energy is proportional to the number of micro-states in system 2.
For a given energy , if multiple states give the same energy, they are all equally probable.We want to find a way to use as little information as possible regarding system 2.We're going to do Givefrom earlier, we substitute that inThen define We want to understand as much information about system 1 as possible, with as little information about system 2.
This means thatTheorem 1.6.1 (Boltzman Factor - The probability of a subsystem at a given probability). 1import matplotlib.pyplot as plt2def boltzmanFactor(T, E = 1):3	kB = 14	return np.exp(-E/(kB*T))5temps = np.linspace(1,10,1000)6plt.plot(np.linspace(1,10,1000), boltzmanFactor(1,temps))7plt.grid()8plt.xlabel('Energy')9plt.ylabel('Probability')10plt.title('Boltzman Factor vs Energy')11plt.show()Run]]></description><link>school/physics/qis/modern-physics/notes/1.6-canonical-ensemble.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.6 Canonical Ensemble.md</guid><pubDate>Tue, 17 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.12 Born Oppenheimer 2]]></title><description><![CDATA[We're specializing to a diatomic molecule to save us from having to do a sum en masse through the nucleiWhen working in our system for the kinetic energy term, we can change our coordinate system to the COM.Where is the reduced mass (our mass within the COM frame of reference)This is the mass for in the homework problem
With this and our born Oppenheimer approximation, we get the equationThis just looks like our hydrogen atom wave-function but with a . This implies that we have our angular coordinatesUnlike the hydrogen atom, the energy didn't depend on the angular quantum numbers. Here though, it will because of the extra term in <a data-href="#^5c84c8" href="#^5c84c8" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^5c84c8</a><a data-href="#^5c84c8" href="#^5c84c8" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.12.3)</a>
This yields the following radial equationWAIT THE ENERGY BASED ON THIS IS THEN <br>AND LOOK! THAT'S WHICH IS MOMENT OF INERTIA! THIS IS LITERALLY FROM <a data-href="../../../../Personal/Tutoring/AP Physics/Session 41- Rotational Motion#^0251d6" href="personal/tutoring/ap-physics/session-41-rotational-motion.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../../Personal/Tutoring/AP Physics/Session 41- Rotational Motion &gt; ^0251d6</a><a data-href="../../../../Personal/Tutoring/AP Physics/Session 41- Rotational Motion#^0251d6" href="personal/tutoring/ap-physics/session-41-rotational-motion.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3 (Moment of Inertia The rotational equivalent of mass; a measure of an object's resistance to changes in its rotation.)</a> Wow this is kinetic energy. You can see that our rotational velocity term is supposed to be squared, is .Definition 2.12.1 (The Rotational Constant). <br>THIS IS HOW A <a href=".?query=tag:microwave" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#microwave">#microwave</a> WORKS! THE HIGHER VALUES OF states are when the molecule spins faster! The energies here fall in the microwave spectrum! To make the molecule spin faster, you give it more energy in photons.Can I use this to figure out the rotational energy level distance is for water?
Just model it as a diatomic molecule at the center of mass right?
We can vibrate inside the minimum of this energy potential, with different possible energy states! As we increase $j$, we can see that $\langle R \rangle$ is going to be larger
rovibrational- Has both rotational part and vibrational part<br>
The exact energy (Which includes <a data-href="#^735ef1" href="#^735ef1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^735ef1</a><a data-href="#^735ef1" href="#^735ef1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.12.6)</a> )Where from before! (There are two of them, one from morse potential and one from this energy). The first is the depth of the well (lowest point to asymptote)
We did it guys, Godel was right! Arithmetic is actually inconsistent
]]></description><link>school/physics/quantum-2/notes/2.12-born-oppenheimer-2.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.12 Born Oppenheimer 2.md</guid><pubDate>Fri, 04 Apr 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.5]]></title><description><![CDATA[Phase transformations of Pure Substances is what we talked aboutVapor Pressure equation comes from separation of variables to get]]></description><link>school/physics/statistical-mechanics/notes/4.5.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.5.md</guid><pubDate>Wed, 05 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.4]]></title><link>school/physics/statistical-mechanics/notes/4.4.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.4.md</guid><pubDate>Mon, 03 Nov 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[4.3 Free Energy]]></title><description><![CDATA[Energy versus entropy is a convex function, which means that we can do a Legendre transform
This allows us to switch from fixed energy to fixed temperatureDefinition 4.3.1 (Legendre Transformation).
For a given convex function, a Legendre transform is any such function where it's slope at a point is , then there exists a unique such that is the same shape as The Legendre transform i sin simple language a way to move between dualities of variables where one is changing and one is constantWe're most negative as a gas
Theres a classic study tool caled the thermodynamic square]]></description><link>school/physics/statistical-mechanics/notes/4.3-free-energy.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/4.3 Free Energy.md</guid><pubDate>Wed, 29 Oct 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.8 Thermodynamics]]></title><description><![CDATA[Definition 1.8.1 (Thermodynamics).
The study of the observed macroscopic properties of materials
Definition 1.8.2 (Heat (Thermodynamics)).
Energy transferred between two objects by thermal contact. Heat is sometimes useless energy. Definition 1.8.3 (Work (Thermodynamics)).
Some macroscopic motion, such as a piston pushing a gas. It is an energy transfer which is not <a data-href="#^80acaf" href="#^80acaf" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^80acaf</a><a data-href="#^80acaf" href="#^80acaf" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.2 (Heat (Thermodynamics))</a> . The energy is somehow "useful". You can harness it to another task
Thermodynamics uses the macroscopic, where statistical mechanics uses the microscopic
If the energy can be used into something useful, we don't care
We know we can convert heat into work The goal is to increase the efficiency of the engine as much as possible, some things are physically impossible Is this getting at the Carnot engine? This means at a fixed temperature, if we want to increase the energy, we must increase the temperature. "All Thermometers are the same, all heat is of the same kind"
Definition (Zeroth Law of Thermodynamics).
"All Thermometers are the same, all heat is of the same kind"
If we have systems , if are in thermal equilibrium, and are in thermal equilibrium, then are in equilibrium. Definition 1.8.4 (First Law of Thermodynamics).
"Energy is conserved"
If a system has an internal energy , and you put heat into it, and the system does work on the surroundings, then Definition 1.8.5 (The Second Law of Thermodynamics).
"Entropy increases", "Heat moves from hotter to colder systems"
If entropy reduces, then the system is a special process which is called "reversible" There are no reversible heat engines Definition 1.8.6 (The Third Law of Thermodynamics).
"You can't reach absolute zero"
This is cause of quantum mechanics
In the context of the heat engine<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240919125605.png" src="supplemental-files/images/pasted-image-20240919125605.png" target="_self">The maximum possible efficiency iCan I run a Carnot engine in reverse to exacerbate a temperature difference? Like refrigeration We know that Where is the heat capacity, and is the temperature.We know that the energy of an ideal has is<br>
Proof of <a data-href="#^2bacf0" href="#^2bacf0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^2bacf0</a><a data-href="#^2bacf0" href="#^2bacf0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.8.7 (Heat Capacity of an ideal gas)</a>. □Theorem 1.8.7 (Heat Capacity of an ideal gas).
For an ideal gas, with avagadros number , or number of molecules , the heat capacity is: For an ideal monotomic gasDefinition 1.8.8 (Heat capacity at constant pressure). ]]></description><link>school/physics/qis/modern-physics/notes/1.8-thermodynamics.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.8 Thermodynamics.md</guid><pubDate>Thu, 19 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Session 13 2025-10-22 18.21.07]]></title><link>supplemental-files/excalidraw/session-13-2025-10-22-18.21.07.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Session 13 2025-10-22 18.21.07.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 23:21:31 GMT</pubDate></item><item><title><![CDATA[Session 13 2025-10-22 17.58.38]]></title><description><![CDATA[p_car = 0p_ball = 5p_i = 5p_f = 5p_ball = -2]]></description><link>supplemental-files/excalidraw/session-13-2025-10-22-17.58.38.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Session 13 2025-10-22 17.58.38.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 23:00:58 GMT</pubDate></item><item><title><![CDATA[Session 13 2025-10-22 17.46.46]]></title><link>supplemental-files/excalidraw/session-13-2025-10-22-17.46.46.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Session 13 2025-10-22 17.46.46.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 22:50:13 GMT</pubDate></item><item><title><![CDATA[Session 13 2025-10-22 17.42.32]]></title><link>supplemental-files/excalidraw/session-13-2025-10-22-17.42.32.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Session 13 2025-10-22 17.42.32.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 22:44:06 GMT</pubDate></item><item><title><![CDATA[Session 13 2025-10-22 17.37.36]]></title><link>supplemental-files/excalidraw/session-13-2025-10-22-17.37.36.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Session 13 2025-10-22 17.37.36.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 22:38:22 GMT</pubDate></item><item><title><![CDATA[Cheatsheet]]></title><description><![CDATA[Stirling's ApproximationMicrostates in monatomic ideal gas<img alt="Pasted image 20251021213524.png" src="supplemental-files/images/pasted-image-20251021213524.png" target="_self">Einstein solidMonotomic ideal gasadd einstein solid expressionwith constant volume and no workThe magnetization is defined as the total magnetic moment, which is
As more energy is added to the system, the multiplicity and entropy actually decrease, since there fewer ways to arrange the energy
<br><img alt="Pasted image 20251021214336.png" src="supplemental-files/images/pasted-image-20251021214336.png" target="_self">
Entropy of paramagnet spin systemThe magnetization is In the room temperature limitIf we're quasistatic, we're promised that soDefinition 1 (Isentropic).
Unchanged entropy (no heat change and quasistatic). Adiabatic and quasistatic
Thermodynamic IdentityThis tells us that is the amount of energy the system changes by when we add a particle!<br>
<img alt="Pasted image 20251021220159.png" src="supplemental-files/images/pasted-image-20251021220159.png" target="_self">]]></description><link>school/physics/statistical-mechanics/notes/cheatsheet.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/Cheatsheet.md</guid><pubDate>Tue, 21 Oct 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Test Corrections 2025-10-21 20.26.47]]></title><description><![CDATA[interface]]></description><link>supplemental-files/excalidraw/test-corrections-2025-10-21-20.26.47.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Test Corrections 2025-10-21 20.26.47.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 01:29:56 GMT</pubDate></item><item><title><![CDATA[Test Corrections 2025-10-21 19.50.53]]></title><description><![CDATA[VPV]]></description><link>supplemental-files/excalidraw/test-corrections-2025-10-21-19.50.53.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Test Corrections 2025-10-21 19.50.53.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 01:13:52 GMT</pubDate></item><item><title><![CDATA[Test Corrections 2025-10-21 20.04.51]]></title><description><![CDATA[PVT1T2T3]]></description><link>supplemental-files/excalidraw/test-corrections-2025-10-21-20.04.51.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Test Corrections 2025-10-21 20.04.51.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 01:06:36 GMT</pubDate></item><item><title><![CDATA[Test Corrections 2025-10-21 11.26.41]]></title><link>supplemental-files/excalidraw/test-corrections-2025-10-21-11.26.41.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Test Corrections 2025-10-21 11.26.41.excalidraw.md</guid><pubDate>Wed, 22 Oct 2025 00:49:27 GMT</pubDate></item><item><title><![CDATA[Applications of Grover's Algorithm 2024-11-21 15.18.51]]></title><description><![CDATA[Grover]]></description><link>supplemental-files/excalidraw/applications-of-grover's-algorithm-2024-11-21-15.18.51.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Applications of Grover's Algorithm 2024-11-21 15.18.51.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Common Ion Effect triangle]]></title><description><![CDATA[Ksp[ion]X[ion] = X*subscriptKsp = [A+][B-]]]></description><link>supplemental-files/excalidraw/common-ion-effect-triangle.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Common Ion Effect triangle.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-04-02 12.25.12]]></title><link>supplemental-files/excalidraw/drawing-2024-04-02-12.25.12.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-04-02 12.25.12.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-04-11 11.05.24]]></title><description><![CDATA[e-solidsolidCl-Cl-Cl-Cl-Cl-Na+Na+Na+Na+As the electrode slowly develops more of a negative charge from the coming electrons,it gets a negative charge, so it pulls from the salt bridge Sodium ionsReduction -&gt; cathodeOxidation: anode]]></description><link>supplemental-files/excalidraw/drawing-2024-04-11-11.05.24.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-04-11 11.05.24.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-04-16 13.18.31]]></title><link>supplemental-files/excalidraw/drawing-2024-04-16-13.18.31.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-04-16 13.18.31.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-04-16 13.18.44]]></title><link>supplemental-files/excalidraw/drawing-2024-04-16-13.18.44.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-04-16 13.18.44.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Drawing 2025-01-29 18.04.52]]></title><link>supplemental-files/excalidraw/drawing-2025-01-29-18.04.52.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2025-01-29 18.04.52.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Drawing 2025-05-11 16.24.50]]></title><link>supplemental-files/excalidraw/drawing-2025-05-11-16.24.50.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2025-05-11 16.24.50.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Example 2 electrode]]></title><description><![CDATA[AgFe3+,Fe2+Ag+Pt]]></description><link>supplemental-files/excalidraw/example-2-electrode.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Example 2 electrode.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Solubility Equilibrium in Water ]]></title><description><![CDATA[Ksp[ion]XKsp = x^2, 4x^3, 27x^4,106x^5[ion] = X*subscriptKsp = [A+][B-]]]></description><link>supplemental-files/excalidraw/solubility-equilibrium-in-water-.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Solubility Equilibrium in Water .excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Untitled 2024-11-21 14.14.07]]></title><description><![CDATA[x]]></description><link>supplemental-files/excalidraw/untitled-2024-11-21-14.14.07.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Untitled 2024-11-21 14.14.07.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[Wrapper Classes 2024-11-20 17.08.55]]></title><link>supplemental-files/excalidraw/wrapper-classes-2024-11-20-17.08.55.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Wrapper Classes 2024-11-20 17.08.55.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:07 GMT</pubDate></item><item><title><![CDATA[3.4 More Perturbation Theory 2024-11-21 10.05.10]]></title><link>supplemental-files/excalidraw/3.4-more-perturbation-theory-2024-11-21-10.05.10.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/3.4 More Perturbation Theory 2024-11-21 10.05.10.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Apartment Note 2024-11-24 15.34.01]]></title><link>supplemental-files/excalidraw/apartment-note-2024-11-24-15.34.01.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Apartment Note 2024-11-24 15.34.01.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Apartment Note 2024-11-24 15.35.27]]></title><link>supplemental-files/excalidraw/apartment-note-2024-11-24-15.35.27.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Apartment Note 2024-11-24 15.35.27.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Beyond 2 qubits intro]]></title><link>supplemental-files/excalidraw/beyond-2-qubits-intro.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Beyond 2 qubits intro.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-03-26 11.26.20]]></title><link>supplemental-files/excalidraw/drawing-2024-03-26-11.26.20.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-03-26 11.26.20.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-04-16 11.07.46]]></title><link>supplemental-files/excalidraw/drawing-2024-04-16-11.07.46.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-04-16 11.07.46.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-04-16 13.18.47]]></title><description><![CDATA[Local ConfigLocal ConfigLocal ConfigCache ConfigMain ConfigN=3Dir = ...N=3Dir = ...SignatureEditSignatureEditSignatureEditInitial SyncON LOAD(Check)Notes:- One device some ID- make signature station entry if not present- Check if config is marked as newIF- All signatures true- , push cache to main if not empty, force empty main if so- Pull main to local- Empty SignatureELSE- Mark Sig- Pull MainN=3N=2N=3Device 1Notifs Seton new dayDevice 2Notifs Seton new dayDevice 3Notifs Seton new dayPUSH- Push to cache for changes- Save locally- SignDay 2N=3N/A33]]></description><link>supplemental-files/excalidraw/drawing-2024-04-16-13.18.47.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-04-16 13.18.47.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-05-13 17.16.03]]></title><link>supplemental-files/excalidraw/drawing-2024-05-13-17.16.03.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-05-13 17.16.03.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-06-01 16.47.59]]></title><link>supplemental-files/excalidraw/drawing-2024-06-01-16.47.59.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-06-01 16.47.59.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-06-04 10.20.07]]></title><link>supplemental-files/excalidraw/drawing-2024-06-04-10.20.07.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-06-04 10.20.07.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-06-19 19.18.12]]></title><link>supplemental-files/excalidraw/drawing-2024-06-19-19.18.12.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-06-19 19.18.12.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2024-06-26 00.13.14]]></title><link>supplemental-files/excalidraw/drawing-2024-06-26-00.13.14.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2024-06-26 00.13.14.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2025-01-24 13.46.23]]></title><link>supplemental-files/excalidraw/drawing-2025-01-24-13.46.23.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2025-01-24 13.46.23.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2025-06-30 23.13.06]]></title><link>supplemental-files/excalidraw/drawing-2025-06-30-23.13.06.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2025-06-30 23.13.06.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Drawing 2025-06-30 23.13.06_0]]></title><link>supplemental-files/excalidraw/drawing-2025-06-30-23.13.06_0.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Drawing 2025-06-30 23.13.06_0.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Example Annotating Salt Bridge]]></title><description><![CDATA[Cathode, "Red Cat"BridgeWiree-Anode, "An Ox"K+NO_3)-Voltage generated V= .80-.34 = .46VCuCu2+Ag+Ag]]></description><link>supplemental-files/excalidraw/example-annotating-salt-bridge.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Example Annotating Salt Bridge.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Example Notation]]></title><description><![CDATA[2Al3SnAl3+(.4M)Sn2+(.1M)]]></description><link>supplemental-files/excalidraw/example-notation.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Example Notation.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[LIGO Setup]]></title><description><![CDATA[////// / / / / / /LaserThe horizontal beam picks uptwo horizontal phase shifts, and one verticalThe vertical beam picks up 3 vertical phase shiftsThe amplitudes don't simply add, so if there's a phaseshift, it'll get darkerTrash📍[[Gravity]]]]></description><link>supplemental-files/excalidraw/ligo-setup.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/LIGO Setup.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Obsidian Home Page UI drawing]]></title><description><![CDATA[MobileClassesDaily NotesPeoplen people(dataview)n people(dataview)npeople(dataview)Class 1Class 2Today's DateYesterday'sdateTmmrwGroup 1Group 2group nDesktopClassesRecent NotesPeopleClass 1Class 2Recent 2Recent 1Recent 3Group 1Group 2group n📍Today's daily note \[[today]]Make a document with thenames of the differentgroups to sort byAll the different notes with theproperty "class", grouped by uniqueclass identifier]]></description><link>supplemental-files/excalidraw/obsidian-home-page-ui-drawing.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Obsidian Home Page UI drawing.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[SHE Electrode]]></title><description><![CDATA[OxidationReductionP+H_2H+]]></description><link>supplemental-files/excalidraw/she-electrode.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/SHE Electrode.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Shorthand for Electrochemical Cell]]></title><description><![CDATA[anodecathodeZnCuSalt BridgeZn 2+Cu2+The Zinc turns to an ionThe Copper Deionizes(1M)(1M)]]></description><link>supplemental-files/excalidraw/shorthand-for-electrochemical-cell.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Shorthand for Electrochemical Cell.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Untitled 2024-11-21 14.49.59]]></title><description><![CDATA[ORANDANDANDORabcdefghi]]></description><link>supplemental-files/excalidraw/untitled-2024-11-21-14.49.59.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Untitled 2024-11-21 14.49.59.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Weather Eclipse]]></title><description><![CDATA[d]]></description><link>supplemental-files/excalidraw/weather-eclipse.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Weather Eclipse.md</guid><pubDate>Mon, 20 Oct 2025 19:50:06 GMT</pubDate></item><item><title><![CDATA[Mach-Zehnder Interferometer]]></title><description><![CDATA[.sqrt(5)*|-&gt;,H&gt;.sqrt(5)*|down,H&gt;.sqrt(5)i*|side,H&gt;.sqrt(5)*|down,H&gt;-.5|down,H&gt;.5|side,H&gt;exp(i*phi)(.5)*|side,H&gt;exp(i*phi)(.5)*|down,H&gt;Notice that we've passed through another beam splitter, so its sqrt(.5)sqrt(.5)]]></description><link>supplemental-files/excalidraw/mach-zehnder-interferometer.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Mach-Zehnder Interferometer.md</guid><pubDate>Mon, 20 Oct 2025 19:50:05 GMT</pubDate></item><item><title><![CDATA[Radiation Table]]></title><description><![CDATA[This stuff is dangerous because it decays in a human lifetime]]></description><link>supplemental-files/excalidraw/radiation-table.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Radiation Table.md</guid><pubDate>Mon, 20 Oct 2025 19:50:05 GMT</pubDate></item><item><title><![CDATA[Untitled 2024-11-21 14.37.46]]></title><description><![CDATA[0111111111101110001011110]]></description><link>supplemental-files/excalidraw/untitled-2024-11-21-14.37.46.excalidraw.html</link><guid isPermaLink="false">Supplemental Files/Excalidraw/Untitled 2024-11-21 14.37.46.excalidraw.md</guid><pubDate>Mon, 20 Oct 2025 19:50:05 GMT</pubDate></item><item><title><![CDATA[merged]]></title><link>school/physics/quantum-computing/semester-1/exam-pdfs/merged.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/Exam PDFS/merged.pdf</guid><pubDate>Mon, 20 Oct 2025 19:48:43 GMT</pubDate></item><item><title><![CDATA[CourseSyllabus-Fall2024]]></title><link>school/physics/quantum-computing/semester-2/class-content/coursesyllabus-fall2024.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/Class Content/CourseSyllabus-Fall2024.pdf</guid><pubDate>Mon, 20 Oct 2025 19:48:43 GMT</pubDate></item><item><title><![CDATA[Midterm_Exam_Fall_Sample]]></title><link>school/physics/quantum-computing/semester-2/class-content/midterm_exam_fall_sample.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/Class Content/Midterm_Exam_Fall_Sample.pdf</guid><pubDate>Mon, 20 Oct 2025 19:48:43 GMT</pubDate></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[First day of Quantum Computing1import sympy as sp2from sympy import init_printing3init_printing()4A = sp.Matrix([[1,1],[1,1]])5sp.pprint(A)Can I use this with qiskit.
Microsoft has a Qiskit-like library called Qisshark, which is in C# and interfaces well with their packages
There's also Pennylane which is experiment oriented, so it's a weird paradigm to use because. it's OOPS focused
Definition 0.1.1 (Quantum Arithmetic).
Given a qubit Note that the entire circuit isn't placed above! To prepare each of the states below from , we need other gates The key part of why this is an adder, is if you look at the qubit. That is the output qubit, and it's result is because of addition. In that space, Definition 0.1.2 (Deutsch’s Algorithm).
Where Me and <a data-tooltip-position="top" aria-label="../../../../../Personal/People/Ayden Gertiser" data-href="../../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Ayden</a><a data-tooltip-position="top" aria-label="../../../../../Personal/People/Ayden Gertiser" data-href="../../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Ayden</a>'s Guess on what's going on:The qubits after testing on the quantum composer, all have the same result. With the gate, it's interesting that it doesn't affect the outcome, but the gate might just be reflecting all the superpositions. Because up to that point it's maximally entangled, flipping the superpositions is just a symmetry, so the does nothing.
Real explanation
The input qubit is the first qubit, while the output is the zeroth qubit. This was the first quantum Computing algorithm. David Deutsch was one of the father's of quantum computing
Deutsch envisioned that QC's would be different ways to measure different interpretations of quantum mechanics. He wanted to make a quantum AGI, put it into superposition, then ask it questions about superpositions.
Theoretically, this is a more efficient algorithm for a QC than a classical computer.
QUANTUM SUPREMACY BABY WE DID IT ‼️‼️‼️‼️The question is "Wether the unitary you're using to measure the function, depends on the input qubit?"]]></description><link>school/physics/quantum-computing/semester-2/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/0.1 Introduction.md</guid><pubDate>Thu, 29 Aug 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 Intro to Qiskit]]></title><description><![CDATA[Find the notebook for this day in the Notebooks file.1from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister23from qiskit_aer import Aer4q = QuantumRegister(5) # Create a quantum register with 5 qubits.56c = ClassicalRegister(5) # Create a classical register with 5 bits.7qc = QuantumCircuit(q, c) # Create a quantum circuit, combining q and c.8910qc.draw()1112qc.draw(output='mpl')13"The reason why magnets work are because they're made up of a bunch of tiny magnets"
-Dr. Davis
You can use %pip when inside a notebook, to make changes to the environment
4Can you also do controlled Unitaries? - <a data-tooltip-position="top" aria-label="../../../../../Personal/People/Ayden Gertiser" data-href="../../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Ayden</a><a data-tooltip-position="top" aria-label="../../../../../Personal/People/Ayden Gertiser" data-href="../../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Ayden</a>
Yep!
If we wanted to verify a measurement was teleported, we can just apply the invert the existing preparation observables, and see if we get a <br>If I had a medium with a longer coherence time, could I use <a data-tooltip-position="top" aria-label="../Semester 1/5.1 Quantum Teleportation" data-href="../Semester 1/5.1 Quantum Teleportation" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">5.1 Quantum Teleportation</a><a data-tooltip-position="top" aria-label="../Semester 1/5.1 Quantum Teleportation" data-href="../Semester 1/5.1 Quantum Teleportation" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">5.1 Quantum Teleportation</a> to take information from my logical circuit, and write it to the better medium? 1q = QuantumRegister(3) #3 qubits23c = ClassicalRegister(1) #only need one classical bit45qc = QuantumCircuit(q,c) #combine q and c into a quantum circuit6#First, initialize the state we want to send78qc.h(q[2])910qc.s(q[2])1112qc.barrier(q)1314 15 1617#Then, initialize the Bell pair we will use as a resource1819qc.h(q[1])2021qc.cx(q[1],q[0])2223qc.barrier(q)2425 26 2728#Now, we perform the correlating part of the Bell State Measurement2930 3132qc.cx(q[2],q[1])3334qc.h(q[2])3536qc.barrier(q)3738 3940#In place of measuring and then doing conditional gates, make the corrections controlled on q1 and q2!4142qc.cx(q[1],q[0])4344qc.cz(q[2],q[0])4546 4748qc.barrier(q)4950 5152#Finally, measure in the appropriate basis5354qc.sdg(q[0])5556 5758qc.h(q[0])5960qc.measure(q[0],c[0])61qc.draw('mpl')62print(qc)1backend = Aer.get_backend('qasm_simulator') #tell it where to simulate23 45job = backend.run(qc)67results = job.result()89counts = results.get_counts(qc)1011 1213#counts=backend.run(qc).result().get_counts(qc)14plot_histogram(counts)]]></description><link>school/physics/quantum-computing/semester-2/1.2-intro-to-qiskit.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/1.2 Intro to Qiskit.md</guid><pubDate>Tue, 03 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.4 Programming Qiskit]]></title><link>school/physics/quantum-computing/semester-2/1.4-programming-qiskit.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/1.4 Programming Qiskit.md</guid><pubDate>Tue, 10 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[Grover's Algorithm]]></title><description><![CDATA[If I have an unstructured boolean function, which takes a value and returns a zero or one.If the function is unstructured, I have to check every single input to see if I got it right, as there's no structure.
To find the right answer, best case we find it in 1. Worst case is . Average is .]]></description><link>school/physics/quantum-computing/semester-2/grover's-algorithm.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/Grover's Algorithm.md</guid><pubDate>Thu, 12 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[Midterm Review]]></title><description><![CDATA[Make sure you get better at building Oracles as needed
For Fourier and phase, those are good concepts to have, but come more strongly later]]></description><link>school/physics/quantum-computing/semester-2/midterm-review.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/Midterm Review.md</guid><pubDate>Tue, 08 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[Scratch]]></title><description><![CDATA[In writing (paper or digital) show that Where Hint: Plugging <a data-href="#^hint2" href="#^hint2" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^hint2</a><a data-href="#^hint2" href="#^hint2" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2)</a> into <a data-href="#^proofDude" href="#^proofDude" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^proofDude</a><a data-href="#^proofDude" href="#^proofDude" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^proofDude</a><br>In that sum, there's only one case when this is not equal to zero, so the summation reduces to, which is also just <a data-href="#^part1" href="#^part1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^part1</a><a data-href="#^part1" href="#^part1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1)</a>]]></description><link>school/physics/quantum-computing/semester-2/scratch.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/Scratch.md</guid><pubDate>Thu, 17 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[Stabilizer Circuit Scratch Paper]]></title><description><![CDATA[The details of this lesson can be found in the corresponding notebook, the main exercise is listed below. ]]></description><link>school/physics/quantum-computing/semester-2/stabilizer-circuit-scratch-paper.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 2/Stabilizer Circuit Scratch Paper.md</guid><pubDate>Tue, 19 Nov 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.2 Quantum Key Distribution]]></title><description><![CDATA[ Learning Objectives:
• Review the symmetric key encryption
• Use a binary one-time pad to encrypt/decrypt a message
• Describe the BB84 quantum key distribution (QKD) protocol
• Identify whether a given QKD channel using BB84 is secure or not
<img alt="Pasted image 20240201153435.png" src="supplemental-files/images/pasted-image-20240201153435.png" target="_self">
Modern encryption relies on the computational difficulty of particular math problems
If that hard math problem suddenly is easy to solve, the secrets ain't secret, they're easy
Secret Key Encryption bypasses this kind of issue
Big issue is delivering and sharing the secret key is mod2 addition, but it's also just the XOR gate, where you have True-False statements operations in mod2 is actually it's own inverse, so if I want to decrypt a message, I just add the key again
How can we transmit the secret message, while being able to know if it was taken?
We can send the secret key out with H/V polarization states
But again, how do we know we've been intercepted
For perfect methods of encryption, we need the same length of seed to data.<br><img alt="Pasted image 20240201163114.png" src="supplemental-files/images/pasted-image-20240201163114.png" target="_self">Inferred Key There is evidence for Eve!
We shared one bit publicly, and when we had the same basis, there was different information read.The BB84 method for quantum key distribution uses classical post-processing to create a secret key between Alice and Bob. Alice prepares and sends a state in a randomly chosen basis, and Bob measures the received state in a randomly chosen basis. After the states have been sent and received, Alice and Bob communicate their basis choices classically and only save the data points where the basis choices match. The assumption is that by selecting the same basis, we will get the same confidence on which bit it is.
Remember that the key is supposed to be secret, so the open communication between Alice and Bob simply contains the basis choices and not the secret key itself!
The knack here, is that if I'm eve, I've also randomly selected a basis to use. Now that I have my basis, and measurements, I cant just sift my information, because some of my basis's won't match bob and I won't have enough information to form the secret key. I'll get some of the data, but not enoughWhy haven't we implemented it?
Money got pulled, politics
It can be hard to do reliably, esp over a longer distance, we can't have repeating stations! Otherwise they all need to be trusted nodes, or we get the Eve problem If they're all trusted nodes (each one is like bob, each one sifts the secret key), the information goes off by The biggest barrier is that there is a lot of implementation problems, over math problems
]]></description><link>school/physics/quantum-computing/semester-1/1.2-quantum-key-distribution.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/1.2 Quantum Key Distribution.md</guid><pubDate>Mon, 20 Oct 2025 19:48:40 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.1 Multi Qubit States]]></title><description><![CDATA[<img alt="../../../../../Supplemental Files/images/Pasted image 20240402153811.png" src="supplemental-files/images/pasted-image-20240402153811.png" target="_self"><br><img alt="../../../../../Supplemental Files/images/Pasted image 20240402153758.png" src="supplemental-files/images/pasted-image-20240402153758.png" target="_self">
This state tells us the different measurement outcomes
The probabilities of Then we can use the Born rule, square the coeffs Then for our beam splitter, we know all the probability on the right half is , the bottom is also , so the values are For the right half, we want to end up with horizontal polarization, we put identity down
For bottom half, we want to go from , so we use For the phase on the bottom beam , we tack on a zero phase<br>Reference image: <img alt="../../../../../Supplemental Files/images/Pasted image 20240402154523.png" src="supplemental-files/images/pasted-image-20240402154523.png" target="_self"><br><img alt="../../../../../Supplemental Files/images/Pasted image 20240402154701.png" src="supplemental-files/images/pasted-image-20240402154701.png" target="_self">Essentially, when you go all the way through from above, you get a negative!<br><img alt="../../../../../Supplemental Files/images/Pasted image 20240402154943.png" src="supplemental-files/images/pasted-image-20240402154943.png" target="_self">Because we're coming in from above and the side, we want to sum up the two states:Then note that because we're coming down, Starting with horizontalThen downward beamThus, the total state is .sqrt(5)*|-&gt;,H&gt;.sqrt(5)*|down,H&gt;.sqrt(5)i*|side,H&gt;.sqrt(5)*|down,H&gt;-.5|down,H&gt;.5|side,H&gt;exp(i*phi)(.5)*|side,H&gt;exp(i*phi)(.5)*|down,H&gt;Notice that we've passed through another beam splitter, so its sqrt(.5)sqrt(.5)
Aftr annotating this diagram with the beam behavior, we get the final state as This is really helpful, because we can directly measure the outputs. From the ratio between the sideways light, versus the down, we can get the value of This is how the LIGO experiment worked! It wouldn't be like the one above, because both beams travel in both directions. Because of them getting the same amount of the two phase influences, we can't detect grav waves which are non-local. Instead, it would be like this.
Note that by bouncing through, you get twice the phase shift
////// / / / / / /LaserThe horizontal beam picks uptwo horizontal phase shifts, and one verticalThe vertical beam picks up 3 vertical phase shiftsThe amplitudes don't simply add, so if there's a phaseshift, it'll get darkerTrash📍[[Gravity]]
The above is a michelson interferometer.Inner product Compute the following for a two qubit systemMath: Math: Math: <br>Hadamard has a association to the <a data-href="Fourier transform" href=".html" class="internal-link" target="_self" rel="noopener nofollow">Fourier transform</a>! <br><img alt="../../../../../Supplemental Files/images/Pasted image 20240404160007.png" src="supplemental-files/images/pasted-image-20240404160007.png" target="_self">
Applying the not gate to qubit zero, as noted by the subscript, flips the zeroth index. QUANTUM COMPUTING MULTI QUBIT INDICIES FORMAT Top to bottom, right to left Definition 4.1.1 (Born Rule for Multi Qubit States).
Where With Any n-qubit state has up to components<br><a data-tooltip-position="top" aria-label="../Definitions/Quantum Gates" data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Quantum Gates</a><a data-tooltip-position="top" aria-label="../Definitions/Quantum Gates" data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Quantum Gates</a><br>Exercise 4.1.2 (Use the IBM composer to build the following Quantum state). <img alt="../../../../../Supplemental Files/images/Pasted image 20240404161804.png" src="supplemental-files/images/pasted-image-20240404161804.png" target="_self" style="width: 200px; max-width: 100%;">
Find the computational basis representation Exercise 4.1.3 (Use the IBM composer to build the following Quantum state). We wanna undo what we did above, WE'RE FACTORING All of the inputs come in as , so we just need to find the gates to transform into those above vectors Exercise 4.1.4 (Put the following in the digital basis). Apply each gate Exercise 4.1.5 (Use the IBM composer to make the following state). Try and factor?
Turns out it's just 3 Hadamards! You can recognize these as 3 Hadamards, because there are eight unique qubits, and that the bottom is a factor of the H coefficient
]]></description><link>school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/4.1 Multi Qubit States.md</guid><pubDate>Mon, 20 Oct 2025 19:48:40 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.2 Multi Qubit Measurements]]></title><description><![CDATA[Exercise 4.2.1 (Draw the circuit for the following gate operations). Then find the ket representation Ket representation time
There's a control and a target for Q0 Up to this point, we've gone up to the first CNOT gate, like above
Now we apply it, CNOT only flips the second bit if the first bit is 1. [Quantum Gates](../../Definitions/Quantum Gates)
Now applying the CNOT They went unchanged Applying Z to qubit 2 gets us
<a href=".?query=tag:Review" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Review">#Review</a>, finish solving this
Now qubit zero and 1 are entangled
The result, to practice later is *Means we want everything with the behavior on both zero and 1We have to normalize by the probability length, because this new state doesn't have a sum of probabilities to 1. We destroyed the superposition on qubit 0, but we still have it on qubit 1*
Below describes the world where by breaking superposition, we got We've totally destroyed this quantum state, only either or survives the collapse
You're allowed to choose which qubit you measure, but you're not allowed to choose what outcome you getThe above is due to superposition.Exercise 4.2.2 (Given the below quantum state). A. What is the quantum state after measurement of qubit 1 if the outcome is 0 B What is the probability of this outcome occurring C. What is the probability of obtaining 1 upon a subsequent measurement of qubit 0
Start with your quantum state from part A. We can think that selecting which qubit to measure, just gives us a random preparation of the subsequent outcomes!Then this means we can get a density matrix<br><a data-href="1.2 Quantum Key Distribution" href="school/physics/quantum-computing/semester-1/1.2-quantum-key-distribution.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.2 Quantum Key Distribution</a><a data-href="1.2 Quantum Key Distribution" href="school/physics/quantum-computing/semester-1/1.2-quantum-key-distribution.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.2 Quantum Key Distribution</a><br><img alt="../../../../../Supplemental Files/images/Pasted image 20240411163815.png" src="supplemental-files/images/pasted-image-20240411163815.png" target="_self">
Same as before!
<br><img alt="../../../../../Supplemental Files/images/Pasted image 20240411163923.png" src="supplemental-files/images/pasted-image-20240411163923.png" target="_self">
Bob and Alice get 0 with probability of , same for 1Highly entangled states are robust to partial measurement and qubit loss. But why?If any one of the qubits is "lost", the resulting qubits are still in a superposition! That way we can still continue to do work
If any qubit is lost, i.e random, then we get a mixed state of mixed states! That means it's still possible to do work.<br>
<a href=".?query=tag:Question" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Question">#Question</a>: If quantum states are just going to decohere, how to I stretch that time long enough to perform a useful calculation?
<br>In <a data-href="Error Correction" href=".html" class="internal-link" target="_self" rel="noopener nofollow">Error Correction</a>, we need to have some kind of way to figure out if the state has been converted to a mixed state. Depending on that we can do what we do with regular error correction and repair the gates. Isn't error correction really difficult in quantum computing, or am I misconnecting it to another subject.
]]></description><link>school/physics/quantum-computing/semester-1/4.2-multi-qubit-measurements.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/4.2 Multi Qubit Measurements.md</guid><pubDate>Mon, 20 Oct 2025 19:48:40 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.2 Superposition]]></title><description><![CDATA[<a data-href="../Definitions/Introduction to Qbits" href="school/physics/quantum-computing/definitions/introduction-to-qbits.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Introduction to Qbits</a><a data-href="../Definitions/Introduction to Qbits" href="school/physics/quantum-computing/definitions/introduction-to-qbits.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Introduction to Qbits</a><br><img alt="Pasted image 20240125154522.png" src="supplemental-files/images/pasted-image-20240125154522.png" target="_self">
Right circular is 0, left circular is 1
Euler's identity is really important, referenced below. If we do this, we then can represent diagonal as The in class question was then just like calculating the values of new points in different vector spaces, extra way is the RREF thing I did here, but it's small enough to just substituteWith both of the above, we can write our horizontal and vertical polarizations in terms of our new basis vectorsWe define a circular polarization vector byWhat this means is we can define circular polarization soley through a phase change Right and Left circular polarization can then be defined as This is the key conceptual jump here, we use complex variables in this vector to represent this rotation. A complex amplitude Eulers identity to reduce: Eulers Identity
Sub in to get]]></description><link>school/physics/quantum-computing/semester-1/1.2-superposition.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/1.2 Superposition.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.3 Introduction to Encryption]]></title><description><![CDATA[Symmetric encryption: Keys need to be shared securely, can only be really secure when key length = message length, security os contingent on the key being secret and hard to get
Asymmetric encryption: only you can open the message]]></description><link>school/physics/quantum-computing/semester-1/1.3-introduction-to-encryption.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/1.3 Introduction to Encryption.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate></item><item><title><![CDATA[2.3 Single-Qubit States and Gates]]></title><description><![CDATA[Using <a data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Quantum Gates</a><a data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Quantum Gates</a>, we can just multiply out the above
Distance is just the complex conjugate identity we know abt!
X gate always flips horizontal and vertical so that X, Y, Z and H are all roots of I ! <br><a href=".?query=tag:Question" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Question">#Question</a> - How do you take the square root of a matrix? Answer: There isn't a unique convention to finding it <br>Using definitions from here:<a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Bra-Ket Notation</a><a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Bra-Ket Notation</a> <br>Any state <a data-tooltip-position="top" aria-label="../../Linear Algebra/6.3 Orthogonal and Orthonormal Spaces > ^0be41c" data-href="../../Linear Algebra/6.3 Orthogonal and Orthonormal Spaces#^0be41c" href=".html" class="internal-link" target="_self" rel="noopener nofollow">inner product</a> 'd to itself is just one, telling us the length of the vector. These are normalized states Dot product of two perpendicular (orthogonal ) vectors REMEMBER COMPLEX CONJUGATE!
a. = This was not on canvas, but for everyones sake we're working this out Remember there is a distributive property! We could have just rephrased this as taking the horizontal component of , which means going back to our definition, because because they are orthogonal, you are left with the factor of You can also just use the same clever reason as above! We only want the vertical component of If you remember that the inner product is the generalization of the dot product, because we have 2x1 vectors, it is identical to the dot product That being said, inner product dot product. The dot product is defined for MxN matrices when n=1<br>
<a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Orthonormal Bases</a><a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Orthonormal Bases</a> <br><a data-href="../Definitions/Polarization Vectors" href="school/physics/quantum-computing/definitions/polarization-vectors.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Polarization Vectors</a><a data-href="../Definitions/Polarization Vectors" href="school/physics/quantum-computing/definitions/polarization-vectors.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Polarization Vectors</a> Rewrite in the {} basis Now we just need to solve for and . To do this, plug in our values for and , then factor. From here we just solve that system for and to get: Therefore, we have a final answer of Rewrite in the {} where , Then plugging back in we get
]]></description><link>school/physics/quantum-computing/semester-1/2.3-single-qubit-states-and-gates.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/2.3 Single-Qubit States and Gates.md</guid><pubDate>Thu, 15 Feb 2024 06:00:00 GMT</pubDate></item><item><title><![CDATA[2.5 Calculating Observables]]></title><description><![CDATA[Example in <a data-href="2.4 Quantum Observables#Activity 3" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#Activity 3" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.4 Quantum Observables &gt; Activity 3</a><a data-href="2.4 Quantum Observables#Activity 3" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#Activity 3" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">2.4 Quantum Observables &gt; Activity 3</a>
Given We write it as a projection sum The observable is a matrix that extracts some property out of , whether that be the polarization amplitudes and , but there are also observable matrices that might pull out energies. What this also means is that we can use this to co-relate different properties of a quantum system <br>Then construct a unitary matrix from the <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvectors</a> <br>Apply hermitian conjugate <a data-href="../Definitions/Orthonormal Bases#Hermitian Conjugate" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Orthonormal Bases &gt; Hermitian Conjugate</a><a data-href="../Definitions/Orthonormal Bases#Hermitian Conjugate" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Orthonormal Bases &gt; Hermitian Conjugate</a>: Then measure in computational basis, measuring means you have , means <br><a href=".?query=tag:proof" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#proof">#proof</a><br>
Given and is claimed to be an <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvector</a> of , with associated <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^5436ef" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^5436ef" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvalues</a> of then we can just plug in and see if the identity is trueIf this identity is true, then we prove it's an outer productGiven the observable and following identity, and a general state, perform the first 3 stepsHe wants us to first prove the outer product stuff, so do that here
<br>
If we want to check if some value is an <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvector</a>, just solve the <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvalue</a> problem Note that the answer was given, but it's good practice Doing work now!Then to calculate the probabilities we use Born's rule:Born rule: The probability of getting a specific outcome, is equal to the coefficient on a basis times it's conj
Note that Born's Rule is specifically saying to get the magnitude of that component, which needs to be realDefinition 2.5.1 (Eigenvectors and Eigenvals in Quantum Computing). The eigenvector has a corresponding value associated with it, such that when multiplying it by the matrix, is equal to a scalar multiple of itself!
The eigenvalues of the hermitian matrix are real ()
Find the eigenvals associated with the D/A vectors, provably.So <br>Get the mechanics down for this, it'll be on the <a href=".?query=tag:exam" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#exam">#exam</a> corresponds to a measurement of 1, corresponds to a measurement of -1. Thus the average is zero if the distribution is even<br><a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Bra-Ket Notation</a><a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Bra-Ket Notation</a>Definition 2.5.2 (Expected Value).
If we prepare the same state a lot and measure the same observable, what value do we expect? By expanding the right and factoring, we can turn it into the below Note the expectation value should always be real
Prepare the following qubit stateWhat is the expectation value of the qubit in gate Y?
A)<br><a data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Quantum Gates</a><a data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Quantum Gates</a><br>
Transform to perform a measurement in the <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^35547b" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^35547b" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenbasis</a> of Y
B)]]></description><link>school/physics/quantum-computing/semester-1/2.5-calculating-observables.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/2.5 Calculating Observables.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate></item><item><title><![CDATA[2.6 Quantum Computing IBM Stuff]]></title><description><![CDATA[For the qubit state The expectation value of the observable X?
We can use <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvalues</a> for the observable X Method 2 Objective Explain** energy levels of quantum computers and how that develops the system Many q-systs exhibit discrete energy states, any pair of these states can represent qubits Common one to use is energy level Ex energy level of electron in Hydrogen atom: It's easy to predict it's energy states. The electron actually oscillates between two states in harmonic fashion The electron orbits "further out". You can't occupy an energy that's not one of the discrete states <br>
Computational Basis <a href=".?query=tag:computational" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#computational">#computational</a> Basis Pulses of radiation perform unitary transformations on qubits, with frequency and duration determines the type if transformation wt = acta as an X gate acta as an H gate But the pulses don't stay that way together, electrons love to interact with stuff<br>
- <a href=".?query=tag:RelaxationTime" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#RelaxationTime">#RelaxationTime</a> () is the total lifetime of a quantum state
- Prepare the qubit in an excited state, after some time t, measure in e/g basis, by we only have some probability of that the system is still in the excited state<br>
- <img alt="Pasted image 20240305154819 1.png" src="supplemental-files/images/pasted-image-20240305154819-1.png" target="_self"><br>
- <a href=".?query=tag:DecoherenceTime-" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#DecoherenceTime-">#DecoherenceTime-</a> We add up the two probabilities, prepared in the "+" superposition of ground and energized, after time t, measure in teh +/- basis
- By time , the sysyem is only 68% likely to be in the + superposition<br>
- <img alt="Pasted image 20240305154828 1.png" src="supplemental-files/images/pasted-image-20240305154828-1.png" target="_self">
- What we're plotting here, is the probability of the superposition, since we're measuring in the DA basis. How long does it stay this new superposition of states, which isn't the excited states <br><a href=".?query=tag:Question" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Question">#Question</a> Why do we use the electron energy state superpositions versus polarization states in light?
Xanadu quantum computing uses qubits and continuous variables. Light polarization stuff is harder to scale
- It's hard to make light interact with each other, two photon qubits don't interact as well as two electron qubitsNotes:
Uses this energy level probability, we then cool to low frequencies (&lt;20mK), then putting us in a superconducting states
This gives us a magnetic moment in each of the currents because of the different energy states, which can be controlled with microwave signals
Despite the super conduction, we still interact with our environment so still matter We can use an API key to interact with the computers locally over on their website
The gates are structured brick like
Simulated vs Real quantum computer in our work We're doing specifically small and educational concepts
Real QC's have along line
Sim QC has perfect fidelity because our programs are so small, our current real quantum computers are feats of engineering, but the noise isn't small enough on real QC's to make it worth it set all the qubits to zero
<br><img alt="Pasted image 20240305161236 1.png" src="supplemental-files/images/pasted-image-20240305161236-1.png" target="_self">
<br><img alt="Pasted image 20240305161315 1.png" src="supplemental-files/images/pasted-image-20240305161315-1.png" target="_self">
We can set it up to include real noise, next semester but noise is a good convention to use
To measure the DA basis, use an H gate! Same rules as before apply, below measures diagonal
<br><img alt="Pasted image 20240305161527 1.png" src="supplemental-files/images/pasted-image-20240305161527-1.png" target="_self">
This now measures anti-diagonal, we can either add a Z gate, or put an X gate a the beginning
<br><img alt="Pasted image 20240305161722 1.png" src="supplemental-files/images/pasted-image-20240305161722-1.png" target="_self">
How do we get to the R/L basis?
<br>-This measures us in R, H-&gt;R <img alt="Pasted image 20240305162050 1.png" src="supplemental-files/images/pasted-image-20240305162050-1.png" target="_self">
- We can put an X at the beginning, a Z in the middle, or a Z at the end
- The NOT only works before the Hadamard, the Z works after the hadamard before the S, or after H after S Measure X using the QX sim, compute the sample mean. Same as expectation value
<br><img alt="Pasted image 20240305162918 1.png" src="supplemental-files/images/pasted-image-20240305162918-1.png" target="_self">
<br>Measurement in the HV basis is doing nothing, to measure in the X basis, we apply a hadamard. The X basis has <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvals</a> of D/A, and to go from HV to DA, we apply hadamard <br>Measuring XHT in DA<img alt="Pasted image 20240305163104 1.png" src="supplemental-files/images/pasted-image-20240305163104-1.png" target="_self">
Given our values for the amplitudes, eigenvalues coeff^2, expected value of ]]></description><link>school/physics/quantum-computing/semester-1/2.6-quantum-computing-ibm-stuff.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/2.6 Quantum Computing IBM Stuff.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.1 General Qubit States]]></title><description><![CDATA[
Prepare any single qubit state
measure any qubit in any orthonormal basis and predict the explained probabilities
Sample mean- instead of manual calculation, use what you've measured
<img alt="Pasted image 20240307153826 1.png" src="supplemental-files/images/pasted-image-20240307153826-1.png" target="_self">
Above is the negative antidiagonal
<br><a href=".?query=tag:Practice" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Practice">#Practice</a> this, given these colors and probabilities, what's the polarization
Simulate to get these results<br>
<img alt="Pasted image 20240307153839 1.png" src="supplemental-files/images/pasted-image-20240307153839-1.png" target="_self">
To calculate the sample mean, the zero part is times 1, one part is times negative 1 Where is the expectation value, and is the sample mean.
We know that , so we can compare against our calculated value. The difference is really small, so we probably did the math right. If I wanted to show with confidence, I'd use a statistical test to check if we're within the expected range Find the state produced: Find the measurement probabilities of We found that previously! , because , we can just plug and chug for the inner product Already found the expectation value above, it's zero!<br>
If someone just asks for the expectation value without an associated basis, you use the operator, because it's <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvectors</a> are and '
<a data-href="../Definitions/Introduction to Qbits#Qbits" href="school/physics/quantum-computing/definitions/introduction-to-qbits.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Introduction to Qbits &gt; Qbits</a><a data-href="../Definitions/Introduction to Qbits#Qbits" href="school/physics/quantum-computing/definitions/introduction-to-qbits.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Introduction to Qbits &gt; Qbits</a><br>
<a href=".?query=tag:blochsphere" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#blochsphere">#blochsphere</a><br>
<img alt="Pasted image 20240307155621 1.png" src="supplemental-files/images/pasted-image-20240307155621-1.png" target="_self"><br>
Above has the regular <a href=".?query=tag:polarization" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#polarization">#polarization</a> vectors represented as points on the bloch sphere So then what's so important about ? We have a polar coordinate system with fixed radius, means two free parameters Given the following qubit state, find the bloch parameters: We then solve for one equal to the other for both variablesNow solving for <br><a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Orthonormal Bases</a><a data-href="../Definitions/Orthonormal Bases" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Orthonormal Bases</a>
We've seen this all before! This is where the Bloch sphere still comes from!<br>
But then again, <a href=".?query=tag:Question" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Question">#Question</a>, what's so special about lambda? it's like setting the relative orientation of the axis on the two orthonormal vectors, there's a orthonormal plane that corresponds to an appropriate vector, the lambda allows us to represent a specific vector based on a relative angle, we define as This shows us the definition of the unitary! Given some state, find the orthonormal stateFind From before, we have our values of and , so we can just plug and chug, is arbitrary!If we pick This means the values for our unitary are We need to stick with this value of though, because the two unitary matrices are distinct!Because of this identity of unitariesThe useful thing about a unitary, is that we start with an orthonormal basis, we always end with an orthonormal basis.
The quality of a Unitary is both that it preserves length and relative angle, but also in it's utility in QC
Put it into IBM, see how it does<br>
<img alt="Pasted image 20240307163056 1.png" src="supplemental-files/images/pasted-image-20240307163056-1.png" target="_self">
To measure in the D/A basis, but a hadamard in it<br><img alt="Pasted image 20240307163144 1.png" src="supplemental-files/images/pasted-image-20240307163144-1.png" target="_self"><br>
<img alt="Pasted image 20240307163220 1.png" src="supplemental-files/images/pasted-image-20240307163220-1.png" target="_self">If we wanted to measure in the Unitary basis, we'd take , in IBM, you need to calculate the angles after symbolically performing the daggerNow if we want to calculate the observable, we find the matrix which has as the projection sum!<br>The observable to calculate the expectation value is the matrix who has the <a data-tooltip-position="top" aria-label="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href=".html" class="internal-link" target="_self" rel="noopener nofollow">eigenvectors</a> of both 's, and eigenvalues corresponding to The angle difference between the first and second polarizer at max polarization is 45˚. This means that is also the angle difference between the second and 3rd polarizer.
We can set up the following expression for the intensityPlugging in for the observed maximum value, we get the ideal light let through as]]></description><link>school/physics/quantum-computing/semester-1/3.1-general-qubit-states.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/3.1 General Qubit States.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.3 Density Matrices]]></title><description><![CDATA[Given the <a data-href="Bloch Sphere" href=".html" class="internal-link" target="_self" rel="noopener nofollow">Bloch Sphere</a><br>
<img alt="Bloch Sphere.png" src="supplemental-files/images/bloch-sphere.png" target="_self" style="width: 200px; max-width: 100%;">
Mixed states are probabilistic mixtures of pure states, not superpositions!Work out the density matrix of the two statesMaximally Mixed State = Horizontally with probability and vertical with probability Superposition State It is again important to note that , we have entries in the off diagonal inside the superposition state
Given a general Qubit state
The set of does NOT need to form an orthonormal basis, or any basis
Definition 3.3.1 (Born Rule for Mixed States).
The measurement outcomes are just a sum of other probabilities. Write out the sum
Then expand by the definition of the magnitude operations on a vector. is constant through the sum, and is a scalar so it is communative. Factor out and put further inside <br><a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../Definitions/Bra-Ket Notation</a><a data-href="../Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../Definitions/Bra-Ket Notation</a>Definition 2.5.2 (Expected Value).
If we prepare the same state a lot and measure the same observable, what value do we expect? By expanding the right and factoring, we can turn it into the below Note the expectation value should always be real
Definition 3.3.2 (Expectation Value of Density Matrix).
Given a density matrix and an observable , the expectation value is Example 3.3.3 (## Example).
Given the following density Matrix for a mixed quantum state
Compute the probability of obtaining D when measuring in D/A basis
Compute Expectation Value of Compute probability of D when in D/A basis
Below are the bra-ket definitions of DA Then using these, we plug into our expression and solve Compute the expected value with the X Observable <br><img alt="Pasted image 20240321161706.png" src="supplemental-files/images/pasted-image-20240321161706.png" target="_self">Exercise 3.3.4 (Answer the Following Questions).
Which if the following matrices does not represent a quantum state?
Which are pure states?
How can you tell for each?<br>
<img alt="Pasted image 20240321161926.png" src="supplemental-files/images/pasted-image-20240321161926.png" target="_self"> ]]></description><link>school/physics/quantum-computing/semester-1/3.3-density-matrices.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/3.3 Density Matrices.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.3-3.4 Quantum State Tomography]]></title><description><![CDATA[Any pure state can be written in terms of some standard basisTheorem 3.3.1 (Pauli Matrices and Density Matrix).
Any pure/mixed state can be written in terms of <a data-tooltip-position="top" aria-label="../Definitions/Pauli Matrices" data-href="../Definitions/Pauli Matrices" href="school/physics/quantum-computing/definitions/pauli-matrices.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Pauli Matrices</a><a data-tooltip-position="top" aria-label="../Definitions/Pauli Matrices" data-href="../Definitions/Pauli Matrices" href="school/physics/quantum-computing/definitions/pauli-matrices.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Pauli Matrices</a>. This is just like our previous basis What this means, is that any density matrix can be written as the sum of the expected value when measuring your quantum system with an observable, times that observable
Definition 3.3.2 (Pauli Matrix).
Any of the observables Perform single-qubit quantum state tomography (#QST)
Estimate state preparation and measurement (#SPAM) errors
<br>Mixed states <a data-tooltip-position="top" aria-label="3.2 Mixed Quantum States > Intro" data-href="3.2 Mixed Quantum States#Intro" href="school/physics/quantum-computing/semester-1/3.2-mixed-quantum-states.html#Intro_0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Mixed States</a><a data-tooltip-position="top" aria-label="3.2 Mixed Quantum States > Intro" data-href="3.2 Mixed Quantum States#Intro" href="school/physics/quantum-computing/semester-1/3.2-mixed-quantum-states.html#Intro_0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Mixed States</a> Reminder probability of observing a pure state (ket)<br>
<a data-tooltip-position="top" aria-label="3.3 Density Matrices > Born Rule for Pure/Mixed States" data-href="3.3 Density Matrices#Born Rule for Pure/Mixed States" href="school/physics/quantum-computing/semester-1/3.3-density-matrices.html#Born Rule for Pure/Mixed States" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Born Rule</a><a data-tooltip-position="top" aria-label="3.3 Density Matrices > Born Rule for Pure/Mixed States" data-href="3.3 Density Matrices#Born Rule for Pure/Mixed States" href="school/physics/quantum-computing/semester-1/3.3-density-matrices.html#Born Rule for Pure/Mixed States" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Born Rule</a><br>Expectation Value <a data-tooltip-position="top" aria-label="2.5 Calculating Observables > Expected Values > Definition" data-href="2.5 Calculating Observables#Expected Values#Definition" href="school/physics/quantum-computing/semester-1/2.5-calculating-observables.html#Expected Values" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Expectation Value</a><a data-tooltip-position="top" aria-label="2.5 Calculating Observables > Expected Values > Definition" data-href="2.5 Calculating Observables#Expected Values#Definition" href="school/physics/quantum-computing/semester-1/2.5-calculating-observables.html#Expected Values" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Expectation Value</a>Exercise 3.3.3 (Compute the expectation values for the Pauli Matricies and verify the Pauli Summation Identity Given the density matrix below). For X For Y For Z And now Verifying <br><img alt="Pasted image 20240326160527.png" src="supplemental-files/images/pasted-image-20240326160527.png" target="_self">
Normally, you're given some state generated by a circuit, and you need to measure things about it. You don't know the density matrix<br><img alt="Pasted image 20240326160616.png" src="supplemental-files/images/pasted-image-20240326160616.png" target="_self"><br>
<a href=".?query=tag:Practice" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Practice">#Practice</a> Come up with the unitary to produce this state Use QX Simulator to measure the expectation values for X,Y, Z (1024 shots) Z, we need no extra gates since the default HV <br>The expectation value is 0<img alt="Pasted image 20240326161036.png" src="supplemental-files/images/pasted-image-20240326161036.png" target="_self" style="width: 500px; max-width: 100%;"> X we need a H<br>
2. expect = -.71<img alt="Pasted image 20240326161206.png" src="supplemental-files/images/pasted-image-20240326161206.png" target="_self" style="width: 500px; max-width: 100%;">
For Y we need an <br>expect = .73 <img alt="Pasted image 20240326161259.png" src="supplemental-files/images/pasted-image-20240326161259.png" target="_self" style="width: 500px; max-width: 100%;"> From the results, estimate the density matrix <br>
4. <img alt="Pasted image 20240326163049.png" src="supplemental-files/images/pasted-image-20240326163049.png" target="_self"> What should it be theoretically <br><img alt="Pasted image 20240326162241.png" src="supplemental-files/images/pasted-image-20240326162241.png" target="_self"> Definition 3.3.4 (Fidelity). Where is what was experimentally calculated, and is what you wanted to get If you get , then it implies that A nonzero determinant means there is statistical error involved
Fidelity is the probability of getting what we expect. We want a very high fidelity
<br>A density matrix needs to to have a determinant equal to zero. If you are making a mixture of pure states, there exists a basis where it is 100% in one state over another, so it's not linearly indapendant <a href=".?query=tag:linearindependance" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#linearindependance">#linearindependance</a> Definition 3.3.5 (SPAM Error is given by **Infidelity** (for shallow state prep)).
The errors that are not within the circuit you're performing. It's mechanical errors Errors we don't expect to grow as we add gates
These errors occur before and after your circuit
They're like the y intercept as a function of the numbers of gates, if we have a lot of gates, the gates might have associated errors. We just want to know what the error with no number of gates is Density matrix estimation <br><img alt="Pasted image 20240326164239.png" src="supplemental-files/images/pasted-image-20240326164239.png" target="_self"> Corresponding Code<br>
<img alt="Pasted image 20240326164653.png" src="supplemental-files/images/pasted-image-20240326164653.png" target="_self">
]]></description><link>school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4.3 Beyond Two Qubits]]></title><description><![CDATA[
We need ways for the qubits to interact if we want to compute anything
We should be able to compute <a data-tooltip-position="top" aria-label="../Definitions/Kronecker Tensor Products" data-href="../Definitions/Kronecker Tensor Products" href="school/physics/quantum-computing/definitions/kronecker-tensor-products.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Kronecker Tensor Products</a><a data-tooltip-position="top" aria-label="../Definitions/Kronecker Tensor Products" data-href="../Definitions/Kronecker Tensor Products" href="school/physics/quantum-computing/definitions/kronecker-tensor-products.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Kronecker Tensor Products</a>
<br>Correctly represent <a data-href="4.1 Multi Qubit States" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">4.1 Multi Qubit States</a><a data-href="4.1 Multi Qubit States" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">4.1 Multi Qubit States</a> <br><img alt="../../../../../Supplemental Files/images/Pasted image 20240402164820.png" src="supplemental-files/images/pasted-image-20240402164820.png" target="_self"><br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240402164846.png" src="supplemental-files/images/pasted-image-20240402164846.png" target="_self">]]></description><link>school/physics/quantum-computing/semester-1/4.3-beyond-two-qubits.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/4.3 Beyond Two Qubits.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.1 Quantum Teleportation]]></title><description><![CDATA[
Design a circuit to perform quantum superdense coding Design a circuit to perform quantum teleportation
If you have someone trying to send a qubit to someone else, then how many digital bits can you encode? - Infinite
If I receive it, how much can you get? Like zero
<a href=".?query=tag:Question" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Question">#Question</a> - If someone sends some information to me, encoded in the basis of some qubit in a basis, and I measure in the wrong basis, where does the information go? Davis answer: You can model the system such that the qubits are also coupled to the environment, so the entropy leaks out of the system, just in a non-useful way
<br>What if we use <a data-href="Entanglement" href=".html" class="internal-link" target="_self" rel="noopener nofollow">Entanglement</a>?<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240416154918.png" src="supplemental-files/images/pasted-image-20240416154918.png" target="_self"><br>
<a data-tooltip-position="top" aria-label="../Definitions/Quantum Gates" data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Quantum Gates</a><a data-tooltip-position="top" aria-label="../Definitions/Quantum Gates" data-href="../Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Quantum Gates</a>
We constructed the above with a Hadamard, and then a control qubit to place them in a superposition
Alice and bob share some entangled qubits, and you then encode your information by applying the following operations<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240416155155.png" src="supplemental-files/images/pasted-image-20240416155155.png" target="_self">
Alice can only operate on her own bit, labeled with the subscript A. She sends it to bob.Then Bob takes his corresponding qubit with Alice's,<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240416155424.png" src="supplemental-files/images/pasted-image-20240416155424.png" target="_self">Compute Alice's four possible states<br>These are called the <a data-tooltip-position="top" aria-label="../Definitions/Bell States" data-href="../Definitions/Bell States" href="school/physics/quantum-computing/definitions/bell-states.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Bell States</a><a data-tooltip-position="top" aria-label="../Definitions/Bell States" data-href="../Definitions/Bell States" href="school/physics/quantum-computing/definitions/bell-states.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Bell States</a>Definition 5.1.1 (Bell States).
States that we can use as a basis to make quantum bits in superposition, seperable Literally do everything again in reverse Why is it shocking that we get two bits out? What's shocking is that you go from no qubits, to like 2<br>How could we do this with one qubit? You could encode two qubits in one photon with directionality stuff from <a data-href="4.1 Multi Qubit States" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">4.1 Multi Qubit States</a><a data-href="4.1 Multi Qubit States" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">4.1 Multi Qubit States</a>What if we want to transmit information about a quantum state digitally, without breaking it through measurement?Given an unknown qubit as Where the shared entanglement pair is defined asThe combined 3 qubit state isHow can we send over ?
Apply a CNOT, with C as control and A as the target. Then apply a Hadamard to qubit C.<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240416164118.png" src="supplemental-files/images/pasted-image-20240416164118.png" target="_self">
You're sending a different class of object to constrain a quantum bit. It's like analogous to a point in one space mapping to another? This is what I was thinking, but it's not super accurate hereThe thinking here was that if we could uniquely "define" a quantum state using two bits, then isn't it a direct map? Where's the extra information? Asking Davis this question, he said that the issue was more with the question itself than his ability to give an answer. Figure out his office hours
]]></description><link>school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/5.1 Quantum Teleportation.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5.2 Exam Review day!]]></title><description><![CDATA[
Don't worry about time pressure, philo "do poorly cause you don't know" Stick around for another hour post class to work on it, just skip math You can have your notes, canvas, google, etc. No communication btwn each other, no GenAI, etc Just like, be honest with your stuff
You can run VQEL to support findings! Running circuits on IBM, etc. Checking matrix math too
<a href=".?query=tag:StudyingIdea" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#StudyingIdea">#StudyingIdea</a> Make some initial solving tools to check in advance
- Expected value, takes input and , along with some gate matrix , it would be cool to make a symbolic solver for this!
We can use wolfram alpha, jupytr, etc. to check <br><img alt="../../../../../Supplemental Files/images/Pasted image 20240227160047 1.png" src="supplemental-files/images/pasted-image-20240227160047-1.png" target="_self" style="width: 500px; max-width: 100%;">Finding angles in Unitary matrix
Strategy: List What you Know
Starting with , find some unitary to get Can do a few different ways
System of equations is the best general technique
NOT gate with a negative? Just by looking In the above, b and d can be anything as long as we fix Thus, our parameters would be Since we have an option for what lambda should be, MAKE IT SIMPLE!
Just working through this and grinding would do it
<br><img alt="../../../../../Supplemental Files/images/Pasted image 20240227161146 1.png" src="supplemental-files/images/pasted-image-20240227161146-1.png" target="_self" style="width: 500px; max-width: 100%;">
(A) is the only question asking us to multiply out the gates
(B) we would just do (C) We get the eigenvects from and use that to make the unitary <br><a data-href="2.4 Quantum Observables#General Orthonormal Basis Measurements" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#General Orthonormal Basis Measurements" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.4 Quantum Observables &gt; General Orthonormal Basis Measurements</a><a data-href="2.4 Quantum Observables#General Orthonormal Basis Measurements" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#General Orthonormal Basis Measurements" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">2.4 Quantum Observables &gt; General Orthonormal Basis Measurements</a> (D) Use above trick ]]></description><link>school/physics/quantum-computing/semester-1/5.2-exam-review-day!.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/5.2 Exam Review day!.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Final Project Website Markdown]]></title><description><![CDATA[On this website, you can see the visualized result of double slit interference. On the left there is a controls panel allowing you to modify the parameters of the simulation, while on the right there is the actual result. The computations on the backend are handled by the following equation. To better understand the equation itself, let's break it up into a general envelope function, and an interference term. is our envelope function. This is the general interference pattern we would observe with only one slit present. As we increase the number of slits, the patterns still follow this general shape. The reason for this has to do with how constructive and destructive interference behave between waves.To explain , the interference term, first notice that it's this term that provides the higher frequency striping we see. Huygen's Principle says that each point on a wavefront, behaves as a point source for a spherical wave. As the wave crosses each slit, it behaves like a brand new spherical point source. More point sources, mean more interference. As we increase the number of slits, we increase the num]]></description><link>school/physics/quantum-computing/semester-1/final-project-website-markdown.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/Final Project Website Markdown.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate></item><item><title><![CDATA[Homework 1]]></title><description><![CDATA[P3- A horizontally polarized photon is passed through a half-wave plate with a fast axis of θ and then a quarter-wave plate with a fast-axis angle of ϕ to obtaina)
b)
c)
Problem 4
Problem 5
Express left and right circular states as linear combinations of diag and anti-diagUsing these definitions, first I want to be able to modify just the vertical component, so Combining these two with a factor of i lends us:1-i)D+(1+i)AProblem 6
a)]]></description><link>school/physics/quantum-computing/semester-1/homework-1.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/Homework 1.md</guid><pubDate>Mon, 20 Oct 2025 19:48:39 GMT</pubDate></item><item><title><![CDATA[1.11 Hyperfine Splitting]]></title><description><![CDATA[We talked about electron-proton magnetic moment coupling"What's finer than fine"The relation between angular momentum and magnetic moment.
For orbital angular momentum For electron spin A proton has but (not a point particle)
Mass of the proton is 2000 times larger than the electron
Because the proton has such a high , it tells us it can't be a point particle
Why does the high on the proton tell us it can't be a point particle
SR tells us that a point particle with spin must have a factor of . We can measure the proton having spin and it's factor, the only contradiction is the assumption is that it must be a point particle
Today we're going to see the effects between the coupling of the proton's magnetic moment and the electron's.The first term falls to zero because of this symmetric cancelling out between the dipoles. There are points where the electron's magnetic moment lines up with the proton's field, and points with complete disagreement. For every orthogonal part, there's a constructive; antiparallel has a parallel. Adding those contributions up (see Griffiths) goes to zero.
Through a similar argument, our second term in <a data-href="#^dipoleInteractionField" href="#^dipoleInteractionField" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dipoleInteractionField</a><a data-href="#^dipoleInteractionField" href="#^dipoleInteractionField" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.1)</a> has to be nonzero. The origin doesn't have a complement to cancel it, it's unique. The more rigorous argument is in Griffiths E&amp;M.<br>We're going to consider <a data-href="#^dipoleInteractionField" href="#^dipoleInteractionField" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dipoleInteractionField</a><a data-href="#^dipoleInteractionField" href="#^dipoleInteractionField" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.1)</a> as producing a perturbation. The perturbation looks likeThe wave-function term comes from the delta function.<br>
The dot-product uses the same trick we did in <a data-href="1.10 Zeeman Effect Cont" href="school/physics/quantum-2/notes/1.10-zeeman-effect-cont.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Zeeman Effect Cont</a><a data-href="1.10 Zeeman Effect Cont" href="school/physics/quantum-2/notes/1.10-zeeman-effect-cont.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.10 Zeeman Effect Cont</a>Our magnitudes are still goodWhere Again we're moving into a coupled basis since now the angular momentum are coupled.Our coupled basis is Our new quantum number is the coupled spin between the electron and proton.Exercise 1.11.1 (INSTAPOLL: What are the possible values for the spin quantum number when the electron is coupled to the proton spin?). ANS: (0,1) Either the spin is in total agreement or disagreement. It's a projection so it can't be negative
Solving this out, our energy correction either has Below is the expression which This energy difference and transition creates the fabled 21cm line in astrophysics. The wavelength is literally 21 cm.What causes the transition between the triplet to the singlet?
Nature wants to find ways to reach lower energy states, we talk more about it later
]]></description><link>school/physics/quantum-2/notes/1.11-hyperfine-splitting.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.11 Hyperfine Splitting.md</guid><pubDate>Mon, 10 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.12 Hyperfine Coupling]]></title><description><![CDATA[Why is the 21 cm line so important? The big bang happened, rapidly expanded really really hot and was super charged. Things then cooled off and things could recombine to become neutral hydrogen.
All of a sudden the radiation ejected when the hydrogen formed and cooled and we got the CMB
After that, stars took over. They re-ionized the hydrogen with their UV from the stars. Re-ionization is when neutral hydrogen stepped out and came back. The 21cm wavelength with the redshift lets you study this period of the universe!
We're now wanting to find the good states since is diagonalThese states turn out to be belowThe first number is the resultant magnitude quantum number, and the second number is the projection of that vector. (The arrows are the spin of the electron and proton respectively)The universe started out very small, the energy density was huge. Why didn't we just form a black hole?
It was literally everything, so it should have. But the answer is that there was no place to collapse to
Why is it that are plus anad minus?
It has to do with the phase. "Down" can mean different thing in different ways. We can still end up with a zero projection onto the axis, if our resultant vector is perpendicular. This is regardless of length We're now going to move to Clebcsh-Gordon values. To use a Clebcsh-Gordon table, the red vertical column represents your state. Your green row represents the corresponding identical quantum numbers.Exercise 1.12.1 (AT HOME: To better understand, go through this and see how you can pull [[#^7fcef6]] from this result).To get the coefficients in the table, you can then use the raising and lowering operators. Remember that the raising and lowering operators only act on the projection quantum number, it's rotating.Why is this table even useful?
If you had spin particles, then your good basis might be more complicated and require more work. This table concisely represents all the transformations for you.
How does the neutron have a magnetic moment? Isn't it neutrally charged?]]></description><link>school/physics/quantum-2/notes/1.12-hyperfine-coupling.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.12 Hyperfine Coupling.md</guid><pubDate>Wed, 12 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/KupdfnqWwV7J6.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/KupdfnqWwV7J6.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.3 Variational Principle Examples]]></title><description><![CDATA[We began talking about how to model the Helium atom using the variational principle! Someone asked me if Einstein ever tried to solve this (helium atom) problem? If he did, he never admitted his failure In the variational problems, you're normally looking for the differences between two energy levelsWe're going to start with When we're working with the hydrogen atom, and then going to modify it's Coloumb constructed Hamiltonian to be any atom with protons and one total electron.
Our Bohr radius in a single electron isEvery time we see an in hydrogen atom solutions, we'll just replace it with Does it make sense that the decay increases?
Yes! The nucleus has more charge and is thus "pulling" tighter on the electron cloud
Then for the energy from <a data-href="../../Quantum 1/Notes/3.2 Two Particles-The Hydrogen Atom#^392a4b" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html#^392a4b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.2 Two Particles-The Hydrogen Atom &gt; ^392a4b</a><a data-href="../../Quantum 1/Notes/3.2 Two Particles-The Hydrogen Atom#^392a4b" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html#^392a4b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.2.1 (The Energy level of a Hydrogen Atom)</a> <br>What is the ground state energy of the Helium Ion ?
We know that the ground state energy for the Helium atom is , and from <a data-href="#^0d7976" href="#^0d7976" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^0d7976</a><a data-href="#^0d7976" href="#^0d7976" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.3)</a> the energy goes up by . Therefore the ground state energy is What is the radius of the electron? Yeah many measurements give you a distribution, but with one measurement what is it?
It's just a point particle.
The experimental binding energy for a helium atom is -78.975 eVTheorem 2.3.1 (The Hamiltonian of the Helium Atom). The difficult part is the last component, it's not separable. You have the <br>To try and solve for the energies of <a data-href="#^b649cf" href="#^b649cf" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^b649cf</a><a data-href="#^b649cf" href="#^b649cf" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.3.1 (The Hamiltonian of the Helium Atom)</a>
The coupled electron term is the problem, so we're ignoring it so that we can treat this as a system with separate variables.<br>
Ignoring that term, our trial wavefunction with <a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.1 Variational Principle &gt; ^3f70ac</a><a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.1.1 (The Variational Principle)</a> is going to just be the product of two Hydrogen 1s states<br>Is this leading to a <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^perturbationForm</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Perturbation Theory)</a> inclusion for the coupled term?
It looks like it, but you'd be embarrassed because it's not small. But if the Pauli exclusion principle exists, how can we even put two electrons in the same state of 1s? Well we give them different spins behind the scenes Next week we're going to see the consequences of this
The first 4 terms are just what we'd get for a nucleus of charge in a single electron atom<br>Together these are the first 4 terms in <a data-href="#^b649cf" href="#^b649cf" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^b649cf</a><a data-href="#^b649cf" href="#^b649cf" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.3.1 (The Hamiltonian of the Helium Atom)</a> The physical meaning of this is that it's measuring the mutual interaction between two mutual charge distributions. Griffiths works it out in a page or so!
To do it you'd
Use the law of cosines
See class notes to get this down betterTrusting Sitz, if you plugged in everything and worked it out, and you use the # # Virial theorem you'd getNotice that the very last term isn't really that small, which is why we couldn't use perturbation theory. This is compared to the real value of , and we can see that Helium isn't two different than two superimposed 1s orbitals from Hydrogen!But what can we do to make this more accurate?
<br>Our trial wavefunction in <a data-href="#^2fcb32" href="#^2fcb32" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^2fcb32</a><a data-href="#^2fcb32" href="#^2fcb32" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.4)</a> assumed each electron felt the full strength of the full nuclear charge. Would they? <br>No! If one electron was further from the nucleus than the other, than it will feel less of a blundt. Think <a data-href="../../Electrodynamics/Notes/1.8 Gauss' Law#^50c460" href="school/physics/electrodynamics/notes/1.8-gauss'-law.html#^50c460" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Electrodynamics/Notes/1.8 Gauss' Law &gt; ^50c460</a><a data-href="../../Electrodynamics/Notes/1.8 Gauss' Law#^50c460" href="school/physics/electrodynamics/notes/1.8-gauss'-law.html#^50c460" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.3 (Gauss' Law)</a><br>
We're going to make in a variational parameter! (NOT in , that one is constant). To do this, you'd only change the in <a data-href="#^32e3c6" href="#^32e3c6" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^32e3c6</a><a data-href="#^32e3c6" href="#^32e3c6" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.5)</a>.
At worst, you'd find was the best answer, but hopefully there's something better! We'll see that next week. ]]></description><link>school/physics/quantum-2/notes/2.3-variational-principle-examples.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.3 Variational Principle Examples.md</guid><pubDate>Fri, 07 Mar 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/PjaQrF9J53UvTS2PPa.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/PjaQrF9J53UvTS2PPa.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.13 Spin Statistics and Molecules]]></title><description><![CDATA[The value of at room temperature Rotational states in have phase There is a part of the wave-function which contains the proton energyThe whole wave-function isThis is where the behaviors of new colors comes from! The exchange symmetries of the hydrogens means different nuclear energy states. This is why long hydrocarbon chains are common in biological pigments, since you can have different nuclear energy states
]]></description><link>school/physics/quantum-2/notes/2.13-spin-statistics-and-molecules.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.13 Spin Statistics and Molecules.md</guid><pubDate>Mon, 07 Apr 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[🟩 Overall Quantum Computing Class Notes 🟩]]></title><description><![CDATA[Hey y'all! These are my notes from when I took the Quantum Computing FRI Stream at UT from '23-'24. At the time I was still adjusting to typing my notes in real time so they might be a bit messy. If you have any corrections for them let me know, I hope they help!
You can navigate them by unit using the table below. ]]></description><link>school/physics/quantum-computing/semester-1/🟩-overall-quantum-computing-class-notes-🟩.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Semester 1/🟩 Overall Quantum Computing Class Notes 🟩.md</guid><pubDate>Mon, 20 Oct 2025 19:48:38 GMT</pubDate></item><item><title><![CDATA[Hidden Variables and Bell's Inequality]]></title><description><![CDATA[Notes regarding the topic of Bell's inequality, which was shown to prove a lack of hidden variables, i.e that things don't have states before measurementDefinition 1 (Hidden Variable Theory).
A hidden variable theory conjectures that behind any "collapse of quantum state", there are some hidden variables at play behind the scenes, that simply seem probabilistic to us. If we were to know how they worked, we could know for certain what our <a data-href="Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Semester 1/5.1 Quantum Teleportation &gt; ^9fbf0d</a><a data-href="Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5.1.1 (Bell States)</a> states would collapse to.
Definition 2 (Bohmian Mechanics).
Essentially a particle in superposition has some "real" location, which is simply guided by the behavior of the superposition. For this to work, we need a rule on how the "guiding" works. The rule must have the property that if anyone does measure the particle, they'll see what QM predicted for it. This theory is a Nonlocal Hidden Variable Theory Given two wave-functionsWhere there exists a unitary transformationA hidden variable theory assumes that there is also a stochastic matrix such that we can find a linear transformation between the probabilities associated with , and the probabilities associated with <br>Definition 3 (Stochastic Matrix). Any such linear transformation that, unlike <a data-tooltip-position="top" aria-label="Semester 1/2.4 Quantum Observables > ^500f42" data-href="Semester 1/2.4 Quantum Observables#^500f42" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#^500f42" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">The Unitary Matrix</a><a data-tooltip-position="top" aria-label="Semester 1/2.4 Quantum Observables > ^500f42" data-href="Semester 1/2.4 Quantum Observables#^500f42" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#^500f42" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">The Unitary Matrix</a>, preserves the 1-norm over the 2-norm. The columns are probability vectors, so it describes transitions from one stte to another based on probabilities. The -born rule matrix represents your "real" state, the is the "rule", and probability vector is the measured state. There is an infinite amount of transformations which can satisfy the born rule. The above notation is written discretely, but if we take , (which is an infinite dimensional space, a Hilbert space), then we can use this to describe a continuous differential equation.<br>This means you can extend this idea to describe the motion of the particle over time, while still satisfying <a data-tooltip-position="top" aria-label="Semester 1/4.1 Multi Qubit States > ^1f115f" data-href="Semester 1/4.1 Multi Qubit States#^1f115f" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html#^1f115f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">The Born Rule</a><a data-tooltip-position="top" aria-label="Semester 1/4.1 Multi Qubit States > ^1f115f" data-href="Semester 1/4.1 Multi Qubit States#^1f115f" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html#^1f115f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">The Born Rule</a>.One issue that was had with this, is that we still get the weird non-local behavior from entanglement. If we have two entangled quantum states, collapsing one collapses the other, regardless of distance. It is not useful for faster-than-light information transfer for the same reason regular entanglement isn't.This isn't local variable, because there is an exact response from Bob, based on Alice's behavior. In a local hidden variable theory, all entanglement represents is some communication between two particles, where they both share rules on how they respond. Given qubit bob, and qubit Alice, let's say they high five (become entangled). Then when they high five, Bob morse-codes a random way for Alice to respond. The map between an interaction, and an output for both Alice and Bob, is random. But it only is decided at the beginning, so entanglement is just the fact they already communicated.<br>Notably, this isn't <a data-tooltip-position="top" aria-label="^23fe58" data-href="#^23fe58" href="#^23fe58" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Bohmian mechanics</a><a data-tooltip-position="top" aria-label="^23fe58" data-href="#^23fe58" href="#^23fe58" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Bohmian mechanics</a>, because the actual measurement itself isn't probabilistic. You'd have no way of knowing what the map was, but the map is fixed.Definition 4 (Bell's theorem).
Bell's theorem was written to prove that all hidden-variable theories must be non-local.
Bell was the first to ask: do local hidden variables have any empirical consequences that disagree with the predictions of
quantum mechanics? Is there an actual experiment that could
rule out the possibility of local hidden variables?
<br>Definition 5 (CHSH Game).
<img alt="../../../../Supplemental Files/images/Pasted image 20240711142824.png" src="supplemental-files/images/pasted-image-20240711142824.png" target="_self">
Charlie gives a single digit 0 or 1 to Alice, represented by , and another random digit to Bob. Alice picks some response from that , and Bob picks . To win the game AND should be equal to XOR .
or the same thing is If Alice and Bob are working with a local hidden variable theory, they agree on a strategy in advance. In this case, the strategy is<br><img alt="../../../../Supplemental Files/images/Pasted image 20240711143647.png" src="supplemental-files/images/pasted-image-20240711143647.png" target="_self">Given random , Alice and Bob will 75% of the time at. (In red, they lose the game)
This describes local realism, because Alice and Bob's response is only ever probabilistic of each other. Alice having a zero in Strategy 2, doesn't necessarily mean Bob picks 1. They aren't influencing each other at non-local distances.If we have a non-local hidden variable theory, and Alice and Bob have access to a pre-shared Bell pair , then they have an ability to win asOne bell inequality, is this difference between the classical probability, and the quantum probability. First, Alice measures in and Bob measures in .
The notation of just implies a phase offset off the standard rotation
Why Alice always goes first, then below this is what we doTo then measure our win rate, we need to analyze 2 cases. To win this case, Alice and Bob should return or To win this case Alice and Bob should return or <br>
It happens that when Bob is offset from the <a data-tooltip-position="top" aria-label="Definitions/Quantum Gates" data-href="Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">$Z$ observable</a><a data-tooltip-position="top" aria-label="Definitions/Quantum Gates" data-href="Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow"> observable</a>, the probability on both these is In general, we define the win rate as Which is to say, the sum of the product of the probability of getting $b$ given it's $a$, times the probability of $a$. Both $a,b$ are the combos needed to win the game at the win products.qyaA
If Bell's inequality is true, ]]></description><link>school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html</link><guid isPermaLink="false">School/Physics/Quantum Computing/Hidden Variables and Bell's Inequality.md</guid><pubDate>Mon, 20 Oct 2025 19:48:38 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Syllabus is <a data-tooltip-position="top" aria-label="../Class Official Files/PHY362k_Day1.pdf" data-href="../Class Official Files/PHY362k_Day1.pdf" href="school/physics/quantum-2/class-official-files/phy362k_day1.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Official Files/PHY362k_Day1.pdf" data-href="../Class Official Files/PHY362k_Day1.pdf" href="school/physics/quantum-2/class-official-files/phy362k_day1.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a><br>
Textbook is <a data-tooltip-position="top" aria-label="../../Quantum 1/Class Content/GriffithsQuantum.pdf" data-href="../../Quantum 1/Class Content/GriffithsQuantum.pdf" href="school/physics/quantum-1/class-content/griffithsquantum.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../../Quantum 1/Class Content/GriffithsQuantum.pdf" data-href="../../Quantum 1/Class Content/GriffithsQuantum.pdf" href="school/physics/quantum-1/class-content/griffithsquantum.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a>
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Midterm Exam #1 🆔 PHY362K ⏳ 2025-02-28 🔺 <br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Midterm Exam #2 🆔 PHY362K ⏳ 2025-04-18 🔺 <br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Final Exam 🆔 PHY362K 1:00PM-3:00PM ⏳ 2025-05-05 🔺 <br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Prelecture Assignment 🆔 PHY362K 🔽 🔁 every week 📅 2025-01-21
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Prelecture Assignment 🆔 PHY362K 🔽 🔁 every week 📅 2025-01-14
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Prelecture Assignment 🆔 PHY362K 🔽 🔁 every week 📅 2025-01-17
Office Hours W 2:00-3:30, Tu 2:00-3:30 or by appointment
In class exams, missing one exam increases the final weight by that proportion.
The exams won't be calculational in nature.
If the final exam score is higher than a midterm, the final replaces the midterm.
The final is cumulative
Before every class there's a pre-lecture assignment. Those are do at 10:00am day of the lecture. Participation matches the homework in weighing
Formulas are going to be given to us before the exam so we don't need to memorize them.
The discussion section just has him give us a problem, and we work it out in small groups.
We're responsible for what's inside the grading document.
Doing any kind of inner product over an operator like the belowBro doesn't know about Sympy who's gonna tell him about the best thing to ever exist?For anyone who isn't me reading these notes, I very much like this prof and this is mostly an inside joke with myselfHow do we go about fixing our existing model of the hydrogen atom?Definition 3.3.2 (Perturbation Theory).
Let's say we have a hamiltonian, with a spectrum we know. A perturbation is something really small. Small means a distance in relation to another. Perturbation Theory is how to find answers to problems which are close to simple ones.
Time dependent perturbation theory, when the hamiltonian is time evolving
Variational Principle This is really important in analytical chemistry, and can help us find out how to solve multi-electron systems (Like the helium atom!!).
Helium Atom
Hydrogen Molecule Ion ()
More molecules
My claim to you is that when you learn about forms, you will know more about chemical bonds than 99% of chemistry majors<br>The rest of the day is revisiting <a data-tooltip-position="top" aria-label="../Class Official Files/PHY362K_Spring25_Day1_Review-1.pdf" data-href="../Class Official Files/PHY362K_Spring25_Day1_Review-1.pdf" href="school/physics/quantum-2/class-official-files/phy362k_spring25_day1_review-1.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">this</a><a data-tooltip-position="top" aria-label="../Class Official Files/PHY362K_Spring25_Day1_Review-1.pdf" data-href="../Class Official Files/PHY362K_Spring25_Day1_Review-1.pdf" href="school/physics/quantum-2/class-official-files/phy362k_spring25_day1_review-1.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">this</a> document.Time has a special position in quantum mechanics, it's not like other operators like position
Why?
Will talk about later Why does the Schrödinger equation use ?
Because from classical physics, we know that energy is conserved. A conserved quantity is easier to model against
When the potential is time invariant, then you can separate time from the position.<br>Also reviewed <a data-href="../../Quantum 1/Notes/1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.10 Harmonic Oscillation &gt; ^dbc3f4</a><a data-href="../../Quantum 1/Notes/1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.10.2 (Raising and Lowering Operator)</a> ]]></description><link>school/physics/quantum-2/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/0.1 Introduction.md</guid><pubDate>Mon, 13 Jan 2025 00:00:00 GMT</pubDate><enclosure url="https://media1.giphy.com/media/yjN7s3fOXtdimCTPrk/200w.webp?cid=dda24d50beyqyx7wdwnfrq49pgzivdi6tczm0k1igtaycker&amp;ep=v1_internal_gif_by_id&amp;rid=200w.webp&amp;ct=g" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://media1.giphy.com/media/yjN7s3fOXtdimCTPrk/200w.webp?cid=dda24d50beyqyx7wdwnfrq49pgzivdi6tczm0k1igtaycker&amp;ep=v1_internal_gif_by_id&amp;rid=200w.webp&amp;ct=g"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.1 Revisiting Perturbation Theory]]></title><description><![CDATA[We're spending this first class day revisiting the relevance of perturbation theory. In advance of class we were told to read Griffiths Chapter 10.1 Perturbation theory and first order.Perturbation is like a brand new car with a flat tire. We want to fix the tire, not throw out the car.With perturbation theory, how can we explicitly charecterize the associated error given the relative magnitude of the perturbation? In quantum 1, Professor Fischler mentioned that epsilon had to be small within the boundary, but is it possible to see how the error for a fixed order approximation grows, as a function of the size of epsilon? Additionally, does higher order approximation solve that problem? For any possible epsilon, can I approximate it to n terms with arbitrary desired perturbation? (Like, does the perturbation&nbsp;have to be small, or can it be big if I'm up for more work)
You just personally decide what small is
Another good use of perturbation theory, is that you often don't know the value of the perturbation. Perturbation theory is good because it helps you work around that when you discover a perturbation, without having to throw all your work out.These are called fine structure. The hydrogen atom needs some corrections added to it to be able to predict those energies!
Definition 3.3.2 (Perturbation Theory).
Let's say we have a hamiltonian, with a spectrum we know. A perturbation is something really small. Small means a distance in relation to another. If the orders of correction does not converge as you go higher, perturbation theory will not work. The higher order corrections must become smaller.We then take our representations of the state and energies, and we're going to start expanding the independent Schrödinger equation <a data-href="#^timeIndependantSch" href="#^timeIndependantSch" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^timeIndependantSch</a><a data-href="#^timeIndependantSch" href="#^timeIndependantSch" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.1.2)</a> . We want to look for terms with the same powers of lambda.The terms with areThis is the new car.<br>Proof of <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^c15950</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.3 (First Perturbed Energy)</a>.
Now lambda to the first, and taking terms which have lambda to the first. Collecting the terms which only have in them we get<br>The first took in the toolbox of every quantum mechanic, is multiplying all of <a data-href="#^firstOrderCorrectionExpanded" href="#^firstOrderCorrectionExpanded" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^firstOrderCorrectionExpanded</a><a data-href="#^firstOrderCorrectionExpanded" href="#^firstOrderCorrectionExpanded" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.1.4)</a> by and integrateHe uses a different braket notation to denote the occurrence of an integral. See the above underline as an example This is actually identical to the existing dirac notation, it just makes it specific on what the operator can act on at all
The operators are ONLY* ever operating on the item to their furthest right. Chapter 3 section 2 in Griffiths will help us reduce the leftmost term. HAS to be hermitian, so it can drift into the bra perfectly fine. <br>Now that we made that switch, we can now start substituting things in from <a data-href="#^wholeThind1" href="#^wholeThind1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^wholeThind1</a><a data-href="#^wholeThind1" href="#^wholeThind1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.1.5)</a> and <a data-href="#^hermetianTrick" href="#^hermetianTrick" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^hermetianTrick</a><a data-href="#^hermetianTrick" href="#^hermetianTrick" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^hermetianTrick</a>□To find the first orderNow from here, is the probability distribution of the particle in the box from the previous order. In the zeroth order, the particle only had a 50% shot of being on the right! Therefore, that integral just goes to Therefore the energy that our particle occupies after the first order correction is just half the energy of the top of the hill! The overall change to the energy of the state is just !Sitz is good at teachingNow what happens with different quantum numbers in this system? Well good news we made no specific "What if that bump were not on one side, but in the middle? That will be a homework problem"
The state will have a probability of 0 at the middle! This allows you to learn about where the perturbation is based on which energy levels get affected by it!
]]></description><link>school/physics/quantum-2/notes/1.1-revisiting-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.1 Revisiting Perturbation Theory.md</guid><pubDate>Mon, 13 Jan 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.3 Second Order Perturbation Theory]]></title><description><![CDATA[We're looking at states where we manually perturb the state with , as opposed to it being the natural state. We assume that our perturbation expansion works.NOTE: We made a small notation swap. Unless otherwise specified, the exponent now corresponds to the order of a correction with operators and vectors in Hilbert space. This note is a rehash of <a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory" data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory</a><a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory" data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">3.3 Introduction to Perturbation Theory</a>We're using the fact that all possible solutions, can be constructed by linearly independent solutions.
Theorem 3.3.4 (First Perturbed Wave-function). Why physically is there the energy difference in the denominator
When you do the math, that's just how it shakes out. The other thing, is to look at the units. The coefficients in the wave-function combinations has to be energy independent. The units have to cancel out energy.
The other way to think of it, is that is already known to be small called (called squiggle in this class). represents the fact that the wave-functions on a bound state are oscillatory. If two states. arefar apart in energy, one wiggles alot, and one doesnt wiggle at all. They won't combine well. Terms which are similar frequencies combine really well.
In theory. Because of the wiggles on the energies match perfectly, we get a division by zero error,. In that event, we need degenerate perturbation. theory. are both at the same energies which means all their linear combinations are the same energy. <br>From <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^completenessClaim" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^completenessClaim" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^completenessClaim</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^completenessClaim" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^completenessClaim" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.11)</a> we can see that our higher energy states become involved once we introduce perturbations. This is the basis of thinking about transitions. If I want to force a system evolve to a different state, we manually introduce a perturbation for the system, which because of this can evolve it to a higher energy. An example of this is a photon hitting an atom with an electron. The electron is perturbed, and evolves to a higher energy state. Theorem 3.3.5 (Second Perturbed Energy). In the ground state, the second perturbed <br>Why might you want the second order perturbed energy (the terms).
Sometimes you might want to calculate for a higher order to be sure that your terms do get smaller. Or your first order correction to the energy is zero like it was in <a data-href="../../Quantum 1/Tests/Final#Problem 2" href="school/physics/quantum-1/tests/final.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Tests/Final &gt; Problem 2</a><a data-href="../../Quantum 1/Tests/Final#Problem 2" href="school/physics/quantum-1/tests/final.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">../../Quantum 1/Tests/Final &gt; Problem 2</a>
<br>Proof of <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a>.
To do this, we're going back to the previous system and finding the terms quadratic in lamdbaTo identify our second order terms, use the
Definition 1.6.2 (Schrödinger Equation). Also written as The only condition you need to solve this equation, is Where is a Unitary, is the identity, and is the hamiltonian of the Hamiltonian Our goal is to getThe next term on the right is Our next move is going to be taking the bra of on this, which is encouraging because our very last term is the corresponding ket. For the With the total quadratic term<br>Now for the second term on the middle of the left, we have <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^c15950</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.3 (First Perturbed Energy)</a> which we can use to expand there. in the first order energy, whcih means they are always orthogonal.<br>This finally gets us <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a>
□How do we go about reducing this further?<br>Exercise 1.3.1 (Given a particle in the below potential, what is the first order correction to the energy going to look like? Would it increase the energy, keep it at zero, or reduce it?). Answer Only second order corrections have an influence over the center. The odd functions get integrated over an odd potential symmetrically, which means that it's zero. We extend this from <a data-href="../../Quantum 1/Notes/2.1 Motion in Potential Function, and Pairity#^c9c667" href="school/physics/quantum-1/notes/2.1-motion-in-potential-function,-and-pairity.html#^c9c667" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/2.1 Motion in Potential Function, and Pairity &gt; ^c9c667</a><a data-href="../../Quantum 1/Notes/2.1 Motion in Potential Function, and Pairity#^c9c667" href="school/physics/quantum-1/notes/2.1-motion-in-potential-function,-and-pairity.html#^c9c667" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.1.3 (Pairity)</a> Definition 2.1.3 (Pairity).
We're going to define a term parity. Where you define the operator This is just like if functions are odd or even
Applying a particle in an electric field is just like this! You can then know right off the bat that the potential is then odd in parity. We can produce an electric field across the box so that it's anti-symmetric. We're basically doing first order perturbation theory on the perturbed wave-function when we have potentials like this. The first order just normalizes the probability distribution.<br>Weird thing from <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> : The second order corrections to the ground state always lower it. Shoutout <a data-tooltip-position="top" aria-label="../../../../Personal/People/Ayden Gertiser" data-href="../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Ayden</a><a data-tooltip-position="top" aria-label="../../../../Personal/People/Ayden Gertiser" data-href="../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Ayden</a> for noticing that. The first order term can be positive or negative
If I have a particle in a high potential, with no perturbation, what makes it fall back to the ground state??
Yes it emits a photon, but we need to be perturbed to fall in the first place.
THE VACUUM PERTURBS IT!! The EM field is a bunch of simple harmonic oscilators
If there's energy there but it can't do work, then how is it energy?]]></description><link>school/physics/quantum-2/notes/1.3-second-order-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.3 Second Order Perturbation Theory.md</guid><pubDate>Wed, 22 Jan 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.4 Degenerate Perturbation Theory]]></title><description><![CDATA[Similar copy of the notes in <a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory" data-href="../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory" href="school/physics/quantum-1/notes/3.6-final-day-and-degenerate-perturbation-theory.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.6 Final Day and Degenerate Perturbation Theory</a><a data-tooltip-position="top" aria-label="../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory" data-href="../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory" href="school/physics/quantum-1/notes/3.6-final-day-and-degenerate-perturbation-theory.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">3.6 Final Day and Degenerate Perturbation Theory</a> from Quantum 1How can we look at a problem and know there will be a degeneracy.
A symmetry A square box has and interchangeable
There will be degeneracies in the hydrogen atom Now we know that Sitz's Texas password is a bunch of dots How would I apply a perturbation to break this symmetry in the box?
Applying a potential off-center
For a particle in 2D square box, we can try separating the variables to two separate wave-function solutions.The ground state is never degenerate!If I have two degenerate states, any one of them solves the schrödinger equation.<br>Our concern form before was that our denominator in the <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> We want to do the same perturbation theory with itGiven our wave-function is the two degenerate wave-functions .We're applying our go-to trick with , then later with . <br>Sanity check, if was zero, we reduce to first order perturbation theory since it's the normal expected value. <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^c15950</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.3 (First Perturbed Energy)</a> .We're using the following notationthen^prev<br>
We can find a value from alpha to solve for this system: from <a data-href="#^ca17f5" href="#^ca17f5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^ca17f5</a><a data-href="#^ca17f5" href="#^ca17f5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^ca17f5</a>. This gives us our quadratic equation in when plugged back in!
The energies are essentially just eigenvalues of our matrix!
You can see that there's an identity hidden inside the ! This is just an energy term, which has to be real!. If the terms have to be real, and are complex conjugates they are the same as each other!
<br>Can you make the following reduction using <a data-href="#^notation" href="#^notation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^notation</a><a data-href="#^notation" href="#^notation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.4.4)</a>? We also know. that so <br>From the energies, we already know that the expectation value is non-zero. If it was zero there would be no problem! We're using language associated with matrices, and you can read more about that in <a data-href="../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory#^fischlerMatrixIntro" href="school/physics/quantum-1/notes/3.6-final-day-and-degenerate-perturbation-theory.html#^fischlerMatrixIntro" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory &gt; ^fischlerMatrixIntro</a><a data-href="../../Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory#^fischlerMatrixIntro" href="school/physics/quantum-1/notes/3.6-final-day-and-degenerate-perturbation-theory.html#^fischlerMatrixIntro" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.6.9)</a>You know what's fun, is that there is a similar thing in density matrices where the weirdness comes from your off-diagonal terms. The units of a density matrix is just probability, but I wonder if there is a connection beyond diagonalization.This means our new goal, is to diagonalize our matrix! We want to find better basis states. If your off-diagonal terms are zero, then your states are already diagonalized! That The reason we need basis states is that otherwise our terms aren't linearly independent. This is just like if you were measuring in the Z observable with a D photon. The Z observable is the basis where we have the degeneracy, but with the change of basis we now measure in one that can distinguish. We've rotated to DA]]></description><link>school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.4 Degenerate Perturbation Theory.md</guid><pubDate>Fri, 24 Jan 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.6 Fine Structure in the Hydrogen Atom]]></title><description><![CDATA[<img alt="Spectrum of Atomic Hydrogen > Experiment 21 from Advanced Physics with ..." src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.vernier.com%2Fwp-content%2Fuploads%2F2019%2F12%2Flab.PHYS-ABM-21-hydrogen_spectrum.001.png&amp;f=1&amp;nofb=1&amp;ipt=9b26b1e3ed8f3085005f3a81beeaabb1bdadbaa1ce199d33d8b7fbc9b64ce2f8&amp;ipo=images" referrerpolicy="no-referrer" target="_self" class="is-unresolved">
Our goal is to figure out what's going on with those left two-most lines, those are the fine structure.
What we're looking at today isn't the cause of this splitting.<br>We model the hydrogen atom with a coulomb potential, see <a class="original-internal-link" data-href="../../Quantum 1/Notes/3.2 Two Particles-The Hydrogen Atom.md" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html" target="_self" rel="noopener nofollow" style="display: none;">3.2 Two Particles-The Hydrogen Atom</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum 1/Notes/3.2 Two Particles-The Hydrogen Atom.md" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html" target="_self" rel="noopener nofollow">3.2 Two Particles-The Hydrogen Atom</a> for more details.We find once you solve for the spectrum of the hydrogen atom, that the energy only depends on the quantum number .Theorem 3.2.1 (The Energy level of a Hydrogen Atom). is the mass of the electron, is the charge of it, is planks constant, and is the quantum number The alternative way to write this expression with some rearrangement, you writeThe fine structure constant is the value of !The number of degeneracies in the hydrogen atom goes by . We know that the splitting of the transition lines is due to some internal <br>Correction terms are going to become which are (special) relativistic in the origin. The issue with <a data-href="#^h0" href="#^h0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^h0</a><a data-href="#^h0" href="#^h0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.6.1)</a> is that we didn't incorporate terms associated with special relativity!The kinetic energy operator, the momentum part, is not consistent with SR. We're going to expand from our guy Einstein.We're going to expand our square root via taylorThe KE in a spherically symmetric potential is An aside: Can we even use perturbation theory? Is this "small"?
To show that the perturbation is small, we have to calculate . We know that momentum is just , so As long as the electron's velocity is small compared to the speed of light, we can use perturbation theory!
To get that, we use Virial's Theorem, which states that in a spherically symmetric potential, the kinetic energy is We know the potential of an electron in hydrogen, so once we actually calculate the velocity using the mass, we find that That means we're clear to use perturbation theory!
We're going to use that second order term, Now to calculate our first corrected energyWhy are the expectation values not including ? Well this is a spherically symmetric potential, so the parts of the state don't get uniquely acted on. The expectation value over those parts is zero. As for notation, not having implies that we don't need to include it in our expectation value, because of this previous reason. <br>Doing the expectation values for is messy and complicated. He will give some intuition though. This is much like how we solved <a data-href="3.2 Two Particles-The Hydrogen Atom#^recursiveRatio" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html#^recursiveRatio" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.2 Two Particles-The Hydrogen Atom &gt; ^recursiveRatio</a><a data-href="3.2 Two Particles-The Hydrogen Atom#^recursiveRatio" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html#^recursiveRatio" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.2.8)</a>: these are complicated integrals, but in principle we could solve it through a power series!Above is our relativistic correction to the energy levels of the hydrogen atom. The energy correction changes depending on the and quantum number! That means it's observable! The spacing is shifted from what regular Schrödinger would give!<br>
Because of how is bounded, the difference in the energy seen inside <a data-href="#^relEnergy" href="#^relEnergy" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^relEnergy</a><a data-href="#^relEnergy" href="#^relEnergy" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.6.7)</a>]]></description><link>school/physics/quantum-2/notes/1.6-fine-structure-in-the-hydrogen-atom.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.6 Fine Structure in the Hydrogen Atom.md</guid><pubDate>Wed, 29 Jan 2025 00:00:00 GMT</pubDate><enclosure url="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.vernier.com%2Fwp-content%2Fuploads%2F2019%2F12%2Flab.PHYS-ABM-21-hydrogen_spectrum.001.png&amp;f=1&amp;nofb=1&amp;ipt=9b26b1e3ed8f3085005f3a81beeaabb1bdadbaa1ce199d33d8b7fbc9b64ce2f8&amp;ipo=images" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.vernier.com%2Fwp-content%2Fuploads%2F2019%2F12%2Flab.PHYS-ABM-21-hydrogen_spectrum.001.png&amp;f=1&amp;nofb=1&amp;ipt=9b26b1e3ed8f3085005f3a81beeaabb1bdadbaa1ce199d33d8b7fbc9b64ce2f8&amp;ipo=images"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.8 Complete Fine Structure]]></title><description><![CDATA[Why is the magnetic moment in an electron much larger to the proton?
Magnetic moment is inversely proportional to mass
The hamiltonian couples the directions of and . This means the magnitudes are still good, l but the quantum numbers and are not. What is a "good quantum number"? Why aren't , good?
This is because now the operators don't freely commute. Knowing one quantum number means you can't know the other. The projection of those numbers onto are good, but we don't really get anything useful form them. That means that our only good remaining quantum numbers are and . (Direction and magnitude quantum numbers).
An Aside
Last time, we learned about a new operator where <img alt="Diagram of the new vector" src="https://chem.libretexts.org/@api/deki/files/90875/379px-LS_coupling.svg.png?revision=1&amp;size=bestfit&amp;width=321&amp;height=343/%7Ccenter" referrerpolicy="no-referrer" target="_self" class="is-unresolved">
A good quantum number is one which isn't coupled together. What makes good is that despite the coupling, it's a vector sum and is itself unique despite it's linear combination being non-unique. my head feels like its filled with water
Oh shit molecules can have dozens of angular momentum vectors because everything can move freely.The good quantum numbers in our system areThen we get the complete fine structureTheorem 1.8.1 (The Complete Fine Structure Energy in the Hydrogen Atom). Where alpha is the fine structure constant. .
To conserve angular momentum, the angular momentum number in transitions must change by 1Today we're evaluating this for a few casesPrinciple quantum number first, then the exponent is the multiplicity, then get's it's own label! That's called because the chemists are despicable. s means spherical : is for principle : is for diffuse
etc.
The broad formula is Are there any degeneracies left in our system? YES! Spin degeneracies and .
How would we break it? With a magnet! That's sneak peak for next class. With that, almost all the degeneracies in the problem are broken.
The quantum numbers are magnitude!! That's why it is . For agnitude.
This perturbation is internal. The things left out of the original hamiltonian. The solution we saw in quantum 1 didn't account for the effects of special relativity. For in the hydrogen atom, we can get Can you use this to make a better transistor?
"If you don't know about spin-orbit interactions, you have no hope of understanding the semi-conductor. I can't say you'll use this to make a better transistor, but you use this to make a transistor that works"
How do you know which of those new energy states are wide enough you can measure?
That's called a selection rule! The selection rule says for us to be able to see a new energy level, Why?
You need to conserve momentum. Can't go from a momentum to momentum
You can't go from to another . What you can do is go from any energy to . When you calculate that from , you find that there are 5 possible transitions! Below is what they are:<br>
<img src="supplemental-files/images/pasted-image-20250203134958.png" target="_self">]]></description><link>school/physics/quantum-2/notes/1.8-complete-fine-structure.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.8 Complete Fine Structure.md</guid><pubDate>Mon, 03 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://chem.libretexts.org/@api/deki/files/90875/379px-LS_coupling.svg.png?revision=1&amp;size=bestfit&amp;width=321&amp;height=343/%7Ccenter" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://chem.libretexts.org/@api/deki/files/90875/379px-LS_coupling.svg.png?revision=1&amp;size=bestfit&amp;width=321&amp;height=343/%7Ccenter"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.10 Zeeman Effect Cont]]></title><description><![CDATA[We talked about the Zeeman effect given a strong magnetic field, and it's application to solar photogrametry.From last time, we see that the Zeeman effect is smaller than fine structureFer how many states does it split into with a magnetic field. I put two, but it's not.
, which is what the energy is dependent on. can be zero or 1, and there's different values of which would make our into . That means we get splitting
To identify which line is which, you use <a data-href="1.9 Zeeman Effect.md#^gfactorZeeman" href="school/physics/quantum-2/notes/1.9-zeeman-effect.html#^gfactorZeeman" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Zeeman Effect.md &gt; ^gfactorZeeman</a><a data-href="1.9 Zeeman Effect.md#^gfactorZeeman" href="school/physics/quantum-2/notes/1.9-zeeman-effect.html#^gfactorZeeman" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.5)</a>
We reviewed for the weak case, but now the strong case.With a strong enough external field, and precess around our oriented fieldThe perturbation becomes<br>with an energy involving <a data-href="1.9 Zeeman Effect.md#^gfactorZeeman" href="school/physics/quantum-2/notes/1.9-zeeman-effect.html#^gfactorZeeman" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Zeeman Effect.md &gt; ^gfactorZeeman</a><a data-href="1.9 Zeeman Effect.md#^gfactorZeeman" href="school/physics/quantum-2/notes/1.9-zeeman-effect.html#^gfactorZeeman" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.5)</a> For a state , what is ?
We don't have the magnitudes of the other vectors, so it implies we're precessing. If we're precessing, the average value of and is zero.
How would you prove this?
You'd use raising and lowering operators associated with angular momentum. Recall: Those operators raise and lower .
You can write as that superposition, apply it to the state, then take the inner product Where before to get the spin-orbit coupling term we need those expected values. We just proved they're independent! is no longer diagonal in either matrix. Pick one and compute all elements of Diagonalize
Good states are combination that depend on Griffiths has the results
This is how we measure the strength of sunspots! We look at the emission lines from the different energy levels, and then predict the field strength that would be required to create that spectrum<br>
<img src="supplemental-files/images/pasted-image-20250207135050.png" target="_self">]]></description><link>school/physics/quantum-2/notes/1.10-zeeman-effect-cont.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.10 Zeeman Effect Cont.md</guid><pubDate>Fri, 07 Feb 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.13 Double Well Problem]]></title><description><![CDATA[We're using tricks we've already learned, on some new things
<img src="supplemental-files/images/pasted-image-20250214131342.png" target="_self">
Happy valentines day chat
ALSO WE REFERENCED MOLECULAR BONDS<br>What's different form the infinite box? <a class="original-internal-link" data-href="../../Quantum 1/Notes/1.11 The Bound State Problem.md" href="school/physics/quantum-1/notes/1.11-the-bound-state-problem.html" target="_self" rel="noopener nofollow" style="display: none;">1.11 The Bound State Problem</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum 1/Notes/1.11 The Bound State Problem.md" href="school/physics/quantum-1/notes/1.11-the-bound-state-problem.html" target="_self" rel="noopener nofollow">1.11 The Bound State Problem</a>
We can be outside the box
Infinitely many states inside an infinite well, finite number of bound states
Can you ever make the well so shallow that there are no states in it?
Nope, there's always at least one!
The energy doesn't go by the quantum number squared anymore There is a lot of the wave-function outside the well, where it's potential energy exceeds the potential energy.
Outside the well, the wavefunction is always an exponential decay. Plus outside the box at the edge, we get an inflection point!
Imagine that we brought in another well, and slowly moved it next to our current well. Can we use perturbation theory to calculate the new energy?Why does it have to be slow? He made it a point to point out that it basically crawled it's way here
This will be answered later when we talk about time elements
Theorem 3.3.3 (First Perturbed Energy).
The first order correction to the energy on the th energy level is just the expectation value of the perturbation in the unperturbed state The complication comes in because of the stipulation that the wells are identical. There would be a bound state within the new well, which has it's own bound state. It would have it's own energy
This might need to be a degenerate perturbation theory It's a bit questionable, but let's see where it goes.
The diagonals make sense to be equal, since in the reference frame of our perturbation well, the original is perturbing it.<br>
<img src="supplemental-files/images/pasted-image-20250214133801.png" target="_self"> CHAT WE'RE DOING MOLECULAR BONDING Now we need to compute the off-diagonal elements to see what the good elements are for this stateTo get Isn't this just getting the first order energy correction?
No it's getting <br>The off diagonal matrix elements are HUGE. These aren't only not the good states, they're pathetic. You can calculate the energies from what we did in <a data-href="1.4 Degenerate Perturbation Theory#^R2eigenEnergy" href="school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html#^R2eigenEnergy" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.4 Degenerate Perturbation Theory &gt; ^R2eigenEnergy</a><a data-href="1.4 Degenerate Perturbation Theory#^R2eigenEnergy" href="school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html#^R2eigenEnergy" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.4.7)</a> The good states and bad states areWhen two Coulomb potentials approach each other, there is suddenly a potential which is lower for the electron to be in than it was before! THIS IS BONDING!!!]]></description><link>school/physics/quantum-2/notes/1.13-double-well-problem.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.13 Double Well Problem.md</guid><pubDate>Fri, 14 Feb 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.14 Time Dependent Perturbation Theory]]></title><description><![CDATA[We learned about how to model the effects of time varying changes to the potential in a quantum system.@adiht - PMA modeling personFirst midterm is next Friday, closed notes and books. Coversheet with formulas. More of a progress report. One more HW assignment between now and then, due next Tuesday.Exercise 1.14.1 (For a quantum system in some definite energy state , what is the time dependence of the wave function?).
The probability doesn't have time dependance, but the wave-function does!
When a system isn't in a well defined energy, but it is in a superposition state. If you end up with different 's somehow, multiplying it out gives you cross terms. The superposition state is of the form of both the time variance, and it's positional dependance.The perturbations we look at will be separable.We know from the Euler relation, that it can be written in the form. This is our "wiggle term" mentioned in Griffiths.We know Then applying our perturbationThen we want to solve <a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> Expanding this givesWhere is our amplitude to derive probability.
We can always do this, this is a good basis to work with. Any possible state is a superposition of the basis states.<br>
We're now plugging the form from <a data-href="#^8177e9" href="#^8177e9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^8177e9</a><a data-href="#^8177e9" href="#^8177e9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.14.5)</a> to <a data-href="#^86c9d0" href="#^86c9d0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^86c9d0</a><a data-href="#^86c9d0" href="#^86c9d0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.14.4)</a>. When you take these derivatives, you'll get two pieces. One involving the derivative of the complex exponential phase, and one involving .
The Hamiltonian acting on will cause . The result of this is that these mutual wave-function terms drop out.Exercise 1.14.2 (AT HOME: Work through this and prove it).As is our usual technique, we're singling out just one of the states and one This gives us a set of coupled differential equations to solve! Now the
We're picking the below notationYou can check to see our units for work out since angular momentum being .
For our first order term, assumeThis gives us our first order termWe're now making a specific assumption: we claim we're initially in a single state . ThenBasically, we're saying that "given a state, what is the evolution of the system with respect to other states over time". To figure out this answer, we can just integrate!<br>This is just the <a href=".?query=tag:fourierTransform" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#fourierTransform">#fourierTransform</a> !!<br>What this does is that it picks out the part of the perturbation, to see what part is at the resonant frequency of the system. That's the part that will be effective in <a data-href="#^5c5b03" href="#^5c5b03" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^5c5b03</a><a data-href="#^5c5b03" href="#^5c5b03" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.14.12)</a> that will be effective at triggering a state transition.Anything that has time dependance can be expanded as sums of harmonic perturbations.
This is cool asf.The transition probability at a given time isLat's say that I have my perturbation, I leave it on for awhile, and at some time later, I turn it off. More specifically, what if I want to know when to turn the perturbation off so that it's maximizing it's probability in another state.<br>Starting from <a data-href="#^5c5b03" href="#^5c5b03" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^5c5b03</a><a data-href="#^5c5b03" href="#^5c5b03" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.14.12)</a> The key points here, are that we factored out that center exponential term because we wanted to add a sin component. Sin has a more physical presence. If I wanted to know when to first turn the perturbation off, then we know that the probability of the state should be zero!
Once you turn the perturbation off, those coefficients get locked in.What about a Gaussian pulse?<br>Well just like before, we apply <a data-href="#^5c5b03" href="#^5c5b03" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^5c5b03</a><a data-href="#^5c5b03" href="#^5c5b03" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.14.12)</a> and plug inBut what bounds do we pick? Well good news, the gaussian has so much of it's area focussed at the center, since we're already approximating we can just integrate over ]]></description><link>school/physics/quantum-2/notes/1.14-time-dependent-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.14 Time Dependent Perturbation Theory.md</guid><pubDate>Mon, 17 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExdGZ3dHY1Y3lkOXp5ZjdlMGF6OXo1czE0dDNmN3lnMDFlNGNuM3U1aiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/l0HUgz8J4UzxKX6SI/giphy.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExdGZ3dHY1Y3lkOXp5ZjdlMGF6OXo1czE0dDNmN3lnMDFlNGNuM3U1aiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/l0HUgz8J4UzxKX6SI/giphy.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.16 The Stark Effect]]></title><description><![CDATA[Last time we covered oscillating perturbations, this time Forget all about fine structure and Zeeman. We're going to put an electric field across our atom. in the z-direction, constant magnitude (like a capacitor) thenwhere This is called an electric dipole interaction.Applying this to the hydrogen atom is called the Stark effectWe're going to look and see if some of the angular terms are zero, since we know that the radial part is never zero. <a class="original-internal-link" data-href="../../Quantum 1/Notes/2.4 Rotation and Angular momentum.md" href="school/physics/quantum-1/notes/2.4-rotation-and-angular-momentum.html" target="_self" rel="noopener nofollow" style="display: none;">2.4 Rotation and Angular momentum</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum 1/Notes/2.4 Rotation and Angular momentum.md" href="school/physics/quantum-1/notes/2.4-rotation-and-angular-momentum.html" target="_self" rel="noopener nofollow">2.4 Rotation and Angular momentum</a>
Important note right now, is from the spherical Jacobian! For the ground state In our case, theta is the polar angle
This is completely analogous to putting a symmetric linear potential in the bound state! The integral is even.
The charge distribution of the electron in the ground state of the Hydrogen atom is symmetric. The expectation value is then gonna be zero!Use as many units as you can before you embark on an actual integralNotice that all the spherical harmonics have a parity!To be an even function is to have a parity of , and odd has a parity of The integrand is always odd, so the integral is always zero! There are no first order shifts possible states where !
This is why the diagonal elements in the pre-lecture were mentioned to be zero! They all integrate to zero. For more information, see the Pre-lecture for 1.15
BUT WAIT, what about degeneracies. Are the off-diagonal elements zero or non-zero? We need to check the off-diagonal elements
This becomes a 4x4 degenerate matrix (Since we are ignoring the effects of spin). Focus on the -partUnless those two phi parts have the same value, the integral will be zero! That's because with different eigenstates, then the integral of those would be zero (orthogonality)!That means we want things with the same value of Homework answer is NON-ZERO! <br>
Since this is non-zero, we have worry about the part seen at <a data-href="#^85ec74" href="#^85ec74" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^85ec74</a><a data-href="#^85ec74" href="#^85ec74" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.16.4)</a>
The columns are in the order of . is the convention I'm using They lied to us in chemistry. The good states have a dipole moment! The charge distribution of the electron is now off-center.
The reason chemistry books lie to you, is that the same energy states are constant on the axis. They don't want to deal with complex numbers so they include a superposition of the two to introduce a directional bias.<br>Why is there no weak field strong field cases like we had for <a class="original-internal-link" data-href="1.9 Zeeman Effect.md" href="school/physics/quantum-2/notes/1.9-zeeman-effect.html" target="_self" rel="noopener nofollow" style="display: none;">1.9 Zeeman Effect</a><a class="internal-link mathLink-internal-link" data-href="1.9 Zeeman Effect.md" href="school/physics/quantum-2/notes/1.9-zeeman-effect.html" target="_self" rel="noopener nofollow">1.9 Zeeman Effect</a>
The electric field in the atom is so strong, it doesn't matter how strong the external field is. We very rarely reach the strong field case. The petawatt laser just reaches it, and it's one of the strongest in the world
Next Monday we're covering transitions. We're going back to our time dependent formula.]]></description><link>school/physics/quantum-2/notes/1.16-the-stark-effect.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.16 The Stark Effect.md</guid><pubDate>Fri, 21 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/hHxTQkcjmHUTC.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/hHxTQkcjmHUTC.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.18 Review Day]]></title><description><![CDATA[We actually talked about LASERSSS. Reference <a data-href="1.17 Transitions in the Atom#^4f0623" href="school/physics/quantum-2/notes/1.17-transitions-in-the-atom.html#^4f0623" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.17 Transitions in the Atom &gt; ^4f0623</a><a data-href="1.17 Transitions in the Atom#^4f0623" href="school/physics/quantum-2/notes/1.17-transitions-in-the-atom.html#^4f0623" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.17.6)</a> and onward for more information on the math.Townes (1953) was the first one to figure out how to produce a microwave maser.There's some minimum in the structure of an amonium atom as a function of the coordinateWe vary our parameter, and there is some minimum in the Nitrogen's potential. If you think of this like springs, the Nitrogen wants to wobble around it's potential. Push it far enough though, if you push this down far enough the Nitrogen can SNAP to the other side!<br>Near each minima, the potential behaves like a simple harmonic oscillator. We can notice this is just like the <a class="original-internal-link" data-href="1.13 Double Well Problem.md" href="school/physics/quantum-2/notes/1.13-double-well-problem.html" target="_self" rel="noopener nofollow" style="display: none;">1.13 Double Well Problem</a><a class="internal-link mathLink-internal-link" data-href="1.13 Double Well Problem.md" href="school/physics/quantum-2/notes/1.13-double-well-problem.html" target="_self" rel="noopener nofollow">1.13 Double Well Problem</a>!SPACE PRODUCES LASERS?? - Astrophysical Masers in molecular clouds, first in hydroxyl (OH)Inhibiting the emission of a Rydberg atom through squeezing a plate.<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.55.2137" target="_self">https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.55.2137</a>
A Rydberg state is a Cesium 16s which has it's energy levels <br>
For more information, theres a note at <a class="original-internal-link" data-href="../../../Miscillaneous/Tidbit Facts/Increasing State Coherence with a Smaller Box.md" href="school/miscillaneous/tidbit-facts/increasing-state-coherence-with-a-smaller-box.html" target="_self" rel="noopener nofollow" style="display: none;">Increasing State Coherence with a Smaller Box</a><a class="internal-link mathLink-internal-link" data-href="../../../Miscillaneous/Tidbit Facts/Increasing State Coherence with a Smaller Box.md" href="school/miscillaneous/tidbit-facts/increasing-state-coherence-with-a-smaller-box.html" target="_self" rel="noopener nofollow">Increasing State Coherence with a Smaller Box</a>Tells you how to go about constituent angular momentums to get a resultanthe number tells you the magnitude of added angular momentum you sum up]]></description><link>school/physics/quantum-2/notes/1.18-review-day.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.18 Review Day.md</guid><pubDate>Wed, 26 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.1 Variational Principle]]></title><description><![CDATA[What happens if the perturbation ISN'T SMALL? Find out, todayLet's say that we want to determine the ground state energy for a many-electron system. We can know , but don't know how to solve the <a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> Definition 2.1.1 (The Variational Principle).
The Variational Principle says make a guess wavefunction , and compute And rely on the fact that That's because our guessed wavefunction is the superposition of a bunch of states in the real spectrum, which likely includes the higher energy of states. That's why the above is obvious. Since is the ground state wave-function, unless we choose a linear multiple of for then if we find a lower energy than the ground state we know it has to be the ground state!
Then we try to minimize the parameters of .
Say is of the form . Then we want to minimize the function . You don't need a good wave-function at all to get a reasonable answer!
<br>We use variational principle when the perturbations aren't small for <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^perturbationForm</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Perturbation Theory)</a> <br>Exercise 2.1.2 (What points with the below potential contribute to ). For a particle in an infinite box from <a class="original-internal-link" data-href="../../Quantum 1/Notes/1.11 The Bound State Problem.md" href="school/physics/quantum-1/notes/1.11-the-bound-state-problem.html" target="_self" rel="noopener nofollow" style="display: none;">1.11 The Bound State Problem</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum 1/Notes/1.11 The Bound State Problem.md" href="school/physics/quantum-1/notes/1.11-the-bound-state-problem.html" target="_self" rel="noopener nofollow">1.11 The Bound State Problem</a>, we're making our trial wave-function just a triangle!
Answer:
For maximization, we take the second derivative. The linear terms die leaving us with delta functions at the edges!
]]></description><link>school/physics/quantum-2/notes/2.1-variational-principle.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.1 Variational Principle.md</guid><pubDate>Mon, 03 Mar 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/HzX8pvJLdT01oyAIot.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/HzX8pvJLdT01oyAIot.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.4 More Variational Principle Examples]]></title><description><![CDATA[More on <a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.1 Variational Principle &gt; ^3f70ac</a><a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.1.1 (The Variational Principle)</a> Theorem 2.3.1 (The Hamiltonian of the Helium Atom). The difficult part is the last component, it's not separable. You have the <br>What are the relative magnitudes of the contributions to the Helium atom ground state in terms of kinetic, electron electron, and electron nucleus
Electron-nucleus, kinetic, electron electron. See <a data-href="2.3 Variational Principle Examples#^234549" href="school/physics/quantum-2/notes/2.3-variational-principle-examples.html#^234549" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Variational Principle Examples &gt; ^234549</a><a data-href="2.3 Variational Principle Examples#^234549" href="school/physics/quantum-2/notes/2.3-variational-principle-examples.html#^234549" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.9)</a> <br>From last time, we're allowed to do whatever we want with our trial wave-function <a data-href="2.3 Variational Principle Examples#^2fcb32" href="school/physics/quantum-2/notes/2.3-variational-principle-examples.html#^2fcb32" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Variational Principle Examples &gt; ^2fcb32</a><a data-href="2.3 Variational Principle Examples#^2fcb32" href="school/physics/quantum-2/notes/2.3-variational-principle-examples.html#^2fcb32" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.4)</a>. At the end of class, we discussed methods to make the trial wavefunction below more accurate. To do this, we're going to (just in the wave-function) make the two 's change from what the Hamiltonian might put.
<br>The nice thing is that we already did all the integrals from before when ! The results are in <a data-href="2.3 Variational Principle Examples#^234549" href="school/physics/quantum-2/notes/2.3-variational-principle-examples.html#^234549" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Variational Principle Examples &gt; ^234549</a><a data-href="2.3 Variational Principle Examples#^234549" href="school/physics/quantum-2/notes/2.3-variational-principle-examples.html#^234549" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.9)</a>. We now have two different though, one from the Hamiltonian and one in the wave-function. To do this, we keep track of when the falls from the wave-function and when comes from the hamiltonian.
Doing this yields the result:Minimizing with respect to , we add the terms together firstThen differentiatePlugging this in and setting to zero, gives us a minimum value of as<br>Solving this value of to <a data-href="#^a1868f" href="#^a1868f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^a1868f</a><a data-href="#^a1868f" href="#^a1868f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.3)</a> gives us an answer of BUT WE'RE NOT READY TO QUIT YET! What next?Why don't we just expand with an infinite series? Then we just fit the infinite number of polynomial parameters?
It makes the integrals simpler
What if we make different between the two electrons in the wave-function? But if we were to do that, we'd be labelling the particles! They should be indistinguishable.
To solve this, we put them in an even super-position between whichever one has the shieldingbut wait, there are two ways to make them an even super-position. The symmetry can be plus or minus, like polarization.<br>If we did calculate the ground state energy from <a data-href="#^59f559" href="#^59f559" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^59f559</a><a data-href="#^59f559" href="#^59f559" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.7)</a> we'd need to diagonalize a matrix. Doing that gives a ground state energy of To go further, we might try the higher level energy states in Hydrogen for our model's fit.That's why you can use Hydrogen wave-functions for higher level atom orbitals, it's because of the variational principle!<br>
Taylor, G. R., &amp; Parr, R. G. (1952). Superposition of Configurations: The Helium Atom. Proceedings of the National Academy of Sciences of the United States of America, 38(3), 154–160. <a rel="noopener nofollow" class="external-link is-unresolved" href="https://doi.org/10.1073/pnas.38.3.154" target="_self">https://doi.org/10.1073/pnas.38.3.154</a>
The above citation is what allows us to represent multi-electron atoms using superpositions of the hydrogen atom wave-functions!
]]></description><link>school/physics/quantum-2/notes/2.4-more-variational-principle-examples.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.4 More Variational Principle Examples.md</guid><pubDate>Mon, 10 Mar 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.5 Excited States of Helium]]></title><description><![CDATA[More on <a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.1 Variational Principle &gt; ^3f70ac</a><a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.1.1 (The Variational Principle)</a>: we use the excited states of helium to learn how to start modeling many body physics<br>We want to find out if there's a function which is able to include the spin states between our electrons. <a data-href="2.4 More Variational Principle Examples#^59f559" href="school/physics/quantum-2/notes/2.4-more-variational-principle-examples.html#^59f559" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.4 More Variational Principle Examples &gt; ^59f559</a><a data-href="2.4 More Variational Principle Examples#^59f559" href="school/physics/quantum-2/notes/2.4-more-variational-principle-examples.html#^59f559" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.7)</a>
When we make our spin wave-function anti-symmetric, then we're able to satisfy Pauli and keep our system indistinguishable. <br>Note that from <a data-href="2.4 More Variational Principle Examples#^59f559" href="school/physics/quantum-2/notes/2.4-more-variational-principle-examples.html#^59f559" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.4 More Variational Principle Examples &gt; ^59f559</a><a data-href="2.4 More Variational Principle Examples#^59f559" href="school/physics/quantum-2/notes/2.4-more-variational-principle-examples.html#^59f559" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.7)</a> , if then the wave-function would go to zero and we wouldn't be able to have that state!Today we're looking at states with one excited electron and one not. We can't know which electron is in the higher coordinate though based on Pauli.Unfortunately, we are once again using Clebsch-Gordon.We're starting with what we always do with the Variational principle.We have two terms as always, Direct(J) and Exchange (K)The direct term come from assuming the probability of the electron distributions are independent, so you can just multiply the probabilities times the operator for the expectation value. The exchange term is when we can't assume independence, so you need to integrate with events given the occurrence of another (hence the exchange.)Even though the hamiltonian doesn't involve spin, the spin configuration constrans the possible wave-functions. Therefore, our potential energies do depend on the spin!!This lecture at the very end has a list of possible questions we should be able to answer! ]]></description><link>school/physics/quantum-2/notes/2.5-excited-states-of-helium.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.5 Excited States of Helium.md</guid><pubDate>Wed, 12 Mar 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.6 The Periodic Table]]></title><description><![CDATA[Why are we able to separate out the spacial wave-function and the spin wave-function. The lowest possible 2 electron excited state in Helium is already unstable! One electron wants to decay to the lower state, which kicks off the last electronNew quantum numbers cost a lot of energy, so filled shells are stable. Partially filled 's tend to leave electrons unpaired.
That's because if you did have them in the same , your direct term seen from <a data-href="2.5 Excited States of Helium#^ed6fb7" href="school/physics/quantum-2/notes/2.5-excited-states-of-helium.html#^ed6fb7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.5 Excited States of Helium &gt; ^ed6fb7</a><a data-href="2.5 Excited States of Helium#^ed6fb7" href="school/physics/quantum-2/notes/2.5-excited-states-of-helium.html#^ed6fb7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.5.4)</a> would be high! Just a different makes then orthogonal, thus minimizing energy.The reason why the outermost electrons are the ones which matter, is because the angular momenta of each electron cancel out in a full shell. We want the total angular momentum and total spin Elements with the same outer electron configuration behave the same in spectroscopy, bonding, and energy levels.]]></description><link>school/physics/quantum-2/notes/2.6-the-periodic-table.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.6 The Periodic Table.md</guid><pubDate>Fri, 14 Mar 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.7 H2+ Ion]]></title><description><![CDATA[We talked about using the <a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.1 Variational Principle &gt; ^3f70ac</a><a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.1.1 (The Variational Principle)</a> to determine whether or not the ion would bond, and if so explain why. Additionally, we drew parallels to how perturbation theory would attach the problem as seen in <a class="original-internal-link" data-href="1.13 Double Well Problem.md" href="school/physics/quantum-2/notes/1.13-double-well-problem.html" target="_self" rel="noopener nofollow" style="display: none;">1.13 Double Well Problem</a><a class="internal-link mathLink-internal-link" data-href="1.13 Double Well Problem.md" href="school/physics/quantum-2/notes/1.13-double-well-problem.html" target="_self" rel="noopener nofollow">1.13 Double Well Problem</a>Simplest variational approach is enough to explain that this would be a bound state<br>
We're going to imagine that we bring in another proton to our hydrogen atom system, similar to what we did on <a class="original-internal-link" data-href="../Homework/Homework 3.md" href="school/physics/quantum-2/homework/homework-3.html" target="_self" rel="noopener nofollow" style="display: none;">Homework 3</a><a class="internal-link mathLink-internal-link" data-href="../Homework/Homework 3.md" href="school/physics/quantum-2/homework/homework-3.html" target="_self" rel="noopener nofollow">Homework 3</a> when we pulled two wells together from infinity. This is what gives us a wave-function which delocalizes the particlesWe're going to put the two coulomb potentials apartThis only models when the protons are fixed
We will cover this at length in the coming weeks, why we can fix the protons down. Qualitatively, the nuclei are far heavier than the electrons This is the Born-Oppenheimer approximation
Definition 2.7.1 (Born Oppenheimer Approximation).
We can separate the timescale of the electron's behavior in a quantum system, and the timescale of the nuclear component. The coupling between the electron and nuclear motion is small, and thus you can leave it out THE most important principle in physical chemistry
With the hydrogen ion, we're just going to guesstimate that the wave-function is a superposition of being in both wells equally.<br>Definition 2.7.2 (LOCI: Linear Combination of Atomic Orbitals). As seen in <a data-href="#^ff22ff" href="#^ff22ff" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^ff22ff</a><a data-href="#^ff22ff" href="#^ff22ff" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.7.2)</a> , LOCI is a method of making our guess wave-function for the <a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.1 Variational Principle &gt; ^3f70ac</a><a data-href="2.1 Variational Principle#^3f70ac" href="school/physics/quantum-2/notes/2.1-variational-principle.html#^3f70ac" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.1.1 (The Variational Principle)</a> by simply combining known superpositions
To normalize, The last integral is tricky cause we have two coordinate systems in our last wave-function. We fix that by using some useful properties of vector quantities.Notice that the amplitude drops with the distance between the nuclei . This is because when the nuclei are far apart, then the overlap is going to be low!Plotting this overlap gives the below plotsNext up we want to compute To get our energy, we apply Notice that even without calculating, the second expectation value has to be negative. Because of that, the energy is lower when the two nuclei are close and we know a bond occurs!<br>In <a data-href="#^446bbb" href="#^446bbb" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^446bbb</a><a data-href="#^446bbb" href="#^446bbb" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.7.6)</a> we can see it looks like <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^perturbationForm</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Perturbation Theory)</a>! More specifically, like a first order energy correction.
Labelled with our perturbation understanding<br>This is EXACTLY what we'd do with perturbation theory! It's <a class="original-internal-link" data-href="1.4 Degenerate Perturbation Theory.md" href="school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html" target="_self" rel="noopener nofollow" style="display: none;">1.4 Degenerate Perturbation Theory</a><a class="internal-link mathLink-internal-link" data-href="1.4 Degenerate Perturbation Theory.md" href="school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html" target="_self" rel="noopener nofollow">1.4 Degenerate Perturbation Theory</a>! The two trial wave-functions are degenerate across the wells, so we'd need to diagonalize the matrix.Now we're also adding in the term for the proton-proton repulsionCombining all these energy features gives the below expressionThere being a minimum which is lower than a proton out at infinity implies that there has to be a bond! The conclusion won't change if we have a more accurate for the variational principle since that could only lower the energy.
The question on the homework, is if the first bound state of the anharmonic oscillator is inside that potential well. Fit a quadratic to that minima, find then find . The binding energy is at .
Experimentally the binding energy is at This graph should be familiar! Any chemistry textbook and class will use the above graph to describe the binding energy of a chemical bond.
We can get the nuclei vibrating in the potential produced by the molecular bond! At the minimum we have a harmonic oscillator behavior. This gives us a way to calculate the nuclear motion .
]]></description><link>school/physics/quantum-2/notes/2.7-h2+-ion.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.7 H2+ Ion.md</guid><pubDate>Mon, 24 Mar 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.9 The Hydrogen Molecule]]></title><description><![CDATA[The hydrogen molecule is represented by the following hamiltonian
How does this energy compare to <a class="original-internal-link" data-href="2.7 H2+ Ion.md" href="school/physics/quantum-2/notes/2.7-h2+-ion.html" target="_self" rel="noopener nofollow" style="display: none;">2.7 H2+ Ion</a><a class="internal-link mathLink-internal-link" data-href="2.7 H2+ Ion.md" href="school/physics/quantum-2/notes/2.7-h2+-ion.html" target="_self" rel="noopener nofollow">2.7 H2+ Ion</a>?
It's between 1-2 times as much! The only difference between the two hamiltonians is the term. The electron-electron repulsion would increase the binding energy
<br>We know we need an overall anti-symmetric wave function, because the electrons are fermions! We also need to incorporate our spin trick from <a data-href="2.5 Excited States of Helium#^426249" href="school/physics/quantum-2/notes/2.5-excited-states-of-helium.html#^426249" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.5 Excited States of Helium &gt; ^426249</a><a data-href="2.5 Excited States of Helium#^426249" href="school/physics/quantum-2/notes/2.5-excited-states-of-helium.html#^426249" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.5.1)</a> to make this happen so we don't make Pauli mad.The Coulomb interaction is superimposable, so this is a godsend! We don't have to worry about the overall behavior since it's adding up independent interactions. The strong nuclear force is NOT superimposable
To do this, we're making a trial wave-function to see what happens. We're putting one electron on one atom, the other on the secondThe trial wave-function that is going to be used is the hydrogen 1s orbital.We're reusing the direct and exchange terms from There are also electron electro direct and exchange terms
This direct term just looks like the classical interaction between two charge distributions, where is the arbitrary distance to integrate over It could be fun to try and train a neural network on my self-reported data, heart-rate (mean, std, max,min), and sleep metrics, to see if it has predictive power. The thing is that that information should be from the previous days, so it needs to be a recurrent neural network.
To do that I need to collect it all into a single csv. I could also put other metrics, but it might be complicated to get them.
DON'T GET SCARED, this is our expectation value
<br> is the same from <a data-href="2.7 H2+ Ion#^c86fd1" href="school/physics/quantum-2/notes/2.7-h2+-ion.html#^c86fd1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 H2+ Ion &gt; ^c86fd1</a><a data-href="2.7 H2+ Ion#^c86fd1" href="school/physics/quantum-2/notes/2.7-h2+-ion.html#^c86fd1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.7.4)</a> <br><img src="supplemental-files/images/pasted-image-20250328133558.png" target="_self">
The minima here gives us a binding energy of . The actual value is Why would I even want to do this if the energy is so bad? Well this is just showing us that the energy lowers, not by how much
<br>Then how could I improve this?
Similar to what we did when we were talking about <a class="original-internal-link" data-href="2.7 H2+ Ion.md" href="school/physics/quantum-2/notes/2.7-h2+-ion.html" target="_self" rel="noopener nofollow" style="display: none;">2.7 H2+ Ion</a><a class="internal-link mathLink-internal-link" data-href="2.7 H2+ Ion.md" href="school/physics/quantum-2/notes/2.7-h2+-ion.html" target="_self" rel="noopener nofollow">2.7 H2+ Ion</a>, we can incorporate nuclear shielding because of Gauss's law. That apparently gives a substantial improvement at the cost of effort
<br>The minus combination is what you expect from <a data-href="#^7cfbe3" href="#^7cfbe3" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^7cfbe3</a><a data-href="#^7cfbe3" href="#^7cfbe3" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.9.1)</a> <br><img src="supplemental-files/images/pasted-image-20250328134541.png" target="_self">]]></description><link>school/physics/quantum-2/notes/2.9-the-hydrogen-molecule.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.9 The Hydrogen Molecule.md</guid><pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate><enclosure url="https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExczVmOW1oamN0OXRlMnZ0bzE2dmlibDBybXRmZjJkc3ZuMWwyaGE1OCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/9Dvcoe3va1R80eUuVW/giphy.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src="https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExczVmOW1oamN0OXRlMnZ0bzE2dmlibDBybXRmZjJkc3ZuMWwyaGE1OCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/9Dvcoe3va1R80eUuVW/giphy.gif"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.14 EPR]]></title><description><![CDATA[See this from a QIS perspective <a class="original-internal-link" data-href="../../QIS/Notes/1.11 EPR and Bell Inequality.md" href="school/physics/qis/notes/1.11-epr-and-bell-inequality.html" target="_self" rel="noopener nofollow" style="display: none;">1.11 EPR and Bell Inequality</a><a class="internal-link mathLink-internal-link" data-href="../../QIS/Notes/1.11 EPR and Bell Inequality.md" href="school/physics/qis/notes/1.11-epr-and-bell-inequality.html" target="_self" rel="noopener nofollow">1.11 EPR and Bell Inequality</a><br>See the original paper <a data-tooltip-position="top" aria-label="https://journals.aps.org/pr/pdf/10.1103/PhysRev.47.777" rel="noopener nofollow" class="external-link is-unresolved" href="https://journals.aps.org/pr/pdf/10.1103/PhysRev.47.777" target="_self">here</a>What does it mean to be a complete theory?
Every element of physical reality must be described by your physical theory
Definition 5.1.1 (Bell States).
States that we can use as a basis to make quantum bits in superposition, seperable ]]></description><link>school/physics/quantum-2/notes/2.14-epr.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.14 EPR.md</guid><pubDate>Wed, 09 Apr 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.1 Numerical TISE]]></title><description><![CDATA[Today we're looking at numerical solutions to <a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> We're looking at the time independent Schrödinger equation because it allows us to separate the system out.^f9f8db
This gives us a second order derivative isWe can then use this above expression tö help figure out the value at with finite difference<br>
Using <a data-href="#^49957c" href="#^49957c" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^49957c</a><a data-href="#^49957c" href="#^49957c" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.2)</a> with <a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> , we can create a finite difference Schrödinger equationDefinition 3.1.1 (Finite Difference Schrödinger Equation). With the above form, we can actually crank out a calculation! This lets us use a wave-function at a few proceeding points, then march across the grid.<br>
<a data-href="#^31df7f" href="#^31df7f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^31df7f</a><a data-href="#^31df7f" href="#^31df7f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.1.1 (Finite Difference Schrödinger Equation)</a> does need two initial values though (the initial conditions!)
Functional form of A guess of the energy For most cases with an arbitrary , the solution of the numerics won't make any sense. We'd get , meaning we can't normalize the wavefunction. Only specific values of has this make physics sense.
<br>If I have the wavefunction at every point, then I can solve directly for the energy as a linear system over all the points with <a data-href="#^31df7f" href="#^31df7f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^31df7f</a><a data-href="#^31df7f" href="#^31df7f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.1.1 (Finite Difference Schrödinger Equation)</a> This ends up with huge sparse matrices
If I had a few points (more than 2 but not that many), could I use linear algebra to approximate an initial and then work around that?
We're coming back to ways to approximate There's a bit of art to know where to choose your initial values, and the step size. ]]></description><link>school/physics/quantum-2/notes/3.1-numerical-tise.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/3.1 Numerical TISE.md</guid><pubDate>Wed, 23 Apr 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.5 More Degenerate Perturbation Theory]]></title><description><![CDATA[Week 3 begins !
1 lesson through chapter
A continuation of <a class="original-internal-link" data-href="1.4 Degenerate Perturbation Theory.md" href="school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html" target="_self" rel="noopener nofollow" style="display: none;">1.4 Degenerate Perturbation Theory</a><a class="internal-link mathLink-internal-link" data-href="1.4 Degenerate Perturbation Theory.md" href="school/physics/quantum-2/notes/1.4-degenerate-perturbation-theory.html" target="_self" rel="noopener nofollow">1.4 Degenerate Perturbation Theory</a>
won't throw up im nmot dizzhy the lights AREN't flickering guys
It's ! When you do the first order energy correction integral, the energy being constant pulls out.<br>
From <a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory &gt; ^c15950</a><a data-href="../../Quantum 1/Notes/3.3 Introduction to Perturbation Theory#^c15950" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^c15950" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.3 (First Perturbed Energy)</a>, the correction is a lot like a weighted average.The first excited state does have degeneracies! We're going to pick two degenerate statesThen do the integrals.For the off-diagonalsWith non-zero off-diagonal terms, we see that we need to diagonalize our basis.
This gives us final energies in the first order ofI am not nauseous. I am like, so stable. The room totally isn't moving.Now we want to find the "good" statesWhen this is reduced, you getIs there a reason why this reduced to cleanly into even superpositions of the original basis?
We'll get to it!
QM will always give us the lowest possible energy. QM ensures that the lowest energy is the lowest it can physically be.Plotting the probabilities of gives usIf we want to make the energy as low as possible and the perturbation is in the lower right, so we want to move as much probability away from that end. That's why the bottom is . In 15 minutes I run to next class, cry, then I go to target and get sunglasses. With those sunglasses.<br>Griffiths is thinking of a symmetry operator. "What symmetry can I express this problem with?" "What can I do to the box which leaves it unchanged?". Then look for basis functions which obey that symmetry. This is my answer to <a class="original-internal-link" data-href="#^2c27e2" href="#^2c27e2" target="_self" rel="noopener nofollow" style="display: none;">my earlier question</a><a class="internal-link mathLink-internal-link" data-href="#^2c27e2" href="#^2c27e2" target="_self" rel="noopener nofollow">my earlier question</a>! We got lucky because our perturbation was perfectly even! That's why it was a uniform superposition.I'm connecting this to operators. How might we get ? In other words, what symmetry might a new eigenstate of originate from?
Maybe a possible phase difference? It is certainly possible, but the symmetry becomes more subtle.
For more information on how this all obeys with matrices, you can check Griffiths A.5 on Matrix operations.
Does the dimension of the matrix depend on the number of matrices?]]></description><link>school/physics/quantum-2/notes/1.5-more-degenerate-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.5 More Degenerate Perturbation Theory.md</guid><pubDate>Mon, 27 Jan 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.9 Zeeman Effect]]></title><description><![CDATA[Today we discussed discrepancies in Dirac's exact solution to the fine structure of the Hydrogen atom. Then we learned about the Zeeman effect, which helps us split the final degeneracies in the angular vector. We treated all of this in the context of perturbation theory, but why didn't we get the exact solution?
Dirac actually exactly solved the hydrogen atom with relativity. The exact energy only depends on in that solution, so we have the right quantum numbers.If Dirac could solve this problem exactly, why are we even doing perturbation theory?
Our technique generalizes to a higher number of electrons! You can't just do that with Dirac's exact solution. How did Dirac do it?
In Dirac theory, and are degenerate. But experimentally Lamb 1947 found those levels weren't degenerate. TF?? What did we miss? We included special relativity and orbit coupling??
We're missing an even more fundamental physics. We treat the magnetic field as classical. Electromagnetic radiation is a bunch of photons! Dirac's theory knows nothing about that
Weee QED is now existing. Now EM fields interact due to photons which are emitted. Those are virtual photons. Where does the energy come from to make the photons?
We borrow it from the vacuum, related to the uncertainty principle.\ref uncertain The more you borrow, the sooner it's due. <a data-href="../../Quantum 1/Notes/1.9 Boundary Conditions in Free Space#^de80e8" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^de80e8" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.9 Boundary Conditions in Free Space &gt; ^de80e8</a><a data-href="../../Quantum 1/Notes/1.9 Boundary Conditions in Free Space#^de80e8" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^de80e8" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.9.1 (Heisenburg Uncertainty Principle)</a> If the photons have momentum, why doesn't the electron just repel the photon during their perpetual exchange?
Cause the electron should lose momentum right? And then the photon absorbs it. How does it know to attract or repel based on charges if a photon is chargeless
The sun has somehow collected sodium from previous dying stars. Any atom with unpaired electrons has fine structure.
There was a transition at the d3 line, which we wanted to identify here on Earth. We couldn't for the life of us figure out what was doing it.
Turns out it was helium, and this was what caused the d3 line.We add an external magnetic fieldWhere and . We're basically selecting a magnetic field to destroy the last degeneracy.
There's an extra factor of 2 on (the g-factor) for spin predicted by Dirac theory (where it's exactly two)
Measurement is almost two but not exactly. There's a whole field dedicated to thus this.
You calculate through a series Schwinger was the first person to calculate this correction, and now is on his tombstone. Status of the field of measurements
Experiment shows: = .00115965218059
Theory is = .00115965218164
This is line insane agreement. What about the magnetic moment of the proton?
The Dirac prediction is two, the measured value is 5.9. Terrible terrible approximation. You can't even get started with an expansion for in the proton because the you use their isn't fine structure, it's ??!
We're breaking it into two regimes. One with a weak field, one with a strong field.We can write our energy correction then as<br>Why do we have a 2? Because in <a data-href="#^originalZeemanHamCor" href="#^originalZeemanHamCor" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^originalZeemanHamCor</a><a data-href="#^originalZeemanHamCor" href="#^originalZeemanHamCor" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.1)</a>, and differ in coefficient by 2. One has a coeff of and the other so we have to factor out. If the field is weak enough, then the size of is somewhat small enough that we are going to average it out. Additionally, it's direction is kind of like the direction of .To find we use the fact that .We simplify this to write a factor of<br>This then gives us for our final energy correction based on <a data-href="#^energyCorrectionFirstOrder" href="#^energyCorrectionFirstOrder" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^energyCorrectionFirstOrder</a><a data-href="#^energyCorrectionFirstOrder" href="#^energyCorrectionFirstOrder" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.2)</a> when reduced gives:Theorem 1.9.1 (First Order Energy Correction for a Weak Magnetic Field with the Zeeman Effect). where . Symbolically it's This means that for any given , the then splits off our energy correction with .
What this means, is that the perturbation to the energy is on the order of if we apply 1 tesla. We're jus
Next time we cover the strong field case.
]]></description><link>school/physics/quantum-2/notes/1.9-zeeman-effect.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/1.9 Zeeman Effect.md</guid><pubDate>Wed, 05 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.10 Molecules]]></title><description><![CDATA[Anti-bonding states are because you can't just completely put the system in a lowered energy state, there should be a higher state which is apprehensive to the bond! Apprehensive just means it's higher energy than if the systems were separated.Note that the orbital isn't completely spherically symmetric. There are several orientations to pair them together to make a bond! Because of the rotational operations not being symmetric, we get degeneracies in the bondDefinition 2.10.1 (Gerade).
The same thing when you invert something
Definition 2.10.2 (Ingerede).
The same thing when you invert something, with a phase of If the anti-bonding orbital is so unstable, why would we move from the bonding orbital to the instead of ?
There's many electron volts of difference in the energy states
How do you even determine this exists, if you can't perform any actions on it?? With a difffraction grating, you can't risk throwing it to a wall. They used a transmission grating! ]]></description><link>school/physics/quantum-2/notes/2.10-molecules.html</link><guid isPermaLink="false">School/Physics/Quantum 2/Notes/2.10 Molecules.md</guid><pubDate>Mon, 31 Mar 2025 00:00:00 GMT</pubDate><enclosure url="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExeHozdTJicDlvbnJlbGtrNGNsdnl6M3Nrd3V5b2ZnMDBxYjY3bndobyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xG4lYFxS4oVx74a0Sj/giphy.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExeHozdTJicDlvbnJlbGtrNGNsdnl6M3Nrd3V5b2ZnMDBxYjY3bndobyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xG4lYFxS4oVx74a0Sj/giphy.gif"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[This is the document that talks about the first quantum mechanics class I took at UT. Below are the important links to local documents used in the course, and the notes are on the Syllabus
Syllabus can be found <a data-tooltip-position="top" aria-label="../Class Content/PHY373Fall24syllabus-3.pdf" data-href="../Class Content/PHY373Fall24syllabus-3.pdf" href="school/physics/quantum-1/class-content/phy373fall24syllabus-3.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">PHY373Fall24syllabus-3</a><a data-tooltip-position="top" aria-label="../Class Content/PHY373Fall24syllabus-3.pdf" data-href="../Class Content/PHY373Fall24syllabus-3.pdf" href="school/physics/quantum-1/class-content/phy373fall24syllabus-3.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">PHY373Fall24syllabus-3</a><br>
Textbook is <a data-tooltip-position="top" aria-label="../Class Content/GriffithsQuantum.pdf" data-href="../Class Content/GriffithsQuantum.pdf" href="school/physics/quantum-1/class-content/griffithsquantum.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Griffiths</a><a data-tooltip-position="top" aria-label="../Class Content/GriffithsQuantum.pdf" data-href="../Class Content/GriffithsQuantum.pdf" href="school/physics/quantum-1/class-content/griffithsquantum.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Griffiths</a>
Fishler, PMA 9.310A
Office Hours Thurs 11-12 noon Can email to arrange other times with prof but can also use LA Announcements on Canvas, homeworks are going on Canvas
8-9 Homeworks a semester, once per about 10 days Solutions will also be regularly posted Griffiths is picked as the book more out of popularity, but Fischler isn't following any textbooks Sakurai's QM, or Feynman Volume 3 will trace out the beginning of the class Everything is on the blackboard, no lecture notes or videos are getting posted. By Uni rules. don't post blackboard
Why are you taking quantum mechanics?
Sounds fun and was interesting
Grades: There are two options for the tests, in-class, or out-of-class. The perks of in-class testing, or out-of-class testing. With out-of class testing, you have open note stuff.
Pros of taking it home, you can be wherever you want to take the final, and it's open note.
Tests are take-home and open-noteIf you work in a group, you upload one copy with all four names. Saves you and the grader time.THERE IS NO CURVING, RAW SCORE ONLY 😭😭😭
Based on how the grading distribution goes, the first group gets the A, the second B, etc. When in-between groups, you get pulled up
No homeworks or tests are dropped
We're learnign about the utility of QM formalism through Stern-Gerlach
<br>Theorem 0.1.1 (Energy if a Magnetic-Dipole Aligning With a Field).
The moment will Align with the field, moving to a lower Potential. This is described by the <a data-tooltip-position="top" aria-label="../Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href=".html" class="internal-link" target="_self" rel="noopener nofollow">dot product</a> Below is a huge problem with QM. Imaging a container filled with an electron gas , who each have their own randomized magnetic dipole. Superheat the container, and poke a hole in it. The hole is facing a much larger magnetic dipole, that changes the ejection of gas particles based on the alignment to the localized field. On the projection screen, you expect a continuous distribution of the particles.
You don't get this]]></description><link>school/physics/quantum-1/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/0.1 Introduction.md</guid><pubDate>Tue, 27 Aug 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.1 Hilbert Spaces and Quantum Observables]]></title><description><![CDATA[Discussing the motivation for Dirac notation today, through the lens of the Stern Gerlach experiment. We go through the math it involves, and the consequences it suggests for Q1.We're going to learn Q1 through the context of an experiment and it's results.
How do we describe said experiment, consistently and mathematically.Assume you have a medium heated up, filled with dipoles. Their magnitude is fixed with heating.
This is the same experiment discussed last time.Definition 1.1.1 (Stern-Gerlach Experiment). Assume you have a medium heated up, filled with dipoles. Their magnitude is fixed with heating. The dipoles have magnetic moment and the large dipole has magnitude . . We're also going to make this field modellable as only changing along the Z direction, so Because we're only having a changing field on the direction, the energy is The issue that comes in for , is that the magnitude of can orient in any range of directions classically.
We don't see this, we see two distinct points on the screen instead. on each point. With a constant potential, there is no force! That's becauseThis is the same experiment discussed last time.We're going to describe the name of the top point as , and the bottom as .
For each , we're going to put the same magnet in the direction. In the, we put another magnetic field in the direction on both and there is do deflection. After though, on each branch we put an orthogonal magnetic field, and we get a new set of branching! In the image, the new field is oriented . Later, if we were to add another oriented field to each branch, we get another 50-50 split.The state of a dipole is a vector!
<a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Bra-Ket Notation" data-href="../../Quantum Computing/Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">This notation we use is called Dirac notation</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Bra-Ket Notation" data-href="../../Quantum Computing/Definitions/Bra-Ket Notation" href="school/physics/quantum-computing/definitions/bra-ket-notation.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">This notation we use is called Dirac notation</a>We are using Dirac notation for this, and getting what seems like collapses of wave-functions. The way this experiment seems to be described seems like it can go on for infinity. How would we even denote that?
This is just the same thing as getting a polarized photon , measuring it in the observable to get the 50-50 photons, then measuring those photons back in the observable. It's not that you're making new outcomes, it's that any pure state can be represented as the superposition of other pure states To describe the results of this experiment, we're going to need complex numbers.Given vectors , we need a way to combine the vectors into a dual-vector space, which is where we get a . There is no more information here, it's the same space.<br>
Between , the inner product is . This is different than the <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">dot product</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">dot product</a>, because the bra of a vector is the hermitian of it's ket.The norm is always strictly positive. Definition 1.1.2 (Hilbert Space).
A hilbert space is any space, which contains vectors , which satisfies the following identity Where the * denotes the complex conjugation
<br>Operators because just like most kinds of variables. They can be linearly combined or multiplied, but it does not commute. We see this when we use <a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Quantum Gates" data-href="../../Quantum Computing/Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Quantum Gates</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Quantum Gates" data-href="../../Quantum Computing/Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Quantum Gates</a> Example 1.1.3 (Let's say , what's the dual of ?).
To solve this, we know we're looking for Example 1.1.4 (What is the dual of given that it is where is an operator). Why does nature do this? Call 9-1-1-God"- Fischler
On why quantum mechanics is this way
Observables are unique from just operators, because they are their own hermitian.<br>This is because Observables are all subsets of the <a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/2.4 Quantum Observables > ^500f42" data-href="../../Quantum Computing/Semester 1/2.4 Quantum Observables#^500f42" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#^500f42" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">The Unitary Matrix</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/2.4 Quantum Observables > ^500f42" data-href="../../Quantum Computing/Semester 1/2.4 Quantum Observables#^500f42" href="school/physics/quantum-computing/semester-1/2.4-quantum-observables.html#^500f42" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">The Unitary Matrix</a> , which is the generalization of an observable in .
Still though, observables don't commute.All we're doing is plugging in backwards. So far, we'e just constructed a mathematical model.<br>Definition 1.1.5 (Equality through Operators).
For two operators within a <a data-href="#^d14200" href="#^d14200" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^d14200</a><a data-href="#^d14200" href="#^d14200" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.1.2 (Hilbert Space)</a> , the two operators are identical IFF. Definition 1.1.6 (Identity Operator).
An operator is the identity operator if both of the following conditions are met Where are an operator and vector within the Hilbert space respectively. This means it is also an observable
<br>Definition 1.1.7 (Eigenvalue Problem Restated for Quantum Mechanics).
Given the following Equation Find the possible values of that satisfy this equation. This is just <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">eigenvalues</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">eigenvalues</a> (), <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">eigenvector</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^ab6240" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^ab6240" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">eigenvector</a> () and this is the eigenvalue problem.<br>
The spectrum of is Which is the set of eigenvalues and eigenvectors. Within the spectrum, they are paired within a <a data-tooltip-position="top" aria-label="../../../../Math/Discrete Math/1.1 The Language of Sets > ^486b94" data-href="../../../../Math/Discrete Math/1.1 The Language of Sets#^486b94" href="school/math/discrete-math/1.1-the-language-of-sets.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">proper subset</a><a data-tooltip-position="top" aria-label="../../../../Math/Discrete Math/1.1 The Language of Sets > ^486b94" data-href="../../../../Math/Discrete Math/1.1 The Language of Sets#^486b94" href="school/math/discrete-math/1.1-the-language-of-sets.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">proper subset</a>. <br>This is the second time we've restated the <a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/2.5 Calculating Observables > ^2d6ffb" data-href="../../Quantum Computing/Semester 1/2.5 Calculating Observables#^2d6ffb" href="school/physics/quantum-computing/semester-1/2.5-calculating-observables.html#^2d6ffb" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">eigenvalue problem</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/2.5 Calculating Observables > ^2d6ffb" data-href="../../Quantum Computing/Semester 1/2.5 Calculating Observables#^2d6ffb" href="school/physics/quantum-computing/semester-1/2.5-calculating-observables.html#^2d6ffb" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">eigenvalue problem</a> using quantum mechanics
Theorem 1.1.8 (Realness of eigenvalues of an operator, and the orthogonality of it's eigenvectors).
We want to prove that given an operator , it's spectrum containing That and for any eigenvector with unique eigenvalues, <br>Isn't this just showing that an operator must have an <a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Orthonormal Bases > ^506716}" data-href="../../Quantum Computing/Definitions/Orthonormal Bases#^506716}" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">orthonormal basis</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Orthonormal Bases > ^506716}" data-href="../../Quantum Computing/Definitions/Orthonormal Bases#^506716}" href="school/physics/quantum-computing/definitions/orthonormal-bases.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">orthonormal basis</a> The possible outcomes of an experiment, the coefficients on the kets, are the eigenvalues of the respective vectors.
If I measure and get a probability of eigenvalue , then I have measured the outcome represented by <br>Definition 1.1.9 (The Probability of a Quantum Mechanical Outcome).
The probability of finding a given outcome, , given below, is This identity extends from <a data-href="#^1fcf04" href="#^1fcf04" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^1fcf04</a><a data-href="#^1fcf04" href="#^1fcf04" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.1.7 (Eigenvalue Problem Restated for Quantum Mechanics)</a> <br>This is just <a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/4.1 Multi Qubit States > ^1f115f" data-href="../../Quantum Computing/Semester 1/4.1 Multi Qubit States#^1f115f" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html#^1f115f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Borns Rule for Mixed Qubit States</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/4.1 Multi Qubit States > ^1f115f" data-href="../../Quantum Computing/Semester 1/4.1 Multi Qubit States#^1f115f" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html#^1f115f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Borns Rule for Mixed Qubit States</a>
Theorem 1.1.10 (The Eigenvalues are real).
Start with an observable , with two eigenvector-value pairs . To satisfy this statement there are two cases. The first one is . In this case, the first factor . From this, The only time this happens, is if The second case is if , which means the second term () contributes to the zero. This only happens if the two eigenvectors are orthogonal. ]]></description><link>school/physics/quantum-1/notes/1.1-hilbert-spaces-and-quantum-observables.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.1 Hilbert Spaces and Quantum Observables.md</guid><pubDate>Thu, 29 Aug 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.4 Matrix Representations and Hamiltonians]]></title><description><![CDATA[Covered the expected value of a Hamiltonian, Compatible and incompatible observables, and reviewed the homework.If you see Where is defined in spherical coordinates like soThe eigenvalues of the Hamiltonian, are the energies of the system.We worked in different bases. Now to talk about Matricies!
Given a system whereAdditionallyFor this basis to be complete,We then substitute the two to getThen you can recognize that in the basis it isWe then can multiply out to getThere are then 4 complex numbers you can pull out from the set, which will help you define the operatorThat can be seen through how the outer product is multiplying out. These factors are all . The vectors can just be organized in a matrix like soHowever, this isn't shown to be the operator, just a key part. These components were pulled from the expanded form, but we don't know.
BUT what's the basis??
We use a test case of Notice that this matrix is diagonal. Because are eigenvectors of , their outer product squeezed in, is zero. Additionally, the outer product of a vector with it's operator and itself, is the eigenvalue.This means in this case, we're in the diagonalized basis.
In general, the matrix in it's own eigenbasis, is diagonal. Diagonalizing a Hermitian is finding it's <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">eigenvalues</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">eigenvalues</a> .Now we're gonna try . First using the below definition,
Definition 1.3.1 ( observables written in the basis). We then use our own work from earlier but drop in from our own work,So what does look like in the diagonalized basis?He's just giving us, but you can find itWhich means that <br>These are just the <a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Quantum Gates" data-href="../../Quantum Computing/Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Quantum Gates</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Definitions/Quantum Gates" data-href="../../Quantum Computing/Definitions/Quantum Gates" href="school/physics/quantum-computing/definitions/quantum-gates.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Quantum Gates</a>
ThenDefinition 1.4.1 (Matrix representation of the Pauli Matricies).
The below representation are in the diagonalized basis What's interesting is that the basis actually flips the amplitude of the vertical polarization. When we're doing QC, we don't think about this!<br>
<a data-href="../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography#^917569" href="school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html#^917569" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography &gt; ^917569</a><a data-href="../../Quantum Computing/Semester 1/3.3-3.4 Quantum State Tomography#^917569" href="school/physics/quantum-computing/semester-1/3.3-3.4-quantum-state-tomography.html#^917569" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.1 (Pauli Matrices and Density Matrix)</a> I'm hungry<br><img alt="../../../../../Supplemental Files/images/Stern-Gerlach Diagram.jpg" src="supplemental-files/images/stern-gerlach-diagram.jpg" target="_self">In the above setup, what is the probability that given , we get This is the same as writing the belowThe probability isBut what if we don't ever look at the observable? Then the probability of the case isThat's the same as the inner product wedged with the identity, which if we did would further prove the fact.
For the two results to be the same, with or without measurement, Then must commute.This also means that have the same eigenbasis
Then has as an eigenvector, with the same eigenvalue as .
There are some degenerate cases, where some eigenvalues have several eigenvectors.Definition 1.4.2 (Comptible Observables).
Compatible observables, are ones where applying one to the output of another, doesn't change the state.
Definition 2.5.2 (Expected Value).
If we prepare the same state a lot and measure the same observable, what value do we expect? By expanding the right and factoring, we can turn it into the below Note the expectation value should always be real If we look for Then this is the average value of when the state is prepared as Where is the weight on the averageExercise 1.4.3 (AT-HOME work through the expected value math, and prove that it is how we described above).We want to prove Well this down here is the variance, so we're gonna try to prove thisProof. Heisenberg Uncertainty PrincipleLemma 1.4.4 (Schwartz Lemma). Proof. We now define as
Plugging back in □
Next time: Proving the Uncertainty PrincipleWe can find it in Saccarai]]></description><link>school/physics/quantum-1/notes/1.4-matrix-representations-and-hamiltonians.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.4 Matrix Representations and Hamiltonians.md</guid><pubDate>Tue, 10 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.7 Rabi's Theorem]]></title><description><![CDATA[We should have all the material ready to solve Homework 2
Today we went through solving for the probability of being in a state, given that the Hamiltonian changes in some way over time. We did the below steps
Used <a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> , wrote coupled-diffeq, made two substitutions (who's time components cancel) to reduce the order to a second-order-uncoupled diffeq, then we solved traditionally and undid the substitutions to prove Rabi's Theorem.**Note, usage of is analogous to <br>Proof of <a data-href="#^4130e4" href="#^4130e4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^4130e4</a><a data-href="#^4130e4" href="#^4130e4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.7.3 (Rabi's Theorem/Problem)</a>. Exercise 1.7.1 (Find the energy states of a system given the below Hamiltonian, with states ). ^problem
Now we don't know the eigenstates of the system, and even less so the Hamiltonian evolves over time with an oscillating time-dependent component.
First assume two things Both can just be changed with convention if a contradiction comes up, with it's just by flipping them, and with , you wrap the phase into the exponential.
We want to ask the same as before are energies because dimensions must match, is frequency. is an energy
This is a ton of energy values, and depending on their magnitude, the system will be crazy over time.
One thing that can happen, is resonance.
We have to solve the differential equation from the Schrödinger Equation<br>
<a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> In Matrix notation, using the basis From before, we knowWe also know thatBack to our differential equation
This is thenThis is a two-coupled-linear differential equation. Note the below <br>AN important question now, what are the two conditions which satisfy this differential equation? It's <a data-href="#^KeyCondition" href="#^KeyCondition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^KeyCondition</a><a data-href="#^KeyCondition" href="#^KeyCondition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.1)</a>! We're defining this as a matrix, which is two conditions!Well now we need to solve :/<br>Plugging this into <a data-href="#^CoupledEquation" href="#^CoupledEquation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^CoupledEquation</a><a data-href="#^CoupledEquation" href="#^CoupledEquation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.6)</a> gives usTo make things easier, we define a new variable If we repeat the same , we'd getPlugging the value of into givesThis is now a single-order differential equation!This is just a simple damped harmonic oscillator! However, the damping is complex???
Let's kill that
We're doing another substitutionWe want to find a way to hopefully fix , so that the terms vanish. We're grabbing the coefficients of on both sides of the equation, since they must be equalWe can then fix this , to resolve this.
By fixing , using just information we know, (remember is newly introduced), we can make this into a simple harmonic oscillator.Why couldn't we do what we just did to , to any of the other coefficients?<br>Plugging back in to <a data-href="#^substitutedDifferentialEquation" href="#^substitutedDifferentialEquation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^substitutedDifferentialEquation</a><a data-href="#^substitutedDifferentialEquation" href="#^substitutedDifferentialEquation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.12)</a>, gives usThis is in the formwhich has the frequency .
In our case, the frequency of the system isThen Something important to note, is that we can't solve this using our conventional methods of solving coupled-differential-equations. is time-dependent. Instead, we reduced the order of the coupled differential equation, into a second-order first. We know this is doable from diffeq.<br>
Now we're going to pull from <a data-href="#^tildaSubstitution" href="#^tildaSubstitution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^tildaSubstitution</a><a data-href="#^tildaSubstitution" href="#^tildaSubstitution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.10)</a><br>
We want to undo all the substitutions, along with plugging in <a data-href="#^fixingA" href="#^fixingA" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^fixingA</a><a data-href="#^fixingA" href="#^fixingA" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.14)</a> to get in terms of <br>We now want to get rid of since we have our initial condition <a data-href="#^KeyCondition" href="#^KeyCondition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^KeyCondition</a><a data-href="#^KeyCondition" href="#^KeyCondition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.1)</a>. (From the initial condition, the initial values of are respectively)
To solve at Exercise 1.7.2 (Using this final value of , work your way back to the original values of ).<br>Going back to our initial question <a data-href="#^7a28a9" href="#^7a28a9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^7a28a9</a><a data-href="#^7a28a9" href="#^7a28a9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Exercise 1.7.1 (Find the energy states of a system given the below Hamiltonian, with states )</a> , how do we get our probabilities?If you were to finally cascade the substitutions, all you'd subsequently do is apply Borns rule, and take the absolute value of the coefficient squared.
□<br>Theorem 1.7.3 (Rabi's Theorem/Problem).
For a state in a hamiltonian defined in <a data-tooltip-position="top" aria-label="^7a28a9" data-href="#^7a28a9" href="#^7a28a9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.7.1</a><a data-tooltip-position="top" aria-label="^7a28a9" data-href="#^7a28a9" href="#^7a28a9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.7.1</a> , the probability of finding a particle in the state over time is given by If we want to find the probability of , we'd just subtract. The total probability should be 1, so we'd use that identity. <br>In our <a data-href="#^tildaSubstitution" href="#^tildaSubstitution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^tildaSubstitution</a><a data-href="#^tildaSubstitution" href="#^tildaSubstitution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.10)</a>, we introduce a complex damping. In our <a data-href="#^dSubstitution" href="#^dSubstitution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dSubstitution</a><a data-href="#^dSubstitution" href="#^dSubstitution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.13)</a>, we introduce another kind of damping. These don't seem like they'd annihilate when they would be recombined. Would the amplitudes then also be damped oscillators? In that case, how do the probabilities sum to one? , if , how is the probability not going to zero over time? Through <a data-href="#^omegaDefinition" href="#^omegaDefinition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^omegaDefinition</a><a data-href="#^omegaDefinition" href="#^omegaDefinition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.7.9)</a>, the two dampings introduced in the substitution actually kill each other, so probabilities are still conserved.
]]></description><link>school/physics/quantum-1/notes/1.7-rabi's-theorem.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.7 Rabi's Theorem.md</guid><pubDate>Thu, 19 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.8 Translation and Momentum]]></title><description><![CDATA[Deriving the uncertainty tradeoff between the translation operator, and momentum operator. We prove that they are not independant of each otehrReview of <a data-href="1.7 Rabi's Theorem#^7a28a9" href="school/physics/quantum-1/notes/1.7-rabi's-theorem.html#^7a28a9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.7 Rabi's Theorem &gt; ^7a28a9</a><a data-href="1.7 Rabi's Theorem#^7a28a9" href="school/physics/quantum-1/notes/1.7-rabi's-theorem.html#^7a28a9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Exercise 1.7.1 (Find the energy states of a system given the below Hamiltonian, with states )</a> Exercise 1.7.1 (Find the energy states of a system given the below Hamiltonian, with states ). ^problem
Now we don't know the eigenstates of the system, and even less so the Hamiltonian evolves over time with an oscillating time-dependent component.
First assume two things Both can just be changed with convention if a contradiction comes up, with it's just by flipping them, and with , you wrap the phase into the exponential.
We want to ask the same as before are energies because dimensions must match, is frequency. is an energy
This is a ton of energy values, and depending on their magnitude, the system will be crazy over time.
One thing that can happen, is resonance.
We have to solve the differential equation from the Schrödinger Equation<br>
<a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> What if we wanted to plot the amplitude over time
PlottingAs a function of Where As gets smaller compared to , then the resonance curve becomes more narrowExample 1.8.1 (Rabi's Formula on a Rotating Magnetic Field). Let's then take a magnetic field with a magnetic field fixed, but rotate it Then vary as a function of time Then Then remember that is a matrix vector with stupid notation
For notation sake, we're working in the Factoring out and then multiplying out form our observables, we get But now we want to define it in the basis
From We can derive it into that basis from this equation. Knowing the above, we can then figure out what the analogous information Rabi's formula applies only for formulas which can be found to be written like that. It tends to applies to to systems with 1D of oscillation which is constant, and which are a two-state
Let's take the position operator as The position operator on a state which is an eigenstate, gives the position of the particle. Completeness for discrete operators isBut for continuous operatorsFor orthogonality with discrete operators, But what the hell is ??Kronecker delta is only good for discrete statesImagine I change the value of the function at a finite number of points, by a finite amount. The theorem says the area doesn't change .Where is the wave-function.If this is zero except for at a finite position, then it stays at zero due to the theorem defined earlier<br>The issue is that this isn't displaced by a finite value! This is defined as the <a data-href="#^0fb5c4" href="#^0fb5c4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^0fb5c4</a><a data-href="#^0fb5c4" href="#^0fb5c4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.2 (Dirac Delta Function)</a> Definition 1.8.2 (Dirac Delta Function). The Delta function is any such function where the area over any region other than the center, is zero, but integrating at all over the single infinite point, is one. This is the derivative of the step function. This is how you get orthogonality for continuous observables.The integral itself is the probability. This is just like how the normal distribution needs to be evaluated.
ClassicallyA translation of on an object , moves itBut in quantum mechanics we talk about operators, so translations are operatorsWe're also requiring that is unitary, so oranges don't fall into the toilet.The inverse of a translation is just the negation, because moving forward is countered by moving backward.
Translations also commute, moving 5 meters then 4, is the same as moving 4 then 5.<br>What does actually mean? Aren't the things in the 's just labels? is the eigenstate of the position observable, which has the <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">eigenvalue</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues > ^2a6704" data-href="../../../Math/Linear Algebra/5.1 Eigenvectors and Eigenvalues#^2a6704" href="school/math/linear-algebra/5.1-eigenvectors-and-eigenvalues.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">eigenvalue</a> of . Definition 1.8.3 (Momentum (Quantum Mechanics)).
Momentum () is the generator of position translatio.<br>
Where the <a data-tooltip-position="top" aria-label="1.6 Working with the Schrödinger Equation > ^d06020" data-href="1.6 Working with the Schrödinger Equation#^d06020" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^d06020" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Hamiltonian</a><a data-tooltip-position="top" aria-label="1.6 Working with the Schrödinger Equation > ^d06020" data-href="1.6 Working with the Schrödinger Equation#^d06020" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^d06020" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Hamiltonian</a> is the generator of translation in time, the momentum is the generator of translation in space. Where has the dimensions of momentum
^f4015a
Let's say we have a very small translationWhich is all to say, that if we move very slightly, it should be a equally linearly small perturbation of the identity.
From how we multiply it out, it means that must be an operator.
What is the implication that is unitary?
(Note that ) Therefore is Hermetian.
You can work out from dimensional analysis, that the unit of is in fact, momentum.We know that is hermitianThere is completenessAny state can be written as The wave function in actual space, can then be written as
This is us trying to figure out the inner product of the position eigenstate, and the momentum eigenstate<br>
Look at this with translations, using <a data-href="#^schrodingerPosition" href="#^schrodingerPosition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^schrodingerPosition</a><a data-href="#^schrodingerPosition" href="#^schrodingerPosition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.17)</a>
<br>We made the jump in those two steps because of the below fact. The inverse of translation, is negation from <a data-href="#^inverseTranslation" href="#^inverseTranslation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^inverseTranslation</a><a data-href="#^inverseTranslation" href="#^inverseTranslation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.14)</a> <br>Continuing from <a data-href="#^lastStep" href="#^lastStep" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^lastStep</a><a data-href="#^lastStep" href="#^lastStep" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.24)</a> Then The wave-function in space is related to the wave-function in momentum space, through a Fourier transform.
Position and momentum are then really tightly related. This is where we get the uncertainty principle between the two. They're the same slice of information.]]></description><link>school/physics/quantum-1/notes/1.8-translation-and-momentum.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.8 Translation and Momentum.md</guid><pubDate>Tue, 24 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.9 Boundary Conditions in Free Space]]></title><description><![CDATA[Covering boundary conditions, and possible energies in continuous free space<a data-href="1.8 Translation and Momentum#^completenessContinuous" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^completenessContinuous" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Translation and Momentum &gt; ^completenessContinuous</a><a data-href="1.8 Translation and Momentum#^completenessContinuous" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^completenessContinuous" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.5)</a><br>
<a data-href="1.8 Translation and Momentum#^cc4d99" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^cc4d99" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Translation and Momentum &gt; ^cc4d99</a><a data-href="1.8 Translation and Momentum#^cc4d99" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^cc4d99" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.3 (Momentum (Quantum Mechanics))</a> How would we find the position over time, given that Well this is just
This derivation is so physicist, dividing out the infinitesimal and all
How do we knock out the ? We can't use the normalization listed below But plugging that in here, means that we get a value of zero. The solution seems to just be, having boundary conditions?
<br>We're now doing to show that the <a data-tooltip-position="top" aria-label="1.3 Commutators, and Observables > ^2796fc" data-href="1.3 Commutators, and Observables#^2796fc" href="school/physics/quantum-1/notes/1.3-commutators,-and-observables.html#^2796fc" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">commutation</a><a data-tooltip-position="top" aria-label="1.3 Commutators, and Observables > ^2796fc" data-href="1.3 Commutators, and Observables#^2796fc" href="school/physics/quantum-1/notes/1.3-commutators,-and-observables.html#^2796fc" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">commutation</a> of the two operators isDefinition 1.9.1 (Heisenburg Uncertainty Principle). Note that the derivation is found in purple journal
<br>Using <a data-href="#^givenCommutator" href="#^givenCommutator" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^givenCommutator</a><a data-href="#^givenCommutator" href="#^givenCommutator" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.2)</a>, we plug into the <a data-href="#^de80e8" href="#^de80e8" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^de80e8</a><a data-href="#^de80e8" href="#^de80e8" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.9.1 (Heisenburg Uncertainty Principle)</a> gives us:This literally means that if we know the value at one point (the expectation value becomes zero), the other value must be infinity<br>
Now to prove <a data-href="#^givenCommutator" href="#^givenCommutator" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^givenCommutator</a><a data-href="#^givenCommutator" href="#^givenCommutator" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.2)</a> The reason why our last step is true, is that is used as the limit as we go to zero, so any transformation of the infinitesimal is just zero
For any , this is a true operator relation for all cases<br>Now we plug in for it's momentum form from <a data-href="1.8 Translation and Momentum#^cc4d99" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^cc4d99" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Translation and Momentum &gt; ^cc4d99</a><a data-href="1.8 Translation and Momentum#^cc4d99" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^cc4d99" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.3 (Momentum (Quantum Mechanics))</a> (Note that the identity is still in there at the end, but we're abusing notation)Now let's imagine we have a particle on a single line. We want to discuss things like it's time evolution, or given a certain situation what it's energy eigenvalues and states of the system?In non-relativistic classical mechanics, the energy of the particle is just it's kinetic energy^energyClassicalParticle
For a completely free particle, system cannot be free if the force is different in different places! A free particle has no dependance on .
This then evaluates to the below, (subbing in kinetic energy)All this is, is a hamiltonian!Note that this isn't the most general hamiltonian <br>Additionally, remember <a data-href="#^freeParticleAssumption" href="#^freeParticleAssumption" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^freeParticleAssumption</a><a data-href="#^freeParticleAssumption" href="#^freeParticleAssumption" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.8)</a>, our free particle assumption, which means that We can explain the above, through the fact that is a taylor series in , so it's inner product of a representative eigenstate, just pulls outWe're going to make an aside here to find Theorem 1.9.2 (Momentum-Position Derivative Relation).
With some wavefunction , you can define the nth power of the momentum, as the nth power of the partial derivative in space <br>This then becomes a differential equation from the <a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> The general equation for the wave-function in our case of is then<br>What does this darn thing represent? Is it the probability of finding a certain particle on the line, given some hamiltonian defined through <a data-href="#^freeParticleHamiltonian" href="#^freeParticleHamiltonian" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^freeParticleHamiltonian</a><a data-href="#^freeParticleHamiltonian" href="#^freeParticleHamiltonian" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.9)</a> We're also imposing the condition of continuity on the wave-function, because energy cannot be infinite.We can then constrain our particle to a box in 1D, by making the boundaries have infinite energyWe're constrained to Quadrant 2. The lowest energy solution classically is just being stationary anywhere in the quadrant. But what happens when we want to have a non-classical particle?Classically, if we had momentum the particle would bounce back and forth forever.<br>
We need to solve <a data-href="#^differentialEqParticleProb" href="#^differentialEqParticleProb" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^differentialEqParticleProb</a><a data-href="#^differentialEqParticleProb" href="#^differentialEqParticleProb" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.12)</a> for Note that the wraps in all of our constantsIn order to have finite energy, we need to have continuity, until we hit the boundaries. Continuity tells us and (where are the positions of the boundaries).
Using these boundary conditions, we then find that equals zero.We then need to satisfy the condition, Why can't this tell us anything about A?
"Then all of quantum mechanics would be caca"
<br>Above is the rearranged fact for what would make <a data-href="#^reducedDiffeq" href="#^reducedDiffeq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^reducedDiffeq</a><a data-href="#^reducedDiffeq" href="#^reducedDiffeq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.15)</a> true given the second boundary condition.<br>Our energies can then only exist in those specific states, since the value of can only be in a fixed number of states. These energies in <a data-href="#^energyBoundarySolutions" href="#^energyBoundarySolutions" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^energyBoundarySolutions</a><a data-href="#^energyBoundarySolutions" href="#^energyBoundarySolutions" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.17)</a> are the only ones which provide solutions to our boundary conditionsSomething interesting about , is that it represents the modes of the wave-function. To be in a higher energy, is to be in a higher mode of the wavefunction
\img]]></description><link>school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.9 Boundary Conditions in Free Space.md</guid><pubDate>Tue, 01 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.10 Harmonic Oscillation]]></title><description><![CDATA[,,,,# OverviewLet's now try to study the little oscillation along some arbitrary potential's minimumOdd order terms fall out, because we're at a minimum.
This is just a harmonic oscillator!The substitutions made here are just basic mechanics, we're describing the potential in terms of it's local taylor series.Solving that differential equation, we get the formThe potential we're talking about here is a quadratic approximation of the image, so what is happening quantum-mechanically?Well we need to repeat what we did in <a data-href="1.9 Boundary Conditions in Free Space#Particle In the Box" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#Particle In the Box" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Boundary Conditions in Free Space &gt; Particle In the Box</a><a data-href="1.9 Boundary Conditions in Free Space#Particle In the Box" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#Particle In the Box" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.9 Boundary Conditions in Free Space &gt; Particle In the Box</a>We then solve this differential equation <br>As an important note, remember that our second derivative came from the momentum from <a data-href="1.9 Boundary Conditions in Free Space#^momentumExponential" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^momentumExponential" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Boundary Conditions in Free Space &gt; ^momentumExponential</a><a data-href="1.9 Boundary Conditions in Free Space#^momentumExponential" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^momentumExponential" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.11)</a>, and that we define our wave-function as Theorem 1.10.1 (Distributive Property of Commutators).
Given operators on the same Hilbert space, The proof is something that can be done via simple expansion
Given an operator , and that ,Find the spectrum of .
Is this an observable?Because we know this is an observable, we know that the eigenvalues are real!This means that Now let's learn more about <br>Using <a data-href="#^27bc24" href="#^27bc24" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^27bc24</a><a data-href="#^27bc24" href="#^27bc24" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.10.1 (Distributive Property of Commutators)</a> How did you simplify in that last step?Now let's try and figure out what is whenWhat this is, is the lowering and raising operators. raises the eigenvalue of by one, drops it by one. Definition 1.10.2 (Raising and Lowering Operator).
The raising () and lowering operator are defined such that given some operator , with eigenstate , the raising operator when applied to increases the eigenvalue by one on the resultant operator
Below is the definition of any state defined in the context of raising and lowering <br>Here's an issue, we can keep recursively applying while preserving the original criteria of the setup, but that will keep dropping our eigenvalue. At some point, the eigenvalue will become negative. This violates <a data-href="#^alphaIsPositive" href="#^alphaIsPositive" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^alphaIsPositive</a><a data-href="#^alphaIsPositive" href="#^alphaIsPositive" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.9)</a> Exercise 1.10.3 (Prove that you can recursivley apply the lowering and raising operators, while preserving the setup).To resolve the contradction, this tells us that there exists some , such thatThen This is how our floor works. There must exist a zero state which can't be lowered through
When we use our raising operatorThis means, not only is positive, but Thuslywhere Now we wanna see what happens to the norm of when the raising operator is applied. NOTE that is just the scalar we are increased byThen we finally get the below for the normalized state.It is normally understood, that when denoting a raised state, it is normalized. Any state can then be defined asThe and operator is a linear combination of the raising and lowering operator.Why is this trueDefinition 1.10.4 (Position and Momentum Operator in Terms of the Raising and Lowering Operators). Where <br>We know from last time that <a data-href="1.9 Boundary Conditions in Free Space#^commutationOfPositionandMomentum" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^commutationOfPositionandMomentum" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Boundary Conditions in Free Space &gt; ^commutationOfPositionandMomentum</a><a data-href="1.9 Boundary Conditions in Free Space#^commutationOfPositionandMomentum" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^commutationOfPositionandMomentum" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.6)</a> that the commutation of these two operator definitions, should be <br>
The gameplan, is that we plug these expressions for into <a data-href="#^secondOrderHarmonicDiffeq" href="#^secondOrderHarmonicDiffeq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^secondOrderHarmonicDiffeq</a><a data-href="#^secondOrderHarmonicDiffeq" href="#^secondOrderHarmonicDiffeq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.5)</a> ]]></description><link>school/physics/quantum-1/notes/1.10-harmonic-oscillation.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.10 Harmonic Oscillation.md</guid><pubDate>Thu, 03 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.11 The Bound State Problem]]></title><description><![CDATA[Last time, we talked about the <a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^dbc3f4</a><a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.10.2 (Raising and Lowering Operator)</a>
To solve the problem, we use the below from last time We then also have the raising and lowering operators.We know that because they are conjugate operators<br>
via <a data-href="1.3 Commutators, and Observables#^19c567" href="school/physics/quantum-1/notes/1.3-commutators,-and-observables.html#^19c567" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.3 Commutators, and Observables &gt; ^19c567</a><a data-href="1.3 Commutators, and Observables#^19c567" href="school/physics/quantum-1/notes/1.3-commutators,-and-observables.html#^19c567" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.3.5 (General formula for Commutator)</a><br>
Plugging in <a data-href="1.10 Harmonic Oscillation#Back to Harmonic Oscillator" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#Back to Harmonic Oscillator" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; Back to Harmonic Oscillator</a><a data-href="1.10 Harmonic Oscillation#Back to Harmonic Oscillator" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#Back to Harmonic Oscillator" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.10 Harmonic Oscillation &gt; Back to Harmonic Oscillator</a>'s formulas for Now we're writing the previous hamiltonian<br>
<a data-href="1.10 Harmonic Oscillation#^HamiltonianDefinition" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^HamiltonianDefinition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^HamiltonianDefinition</a><a data-href="1.10 Harmonic Oscillation#^HamiltonianDefinition" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^HamiltonianDefinition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.4)</a> with this informationIt would be nice if we can rewrite the hamiltonian purely in terms of the raising-lowering operators. Because we have several free parameters, we're going to do a trick. First we keep expanding.We're now going to find a way to cancel the underlined term through the following substitution. This is allowed because of that extra free parameterThis reduces our Hamiltonian toWe made that jump from our definition of the number operator.
This gives us a final hamiltonian of<br>Is the substitution we made in <a data-href="#^teacherSubstitution" href="#^teacherSubstitution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^teacherSubstitution</a><a data-href="#^teacherSubstitution" href="#^teacherSubstitution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.5)</a> because an extra piece of information was analogous to a global phase?<br>We know from <a data-href="#^diagonalizedHamiltonianDef" href="#^diagonalizedHamiltonianDef" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^diagonalizedHamiltonianDef</a><a data-href="#^diagonalizedHamiltonianDef" href="#^diagonalizedHamiltonianDef" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.7)</a> that the energy states of our system must be<br>If we want to find the position wave-function, we don't need to solve <a data-href="1.10 Harmonic Oscillation#^secondOrderHarmonicDiffeq" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^secondOrderHarmonicDiffeq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^secondOrderHarmonicDiffeq</a><a data-href="1.10 Harmonic Oscillation#^secondOrderHarmonicDiffeq" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^secondOrderHarmonicDiffeq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.5)</a> "Ugh who was that * checks phone* oh it was the president of the United states, he wants to invite me for lunch. I'm not sure if I can make it"
-Fischler
<br>Then we plug in <a data-href="#^teacherSubstitution" href="#^teacherSubstitution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^teacherSubstitution</a><a data-href="#^teacherSubstitution" href="#^teacherSubstitution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.5)</a>The difference then give us"Why is the president calling, I told him I'm busy. Oh god *eyeroll*"(the difference gives us , we divide out the , which gives us for the denominators) Back to the wave-function with this Now though, we want to find . This must be equal to because the state is the floor and can't be lowered.What was the point of deriving the above, when we later used the lowering operator instead to find the wave-function?Why could we pull that inner operator out, did it commute?<br>From <a data-href="#^aDaggerDefinition" href="#^aDaggerDefinition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^aDaggerDefinition</a><a data-href="#^aDaggerDefinition" href="#^aDaggerDefinition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.12)</a>, we want thenThis gives us a final ground state wave-function of<br>Theorem 1.11.1 (The Wave-function for a Particle in a Harmonic Potential). From the ground state, you can use the <a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^dbc3f4</a><a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.10.2 (Raising and Lowering Operator)</a> to increase or decrease the energies.<br>
This is a <a href=".?query=tag:gauss" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#gauss">#gauss</a> ian What are the raising and lowering operators, "Any other energy level turns into a polynomial*gaussian", BUT WHY ARE THEY POLYNOMIALSHow do we find <br>Well we know that the momentum is just the Fourier transform of the gaussian from <a data-href="1.8 Translation and Momentum#^fourierTransformIdentity" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^fourierTransformIdentity" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Translation and Momentum &gt; ^fourierTransformIdentity</a><a data-href="1.8 Translation and Momentum#^fourierTransformIdentity" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^fourierTransformIdentity" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.8.27)</a> Exercise 1.11.2 (AT-HOME: Prove that the Fourier transform of a Gaussian, is a Gaussian).The electromagnetic field has infinite ground-state operators, which are all in non-zero ground states. That means that there's an infinite amount of ground-state energy. This would mean that gravity should crush us down to a pea, but it's expanding. This is where we get the cosmological constant.
Now we're back to
Definition 1.9.1 (Heisenburg Uncertainty Principle). Note that the derivation is found in purple journal We'll prove next time, isThe ground-state wave-function, is the best you can get in terms of uncertainties. It "saturates" the wave-function. ]]></description><link>school/physics/quantum-1/notes/1.11-the-bound-state-problem.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.11 The Bound State Problem.md</guid><pubDate>Tue, 08 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.1 Motion in Potential Function, and Pairity]]></title><description><![CDATA[Did more work talking about a quantum state in a continuous potential. Also talked about even and odd potentials leading to unique characteristics.Continuing from last time, remember that we're using the below Hamiltonian, and our goal is to solve for the motion of the particle in the potential as a function of time.
Let's say we wanted to know the uncertainty on the position, on the ground statewhen you have yourself in some parabolic potential functionExercise 2.1.1 (AT HOME: Try and do the above using [[1.10 Harmonic Oscillation#^dbc3f4]]).Now we want to get rid of the , but we don't wanna use integrals for that, that's annoying.
Definition 1.10.4 (Position and Momentum Operator in Terms of the Raising and Lowering Operators). Where Also look at <a data-href="1.11 The Bound State Problem#^teacherSubstitution" href="school/physics/quantum-1/notes/1.11-the-bound-state-problem.html#^teacherSubstitution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.11 The Bound State Problem &gt; ^teacherSubstitution</a><a data-href="1.11 The Bound State Problem#^teacherSubstitution" href="school/physics/quantum-1/notes/1.11-the-bound-state-problem.html#^teacherSubstitution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.5)</a>
From our previous notes, we know that From the fact that we're in the ground state, we can't be lowered anymore. If the raising operator acts on the outer state, then it becomes orthogonal to , and it dies
This gives usNow to find the momentum termFor the second term in the expansion of ThereforeGoing back to SchrödingerTherefore, Remember that the expectation value of momentum to the nth power, gives you some order of partial derivative. Look through notes for that<br>Theorem 1.11.1 (The Wave-function for a Particle in a Harmonic Potential). From the ground state, you can use the <a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^dbc3f4</a><a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.10.2 (Raising and Lowering Operator)</a> to increase or decrease the energies.<br>
This is a <a href=".?query=tag:gauss" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#gauss">#gauss</a> ian Our state using this ground state wave-function, becomesExercise 2.1.2 (Find that coefficient through [[#^firstEnergyStateDefinition]]).Definition 2.1.3 (Pairity).
We're going to define a term parity. Where you define the operator If the Hamiltonian and parity operator commute, then they have the same eigenvalues. You can classify the eigenstates of the Hamiltonian, under the parity. Theorem 2.1.4 (Commutation of Hamiltonian and Parity Operator). <br>Proof.@ <a data-href="#^d1a191" href="#^d1a191" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^d1a191</a><a data-href="#^d1a191" href="#^d1a191" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.1.4 (Commutation of Hamiltonian and Parity Operator)</a>Lemma 2.1.5 (Commutation of Parity Operator and position Operatpr). We are also conjecturing that the parity operator is Hermitian, because applying what is essentially a flip of your position, won't just throw out probabilitiesThen It seems intuitive that would return , the parity operator has the behavior of flipping an eigenkets, so it would feel like it should flip operators too.Exercise 2.1.6 (AT HOME: Prove ).<br>Assuming we did prove that, we can go back to our hamiltonian definition <a data-href="1.10 Harmonic Oscillation#^HamiltonianDefinition" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^HamiltonianDefinition" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^HamiltonianDefinition</a><a data-href="1.10 Harmonic Oscillation#^HamiltonianDefinition" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^HamiltonianDefinition" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.10.4)</a>, and now we have a way of connecting the hamiltonian operator, to the parity operatorExercise 2.1.7 (AT HOME: Finish this proof).□The wave-function must be continuous, so we must match the values of the potential function at zero. The lowest energy which can do that isn't , but from before! !! The potential function is odd, so the parity of the ground state must also be odd.Look up later- commutative geometry.Let's say we now have an coordinate operator, and a coordinate operator. We make the following below assumptions:More generallyAndThe same goes for the momentum, soAnd for overall uncertainty A cool fact then is that I can totally know the position in the direction, and, since those aren't the operators which commute to each other. No information is shared between the quantities.Now that our assumptions are done, let's do some notationIf you were to do the below to get a 2D wave-function]]></description><link>school/physics/quantum-1/notes/2.1-motion-in-potential-function,-and-pairity.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/2.1 Motion in Potential Function, and Pairity.md</guid><pubDate>Tue, 15 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.2 2D Boundary and Electric Field]]></title><description><![CDATA[Talked about the behaviors of particle in a multi-dimensional boundary and how to find the energies. Also began talking about adding an electric field to the boundary. Reference <a data-href="1.9 Boundary Conditions in Free Space" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Boundary Conditions in Free Space</a><a data-href="1.9 Boundary Conditions in Free Space" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">1.9 Boundary Conditions in Free Space</a> for a review in 1D.<br>We're continuing from <a class="original-internal-link" data-href="2.1 Motion in Potential Function, and Pairity.md#Multiple Dimensions" href="school/physics/quantum-1/notes/2.1-motion-in-potential-function,-and-pairity.html#Multiple Dimensions" target="_self" rel="noopener nofollow" style="display: none;">Multiple Dimensions</a><a class="internal-link mathLink-internal-link" data-href="2.1 Motion in Potential Function, and Pairity.md#Multiple Dimensions" href="school/physics/quantum-1/notes/2.1-motion-in-potential-function,-and-pairity.html#Multiple Dimensions" target="_self" rel="noopener nofollow">Multiple Dimensions</a> last time
Also, some notation, the position wave-function isMore notation isClassically, the ball either rolls around inside the box with momentum, or it stays stationary,
With quantum, we need to solveIf we can find the wavefunctions, then we can recontruct the state<br>Back to <a data-href="#^mainProblem" href="#^mainProblem" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^mainProblem</a><a data-href="#^mainProblem" href="#^mainProblem" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.3)</a><br>Then also recall <a data-href="1.9 Boundary Conditions in Free Space#^ffceb0" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^ffceb0" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Boundary Conditions in Free Space &gt; ^ffceb0</a><a data-href="1.9 Boundary Conditions in Free Space#^ffceb0" href="school/physics/quantum-1/notes/1.9-boundary-conditions-in-free-space.html#^ffceb0" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.9.2 (Momentum-Position Derivative Relation)</a> <br>Using <a data-href="#^HamiltonianEq" href="#^HamiltonianEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^HamiltonianEq</a><a data-href="#^HamiltonianEq" href="#^HamiltonianEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.5)</a>For outside the box, Region inside the box This gives us an expression ofIt feels fair to say, that our motion in the direction, is independent from our motion in the direction.We're using separation of variables to split this up() have the planks constant wrapped in, idk how to express that w/o expanding)This means we need to solve two independent problemsThis gives us final solutions of
Continuity Implies Symmetry on Edges Implies the below How do we know the second condition?
Well we know that in the area that the potential is infinite, the wave-function is infinite, then the wave-function right on the edge, must also be zero. The edge has to match the outside for continuity
<br>Then plugging back this information to <a data-href="#^EnergyFormula" href="#^EnergyFormula" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^EnergyFormula</a><a data-href="#^EnergyFormula" href="#^EnergyFormula" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.11)</a>, reducing from the expressions for , gives usRemember that <br>From <a data-href="#^HamiltonianEq" href="#^HamiltonianEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^HamiltonianEq</a><a data-href="#^HamiltonianEq" href="#^HamiltonianEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.5)</a>, using separation of variables, we know it's in the form ofDuring the Cold war, Lev Landau was a famous physicist. He got in a serious car accident, and got brain damage. After recovering, he still wasn't at his prime, but he apparently said "I'm not the Landau I used to be, but I'm still smarter than you." to Pauli 💀<br>Proof of <a data-href="#^dab03c" href="#^dab03c" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dab03c</a><a data-href="#^dab03c" href="#^dab03c" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.2.1 (Cyclotron Frequency)</a>. GivenClassicallyWe can add these expressions for together, to get the below
You can just explain the above as satisfying conservation of energy. The magnitude of total velocity, is The solutions to the equation are then<br>Plugging this into <a data-href="#^derivationOfDiffEq" href="#^derivationOfDiffEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^derivationOfDiffEq</a><a data-href="#^derivationOfDiffEq" href="#^derivationOfDiffEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.19)</a>□Definition 2.2.1 (Cyclotron Frequency).
Given a charged particle, in a constant-magnetic field, the frequency of the particle's oscillationi n the field is This means that the initial velocity in the direction, is at . The velocity on the direction is subsequently at Note that classically, with just the energy there's infinite solutions. You need a space constraint.Once again, we use the given field construction ofRemember from electro thatCan we look this up, I've not taken electro is some arbitrary potential field ig
This is a useful definition because it ensures that the divergence of is zero. <br>When you have a charged particle, compared to before in <a data-href="#^HamiltonianEq" href="#^HamiltonianEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^HamiltonianEq</a><a data-href="#^HamiltonianEq" href="#^HamiltonianEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.2.5)</a>, it isUnfortunately, you need Lagrange mechanics to finish the derivation.
Just take it as given thatExercise 2.2.2 (Try and find a way to have the above make sense with Lorentz's force. If not he's gonna try to simply explain it).There is an infinite set of which can give us a fixed . This is gauge invarianceBoth those values of give the same NOTE: The wave-functions might differ, but the energies are the same. You don't measure wave-functions, you measure it's properties.
This is gonna be on homework, so if you feel like there's a contradiction be careful
Choosing the gauge field to beContinuing onThis shows us first of all, that the energies on are free. This also clearly shows us thatBut what about ]]></description><link>school/physics/quantum-1/notes/2.2-2d-boundary-and-electric-field.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/2.2 2D Boundary and Electric Field.md</guid><pubDate>Thu, 17 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.4 Rotation and Angular momentum]]></title><description><![CDATA[Missed last class, so like, do with that what you willA rotation is defined by an axis and an angle . The group is commutative, the order of rotations matter.Take the component on the direction to be zero, since it isn't influenced by the rotation.
We can then write We can see that it's related by some rotation that we can see Now we want to this along the axis at an increment of This is just the commutator right?We now want to work to the second order of . .That's because rotations of a very small angle are essentially a translation
i.e, we're doing the second order taylor expansion for . First order infentesimal rotations are translations, which should commute.
ow to take the differenceThe claim is that this above matrix, is justWe talked about last time how rotation matrices must be unitary, and have to depend on the same vars as the initial rotation matrix. For an infinitesimal rotation along a small axisFirst question, what the hell is ? The generator of rotations.
What are the dimensions of this? is an angle, and has no dimension, so the units match . That means has dimensions of angular momentum.Definition 2.4.1 (Angular Momentum (Quantum Mechanics)).
The generator of rotation is the angular momentum, similar to <a data-href="1.8 Translation and Momentum#^cc4d99" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^cc4d99" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8 Translation and Momentum &gt; ^cc4d99</a><a data-href="1.8 Translation and Momentum#^cc4d99" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^cc4d99" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.3 (Momentum (Quantum Mechanics))</a>
same vars as the initial rotation matrix. For an infinitesimal rotation along a small axis The same way that the momentum was hermitian, Exercise 2.4.2 (AT HOME: Perform the above derivation, note that the relation between linear translation and linear momentum has been derived before, so we need to repeat that in this new case.).Unlike classical mechanics, we know that we can only have discrete available possible angular momentum. These are all operators, what is the algebra of these operators?
The multiplication table of the rotations is completely copied by the 's.<br>
Proof of <a data-href="#^9f4662" href="#^9f4662" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^9f4662</a><a data-href="#^9f4662" href="#^9f4662" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.4.3 (Angular Momentum Commutation)</a>.<br>
Below is extended from <a data-href="#^OrthogonalRotationCommutationRelation" href="#^OrthogonalRotationCommutationRelation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^OrthogonalRotationCommutationRelation</a><a data-href="#^OrthogonalRotationCommutationRelation" href="#^OrthogonalRotationCommutationRelation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.7)</a>, and <a data-href="#^241bdc" href="#^241bdc" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^241bdc</a><a data-href="#^241bdc" href="#^241bdc" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.4.1 (Angular Momentum (Quantum Mechanics))</a> □<br>Definition 2.4.3 (Angular Momentum Commutation). Where is from <a data-href="1.3 Commutators, and Observables#^symtensor" href="school/physics/quantum-1/notes/1.3-commutators,-and-observables.html#^symtensor" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.3 Commutators, and Observables &gt; ^symtensor</a><a data-href="1.3 Commutators, and Observables#^symtensor" href="school/physics/quantum-1/notes/1.3-commutators,-and-observables.html#^symtensor" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.3.4 (Totally Symmetric Tensor)</a>
This is also the algebra of SU(2) This is also the algebra we found for spin! That's why it's also a generator of rotationsAn important note, is that you can't directly measure any of theseLet's findThis is true for all the axis!Where are the simultaneous eigenstates.If you don't let me do this, I'll kick you out of class. Put you in jail, you'll have to wait for TrumpFor kicks, we're going to now findWhereStartingThe same thing with happens, soNow a question is an eigenstate of ? To do this, we're going to use our algebra.Then you can see that it must be an eigenstate, becauseThis means that is a raising operator on the eigenvalue on Taking an aside for that inner operator<br>Back to <a data-href="#^normValue" href="#^normValue" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^normValue</a><a data-href="#^normValue" href="#^normValue" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.20)</a>, from <a data-href="#^eigenstatesOfAlphaBeta" href="#^eigenstatesOfAlphaBeta" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^eigenstatesOfAlphaBeta</a><a data-href="#^eigenstatesOfAlphaBeta" href="#^eigenstatesOfAlphaBeta" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.4.13)</a> . This reduces to give usThere exists an , because otherwise the norm can be negative which won't make sense. Also, we can induce that Our final two deductions summarized areThis means that itself can be a non-integer!If not, you have crapoola, something like Trump's politics.Think about for next time, what is the spectrum of a particle confined to a sphere?]]></description><link>school/physics/quantum-1/notes/2.4-rotation-and-angular-momentum.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/2.4 Rotation and Angular momentum.md</guid><pubDate>Thu, 24 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.6 Spherical Harmonics]]></title><description><![CDATA[Today we worked out the math for the spherical harmonics, which is critical to understanding the behavior of an electron in the hydrogen atom.Test is 8am to 8pm
This system is called a fixed rotor.
Started discussing orbital angular momentum, with the particle on a sphere and it's classical energy levels.Where the moment of inertia for a particle on a sphere, isand is the angular momentum. Last time, we showed that it satisfies the algebra of generators of rotation
Additionally, we have the same properties of <a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 Harmonic Oscillation &gt; ^dbc3f4</a><a data-href="1.10 Harmonic Oscillation#^dbc3f4" href="school/physics/quantum-1/notes/1.10-harmonic-oscillation.html#^dbc3f4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.10.2 (Raising and Lowering Operator)</a> On a sphere, it's just more appropriate to use spherical coordinates since we're not masochistsNow for our energiesWhereNotice that every energy level has a degeneracy, for now accept we can't have <br>For our ground state, from <a data-href="#^raisingRotation" href="#^raisingRotation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^raisingRotation</a><a data-href="#^raisingRotation" href="#^raisingRotation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.4)</a> we now get the energiesFor each energy state that there are increasing degenerate states. The particle has increasing superpositions.
The probability of a particle being in any given region on the sphere, like the upper half, is non-zero but isn't always .Every time you have a degeneracy, there is a symmetry going onLet's say we had the stateand we want the probability in the northern hemisphere.
We want to find the probability of finding at a given In this case, we know that is just composed of . What we want to find out is the spherical harmonics in this case.Definition 2.6.1 (Spherical Harmonics).
For a given spherically confined state, in terms of , the spherical harmonics are denoted as Those harmonics can be expressed in terms of as When we talk about the eigenstate of a position in , we're talking about generallyThen the same is true on a sphere, but we also know that the radial direction is frozenIf we were then to rotate along the axis by through , this rotation implies an operation on the state. Spherical coordinates really shine here.<br>
Proof.@ <a data-href="#^3398f1" href="#^3398f1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^3398f1</a><a data-href="#^3398f1" href="#^3398f1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.6.1 (Spherical Harmonics)</a> <br>To get our harmonics, we're going to do an infinitesimal rotation on using <a data-href="#^rotationSphericalRelation" href="#^rotationSphericalRelation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^rotationSphericalRelation</a><a data-href="#^rotationSphericalRelation" href="#^rotationSphericalRelation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.12)</a>Now combining the two equivalencies for the spherical harmonics<br>But how do we find in <a data-href="#^sphericalHarmonicEquation" href="#^sphericalHarmonicEquation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^sphericalHarmonicEquation</a><a data-href="#^sphericalHarmonicEquation" href="#^sphericalHarmonicEquation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.14)</a>?<br>Let's go back to <a data-href="#^raisingRotation" href="#^raisingRotation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^raisingRotation</a><a data-href="#^raisingRotation" href="#^raisingRotation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.4)</a>, we can apply the raising or lowering operators to the following states, and they return zeroDefined in cartesian coordinates, there are the following definitions of the angular momentum in terms of cartesian coordinates and their momenta.Now converting to sphericalExercise 2.6.2 (AT HOME: Derive the below using the spherical transformation).
Just change of coordinates
Wait till trump gets to be president, theres going to be a lot of issues like that*
that being writing in one country, and in another, both meaning cotangent.
<br>Now we're going back to our expected value of the raising operator, and substituting in <a data-href="#^sphericalHarmonicEquation" href="#^sphericalHarmonicEquation" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^sphericalHarmonicEquation</a><a data-href="#^sphericalHarmonicEquation" href="#^sphericalHarmonicEquation" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.14)</a> Finally, we find that the spherical harmonics are Exercise 2.6.3 (AT HOME: Repeat [[#^derivationForHarmonic]] for ).Repeating the derivative an number of times allows you to get to any m, not just . We're bounded on the number of possible harmonics we are able to occupy at all, over the range of □In case you're ever being tortured, manually calculate the 's in your head. Dedissociate from the situationNow let's take the state , and we want to know the probability of being in the lower hemisphere?Why is the differential , and not just ?
There is a jacobian! Then <br>Continuing on using <a data-href="#^mequalsL" href="#^mequalsL" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^mequalsL</a><a data-href="#^mequalsL" href="#^mequalsL" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.19)</a>Key assumption, to prove at a later date,]]></description><link>school/physics/quantum-1/notes/2.6-spherical-harmonics.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/2.6 Spherical Harmonics.md</guid><pubDate>Thu, 31 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3.3 Introduction to Perturbation Theory]]></title><description><![CDATA[We're continuing directly from <a data-href="3.2 Two Particles-The Hydrogen Atom" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.2 Two Particles-The Hydrogen Atom</a><a data-href="3.2 Two Particles-The Hydrogen Atom" href="school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">3.2 Two Particles-The Hydrogen Atom</a>, and then introducing non-degenerate perturbation theory. That kind of perturbation theory only works with no degeneracies, with the hydrogen atom that's the ground state.Theorem 3.2.1 (The Energy level of a Hydrogen Atom). is the mass of the electron, is the charge of it, is planks constant, and is the quantum number Something to note when we get the wave-function, is that if we have a value of equal to zero, the wave-function won't vanish at . That's because we have no angular momentum. Notice that as you increase , the energy level lines get closer together. When we clear those lines by kicking the electron hard. That's ionizationDefinition 3.3.1 (Bohr Radius).
The Bohr radius is defined as the most probable distance an electron takes from the hydrogen atom We rarely can solve a problem exactly, so one has to develop techniques to approximate the exact result. This is Perturbation theory. The quality of a physicist is fancy approximations. One of the techniques is called perturbation theory.Definition 3.3.2 (Perturbation Theory).
Let's say we have a hamiltonian, with a spectrum we know. A perturbation is something really small. Small means a distance in relation to another.
Imagine a 1D Harmonic oscillator, with a small un-harmonic-nessThe units of isThe scale of this is nothing without a comparison. Let's say we want to refer to the energy of the un-harmonic term, compared to the harmonic term . We can use Perturbation Theory whenover relevant 's
We want to solve <br>when it is in the form of <a data-href="#^perturbationForm" href="#^perturbationForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^perturbationForm</a><a data-href="#^perturbationForm" href="#^perturbationForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Perturbation Theory)</a>. We're writing this asWe basically represent our state as correction terms of increasing size. Where we stop our expansion is up to the context of the experiment.<br>
We're going to solve <a data-href="#^perturbationForm" href="#^perturbationForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^perturbationForm</a><a data-href="#^perturbationForm" href="#^perturbationForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Perturbation Theory)</a> using <a data-href="#^expansion" href="#^expansion" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^expansion</a><a data-href="#^expansion" href="#^expansion" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.5)</a>. To simplify this, we're going to normalize our exact state.We're writing this out together asBreaking this up in terms of orders <br>We made an initial assumption from <a data-href="#^innerProdAss" href="#^innerProdAss" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^innerProdAss</a><a data-href="#^innerProdAss" href="#^innerProdAss" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.6)</a> which by extension meant the th perturbed state, is orthogonal to the th state when Theorem 3.3.3 (First Perturbed Energy).
The first order correction to the energy on the th energy level is just the expectation value of the perturbation in the unperturbed state <br>Proof.@ <a data-href="#^energyOf2ndEps" href="#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^energyOf2ndEps</a><a data-href="#^energyOf2ndEps" href="#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> and <a data-href="#^stateOfFirstEps" href="#^stateOfFirstEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^stateOfFirstEps</a><a data-href="#^stateOfFirstEps" href="#^stateOfFirstEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.4 (First Perturbed Wave-function)</a><br>
Now for the second order correction we go back to <a data-href="#^mainPerturbedEq" href="#^mainPerturbedEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^mainPerturbedEq</a><a data-href="#^mainPerturbedEq" href="#^mainPerturbedEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.7)</a> to With more math massaging, we getThis is useless! We need We claim that<br>We get this from completeness since this is just identity times the vector we want. From <a data-href="#^idkanymore" href="#^idkanymore" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^idkanymore</a><a data-href="#^idkanymore" href="#^idkanymore" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.8)</a>, we're instead going to project on , and we're going to assume there's no degeneracies.<br>This is what we're looking for in our summation in <a data-href="#^completenessClaim" href="#^completenessClaim" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^completenessClaim</a><a data-href="#^completenessClaim" href="#^completenessClaim" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.11)</a>Theorem 3.3.4 (First Perturbed Wave-function). <br>Which then gives us from <a data-href="#^secondPerturbationApprox" href="#^secondPerturbationApprox" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^secondPerturbationApprox</a><a data-href="#^secondPerturbationApprox" href="#^secondPerturbationApprox" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.3.10)</a>Another way of writing this is:Theorem 3.3.5 (Second Perturbed Energy). In the ground state, the second perturbed ]]></description><link>school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/3.3 Introduction to Perturbation Theory.md</guid><pubDate>Tue, 19 Nov 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.5 Induced Dipole Dipole Interaction]]></title><description><![CDATA[This felt like a rehash of the second half <a data-href="3.4 More Perturbation Theory" href="school/physics/quantum-1/notes/3.4-more-perturbation-theory.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.4 More Perturbation Theory</a><a data-href="3.4 More Perturbation Theory" href="school/physics/quantum-1/notes/3.4-more-perturbation-theory.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">3.4 More Perturbation Theory</a>, but substantially less rushed. We derived the induced dipole interactions which are responsible for Vanderwals forces. We also began describing the behavior of the hydrogen atom in an external magnetic field, through a parameter called the polarizability.Definition 3.3.2 (Perturbation Theory).
Let's say we have a hamiltonian, with a spectrum we know. A perturbation is something really small. Small means a distance in relation to another. We're assuming we're in some atom, so just like last time This means our eigenstates look likeThis means that the ground state of our system is represented byFrom here onward, we're denoting as the ground stateThen we use
Classically, remember that we thought we were getting a dipole dipole attraction. We're making the approximation that the atoms aren't overlapping, as noted in the diagram.<br>
From last time, <a data-href="3.4 More Perturbation Theory#^PotentialForm" href="school/physics/quantum-1/notes/3.4-more-perturbation-theory.html#^PotentialForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.4 More Perturbation Theory &gt; ^PotentialForm</a><a data-href="3.4 More Perturbation Theory#^PotentialForm" href="school/physics/quantum-1/notes/3.4-more-perturbation-theory.html#^PotentialForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.4.14)</a>
Because of our approximation, we're going to factor With this algebraic expansion, we're going to use our taylor expansion of thisWe stopped the approximation at the quadratic term. The higher order terms are sub-leading corrections. Perturbation theory wants us to neglect anything except the leading terms. Precision means we wanna keep this, but we get good approximations with this.
This needs to be done with each term in the potentialExercise 3.5.1 (AT HOME: Work this out if you wanna practice Taylor expansions).Through this expansion, the drops. Using the fact that ,The interaction energy is how much the energy changes based on the actual interaction.<br>
We know that the interaction should depend on the distance between the atoms. However, in <a data-href="#^energyState" href="#^energyState" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^energyState</a><a data-href="#^energyState" href="#^energyState" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.5.1)</a> we can see no dependence on distance. We are going to keep looking for perturbed energies until we find the first one with this dependance. (That's the leading term)
Let's go to the first perturbed state
Theorem 3.3.3 (First Perturbed Energy).
The first order correction to the energy on the th energy level is just the expectation value of the perturbation in the unperturbed state We know instantly that this is zero. We're in a spherically symmetric potential, so there should be no dependence on any cartesian terms!The expectation value of a vector, in a sphere, is obviously zero.
This is why books will often say that the dipole dipole interaction is induced.<br>Now to the <a data-tooltip-position="top" aria-label="3.3 Introduction to Perturbation Theory > ^energyOf2ndEps" data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">second perturbed energy</a><a data-tooltip-position="top" aria-label="3.3 Introduction to Perturbation Theory > ^energyOf2ndEps" data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">second perturbed energy</a>We now want to make a deliberate mistake. In the denominator of the second perturbed energy, we're going to set only there. We do this to enable an upper bound on our second perturbed energy. Any higher excited states will be larger than , which means that as being in the denominator, it'l be smaller. Manually doing the computation from the second perturbed energy without a computer would suck, and he can't do it. <br>We know that because it's the square of <a data-href="#^potentialApprox" href="#^potentialApprox" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^potentialApprox</a><a data-href="#^potentialApprox" href="#^potentialApprox" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.5.5)</a> just because of how the above is our inner product in <a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> .
But these are the wrong units! We need to throw some more things into there, but to fix the units it has to depend on something. There's an extra term. The only other relevant distance is the size of the atom !This is crud though, the units are still garbage.
Notice that we have so far only pulled our information from the numerator of the second perturbed energy. Once we factor in the denominator of , we getWe're summing over , which would give us some nasty constant, but theres a factor of in there we need to divide out.
Doing thatThe ground state energy always goes down in second order energy. That makes this negative!<br>What does mean? is just the numeric constant that came from summing over in <a data-href="#^secondEnergyDenom" href="#^secondEnergyDenom" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^secondEnergyDenom</a><a data-href="#^secondEnergyDenom" href="#^secondEnergyDenom" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.5.11)</a> and the summation from <a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> How much the atom stretches is called it's polarizability.We have a force of The atom stabilizes when the force from the electric field equals the force exerted by the proton to the charge itself. It's cubed because of the same reason falling through the earth doesn't yield infinite energy, there's less mass below you as you go. It goes by volume.
This means our electric field isWhere is the dipole (remember a dipole is charge times length)
But hydrogen atoms don't have volume, so we're gonna need perturbation theoryWe have a hamiltonian of at least<br>Claim that so we can do <a data-href="3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory &gt; ^perturbationForm</a><a data-href="3.3 Introduction to Perturbation Theory#^perturbationForm" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^perturbationForm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 3.3.2 (Perturbation Theory)</a>
Our ground state isThis is zero because of the position dependance. We have to go to our second perturbed state.Using a given definition on the units of a dipole,Exercise 3.5.2 (AT HOME: Check this!).
I can tell it's proportional because this is the first energy where the untis can match the dipole, but I'd like to work it out
The reason we could make that jump was because was the only operator wedged in the inner product, so we could pull the scalars out.
This tells us or dipole-ness isBUT WE HAVE DEGENERACIES! Our different excited states will make the math all wacky and funky.]]></description><link>school/physics/quantum-1/notes/3.5-induced-dipole-dipole-interaction.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/3.5 Induced Dipole Dipole Interaction.md</guid><pubDate>Tue, 03 Dec 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[Squeezed Light]]></title><description><![CDATA[<img alt="../../../../../Supplemental Files/images/Pasted image 20240902194106.png" src="supplemental-files/images/pasted-image-20240902194106.png" target="_self">
The idea essentially uses the uncertainty principle to trade off certainty in one region, for lack of certainty in another. It is generated by non-linear mediums. Just like the picture above, the uncertainty is represented by the area of the ellipse, and so the ellipse can be rotated and scaled in any direction.]]></description><link>school/physics/quantum-1/notes/squeezed-light.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/Squeezed Light.md</guid><pubDate>Mon, 02 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.3 Commutators, and Observables]]></title><description><![CDATA[We discussed more specific properties of Observables, using the idea of a commutator to structure them more strictly.
The reason we haven't talked about matrices yet, is because we're building from the ground up. We have no clue yet if these operators can be described with matrices or not.We now want to calculate the observableWe make that expansion, because of the completeness of the basis. Now we expand out to see what we can getWe know that are eigenvectors of , which meansUsing this, and the fact that because of orthogonality, we then getIn the basis, it's the same thing. Since we've decided to work in the eigenbasis, how can we represent the above definitions in this basis?Definition 1.2.5 ( represented in the basis). We can use the above definitions to help.Now we want to multiply it all out, and see what we can reduce. This can be done my simple rules of reduction.Definition 1.3.1 ( observables written in the basis). If the above vectors are orthogonal, do they not evaluate to zero?
Maybe because they're outer products it doesn't
Lets say there is a basis as Those two vectors are orthogonal in a standard basis Because the outer product of the spanning vectors is not the zero matrix, orthogonal vector's outer products doesn't need to be the zero vector
We know that for any matrixWe're now going to perform the same process on the operator THIS IS NOT THE ZERO OPERATORGiven that are eigenvectors of , we have established thatWhere Definition 1.3.2 (Commutator).
Given two observables , we can determine if some operators commute if If the commutator (which is denoted by square brackets) is equal to zero, the operator commutes
What's the easiest way to check the Commutator of .
Acting it on a general vector would be a huge pain in the ass?
Multiplying it out would also be a pain in the ass.
I guess we're multiplying it outExercise 1.3.3 (Find ). Now multiplying out the first term THIS IS CRAZY, CAUSE THAT INNER THING IS For homework, we're going to do Definition 1.3.4 (Totally Symmetric Tensor).
Where is the totally symmetric tensor. Any of the values can be sqapped around. Where This also means that Because that is any number which is the negative of itself Definition 1.3.5 (General formula for Commutator). Where is the <a data-tooltip-position="top" aria-label="^symtensor" data-href="#^symtensor" href="#^symtensor" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Totally Symmetric Tensor</a><a data-tooltip-position="top" aria-label="^symtensor" data-href="#^symtensor" href="#^symtensor" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Totally Symmetric Tensor</a> Exercise 1.3.6 (Given [[#^19c567]] find ). I should review commutators, this hurts my brain
]]></description><link>school/physics/quantum-1/notes/1.3-commutators,-and-observables.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.3 Commutators, and Observables.md</guid><pubDate>Thu, 05 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.6 Working with the Schrödinger Equation]]></title><description><![CDATA[Note that 1.5 can be found in the purple journal, including the Schrödinger Equation Derivation.Going from one state to anotherThis unitary preserves probabilityWe can realize just by looking at this thatUnitarity is time-reversible, so if we know a Unitary, we can reverse to get the Quantum state
Proof. Derivation of the Schrödinger EquationAlsoAndWhere is the generator of time translationDefinition 1.6.1 (Hamiltonian).
The Hamiltonian (denoted in the Schrödinger Equation) is the Generator of time translations in a quantum system. It has units of Energy, so it's eigenvalues are energy states of a system.
Most commonly it is denoted as for a particle in a potential Evolving on a random system over time has the below derivationFrom before, we know that is the <a data-href="#^ba33b7" href="#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^ba33b7</a><a data-href="#^ba33b7" href="#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> so Now we divide by , and take the limit□Definition 1.6.2 (Schrödinger Equation). Also written as The only condition you need to solve this equation, is Where is a Unitary, is the identity, and is the hamiltonian of the Hamiltonian Now we want to define the equation for the time evolutionWhere the initial state is Example 1.6.3 (What are the energies of the system). In the above derivation, remember that in the notationAbove are the energies for the spin system. In general, a state in that system at a given time, can be writtenYou can notice that the eigenvectors here are just energy eigenstatesThis is just another system of define a wave-function, but now in terms of it's possible energy states.
This then reduces towhere is just the eigenvalue.Now we're going to multiply the left by This is just a first-order differential equation!Because it's a first order equation, one solution is linearly identical to all solutionsThis means that for any given system, if we know the Hamiltonian , the spectrum of the hamiltonian, the eigen-system, and then an initial state, we know how the system evolves over time.<br>
The easiest way to solve the <a data-href="#^ba33b7" href="#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^ba33b7</a><a data-href="#^ba33b7" href="#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> , is if we know the eigenstates of the <a data-href="#^d06020" href="#^d06020" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^d06020</a><a data-href="#^d06020" href="#^d06020" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.1 (Hamiltonian)</a> What you cannot do, is change the relative weights of the constants freely, because there are relative phases between them. The only thing you can change, is the global phase of the state
Definition 1.6.4 (Stationary State).
Any state which is stationary through being first order, and follows the below behavior Let's take the below initial stateExample 1.6.5 (Given , and the spectrum of the Hamiltonian what is the probability of ending up at again over time?). Definition 1.2.5 ( represented in the basis). First we need to convert to an energy state in the correct basis Ask What is the probability we land on again over time? Now we want the probability of that, so the absolute value squared 1import matplotlib.pyplot as plt2t = np.linspace(0,4*np.pi,200)3plt.plot(t,np.cos(t)**2)4plt.axhline(y=1,linestyle = '--',color = 'r')5plt.tick_params(axis='x', which='both', labelbottom=False)6plt.axvline(x=np.pi/2,linestyle = '--',color = 'r')7plt.grid()8plt.show()Run<br>
<img src="supplemental-files/images/pasted-image-20240917103717.png" target="_self">
We land on the x-axis at multiples of . The red-dashes above denote when we are in the state.The neutrino eigenstates inside the sun, aren't the same as the neutrino eigenstates outside the sun. The state produced by the nuclear reactions, oscillates between two corresponding states.Solving a Two state system, . We don't know what the observable is. Imagine we don't know the spectrum of the Hamiltonian
Exercise 1.7.1 (Find the energy states of a system given the below Hamiltonian, with states ). ^problem
Now we don't know the eigenstates of the system, and even less so the Hamiltonian evolves over time with an oscillating time-dependent component.
First assume two things Both can just be changed with convention if a contradiction comes up, with it's just by flipping them, and with , you wrap the phase into the exponential.
We want to ask the same as before are energies because dimensions must match, is frequency. is an energy
This is a ton of energy values, and depending on their magnitude, the system will be crazy over time.
One thing that can happen, is resonance.
We have to solve the differential equation from the Schrödinger Equation<br>
<a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> ]]></description><link>school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/1.6 Working with the Schrödinger Equation.md</guid><pubDate>Tue, 17 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.5]]></title><description><![CDATA[See Green Journal ]]></description><link>school/physics/quantum-1/notes/2.5.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/2.5.md</guid><pubDate>Thu, 31 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.2 Two Particles-The Hydrogen Atom]]></title><description><![CDATA[We solved for the energy states of the Hydrogen atom with a Coulomb potential. Last time we were discussing spherically symmetric hamiltonians. For reference <a data-href="3.1 Spherically Symmetric Potentials#^radiusDepHam" href="school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html#^radiusDepHam" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.1 Spherically Symmetric Potentials &gt; ^radiusDepHam</a><a data-href="3.1 Spherically Symmetric Potentials#^radiusDepHam" href="school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html#^radiusDepHam" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.1)</a>
Definition 2.6.1 (Spherical Harmonics).
For a given spherically confined state, in terms of , the spherical harmonics are denoted as Those harmonics can be expressed in terms of as We just need to change our spherically symmetric potential from the hamiltonian(Just a standard Coulomb potential)<br>
Similar to <a data-href="3.1 Spherically Symmetric Potentials#^diffEq" href="school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html#^diffEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.1 Spherically Symmetric Potentials &gt; ^diffEq</a><a data-href="3.1 Spherically Symmetric Potentials#^diffEq" href="school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html#^diffEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.16)</a>Classically with a columb potentialWe're doing to make the following substitutions<br>We're off-screening the math for the sake of sanity, substituting the diffeq from <a data-href="3.1 Spherically Symmetric Potentials#^diffEq" href="school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html#^diffEq" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.1 Spherically Symmetric Potentials &gt; ^diffEq</a><a data-href="3.1 Spherically Symmetric Potentials#^diffEq" href="school/physics/quantum-1/notes/3.1-spherically-symmetric-potentials.html#^diffEq" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.1.16)</a> with our new potential and substitutionsAt a fixed , there will always be possible states. For our value of rho, we're going to take the limit of the diffeq as . We decay by at infinity. If the result is nonsense cause then we'd get infinite energy
For Same reason for throwing out as we did for .Now that we have the end and initial behaviors, we conjecture that is of the formWhy can I just say that the solution is of this form?
This product is just because it is an easy way to capture both behaviors of the function.If you can find a way to combine the fact of those end behaviors, then any trick will do.
Now we want to solve for that term, by plugging back into the diffeq. We do this by expressing this as a power series!Going to that fourth step, is a matter of recognizing that now our sum has a recursion relation, which means we can't explicitly solve for . This can be seen more obviously if you plug in for a fixed value of . Off-screening the math, you can recognize that the way to reduce the recursion relation.Plugging this value of the ratio into our summation expression for assuming that there is infinite <br>Serious problem though, if we now plug back into <a data-href="#^conjecturedSolution" href="#^conjecturedSolution" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^conjecturedSolution</a><a data-href="#^conjecturedSolution" href="#^conjecturedSolution" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.2.7)</a>, we now break our end behavior criteria! As we approach infinity, the wave-function now also goes to infinity. The only way to get out of this problem, is if the series is bounded. There has to be a fixed number of possible .<br>
From <a data-href="#^recursiveRatio" href="#^recursiveRatio" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^recursiveRatio</a><a data-href="#^recursiveRatio" href="#^recursiveRatio" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.2.8)</a>,because , we know that ! must be quantized and even!I don't think he's going to pass confirmation, but if mr. Gaetz does, then he's going to allow wavefunctions to go to infinity, at infinityGood luck to you guys...With all this information, we findTheorem 3.2.1 (The Energy level of a Hydrogen Atom). is the mass of the electron, is the charge of it, is planks constant, and is the quantum number Those are the energy levels when .
Higher quantum numbers have lower energies. This makes sense with classical coulomb potentials. But, WHERE DID OUR DEPENDENCE GO? The Hydrogen atom no longer needs this quantum number on the energy!
There are a BUNCH more quantum numbers for us now to occupy for ground states. Recall we already found thatWhy the quantum number vanished, is beyond this course. There is a symmetry, which "has something to do with "<br>
There is an additional symmetry called "Runge-Lenz vector". Like the hearth moves around the sun, there's something conserved there other than angular momentum. That's the <a data-tooltip-position="top" aria-label="https://www.youtube.com/watch?v=a7hj_0r3_Ws" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.youtube.com/watch?v=a7hj_0r3_Ws" target="_self">Runge-Lenz vector.</a>What was the importance of We never solved for and thusly , so it wasn't important
We never solved for the wave-function, just the energies]]></description><link>school/physics/quantum-1/notes/3.2-two-particles-the-hydrogen-atom.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/3.2 Two Particles-The Hydrogen Atom.md</guid><pubDate>Thu, 14 Nov 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.4 More Perturbation Theory]]></title><description><![CDATA[We worked out some examples of non-degenerate perturbation theory. First for a case we can analytically solve, then for two non-analytic cases.From last time,
<a data-href="3.3 Introduction to Perturbation Theory#^stateOfFirstEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^stateOfFirstEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory &gt; ^stateOfFirstEps</a><a data-href="3.3 Introduction to Perturbation Theory#^stateOfFirstEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^stateOfFirstEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.4 (First Perturbed Wave-function)</a><br>
<a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> Theorem 3.3.4 (First Perturbed Wave-function). Theorem 3.3.5 (Second Perturbed Energy). In the ground state, the second perturbed We're doing an example that doesn't need perturbation theory in principle, so we can see how it works.We're going to rewrite as To find the nth level, we already know from simple harmonic oscillators thatWe're going to do a taylor expansion to this, and stop at the first termThen the first term will beOur perturbation on the first order should yield the same answer.We're going to some the first order for a non-harmonic oscillatorNote that we can't go too far from the equilibrium position, because then dominates We'd put them in tar and cover then in feathers. We used to do this to professors that teach nonsense. We know that the unperturbed hamiltonian is just a harmonic oscillator, soOur first perturbed is<br>Finally, from our first order approximation method <a data-href="#^energyGround" href="#^energyGround" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^energyGround</a><a data-href="#^energyGround" href="#^energyGround" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(3.4.8)</a> This approximation is only valid whenIf this condition is not met, your perturbed state exceeds your unperturbed state, then you cannot use this approximationThings just got fancy.How can two neutral atoms even interact?
Vanderwalls forces! Depending on "where" your electron is, you might experience EM forces!
The Hamiltonian is pretty obviously including the sum of the two hamiltonians, and the mutual interactions. We get those from electron-electron interactions, and proton-electron interactions. <br>We want to use <a data-href="3.3 Introduction to Perturbation Theory" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory</a><a data-href="3.3 Introduction to Perturbation Theory" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">3.3 Introduction to Perturbation Theory</a> so we also need to decide whats perturbed, and whats not.(Note that the absolute values mean the magnitude)
Our spectrum is then going to be of the form Now we're going to to Perturbation Theory.
First, we want to simplify things, note thatThis would be just a dipole-dipole interaction, BUT we'll find that to a leading term it'll be a dipole interaction until we take the expectation value.
The expectation value of a vector, in a sphere, is obviously zero. Integrating vectors through a sphere cancels to zero. The ground state of a hydrogen atom, isn't a dipole-dipole
What we'll find, is that the first order term gives us zero (It's just the expectation value of ). When we go to the second order, we'll see the dipole-dipole term kick out
Theorem 3.3.5 (Second Perturbed Energy). In the ground state, the second perturbed This is what we're doing next time.
The day after the final class, that subsequent Sunday, the final becomes available (Just like the homework). Perturbation theory will be on the exam
Next Tuesday after thanksgiving we finish this
That Thursday we might either do office hours, and go over the kind of questions that the exam will have
That Sunday the exam opens up, and it'll be 3-5 questions
]]></description><link>school/physics/quantum-1/notes/3.4-more-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/3.4 More Perturbation Theory.md</guid><pubDate>Thu, 21 Nov 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[3.6 Final Day and Degenerate Perturbation Theory]]></title><description><![CDATA[We went over the final and it's questions, and then did an introduction for degenerate perturbation theory.How would we go about modelling multiple particle systems, like if we didn't nail the proton to a blackboard
Doesn't have anything to do with the levels, we'd want to go into thte rest frame. We took teh rest frame to sit on the proton, but that's not exact. It doesn't change anything about the calculation itself.
The final stops exactly at the official hour when the official exam stops ~On Friday the 13th~
There's one question which is straightforward, but really tedious. You won't get time to crunch the algebra out the last minute. 9 matrix elements to compute. They're all of the same kind. The grader is going to be gentle over stupid mistakes
Write nice and clear because the grader also has some rough exam. Beware of a haunting colleague of Fischer's. There's a perturbation theory, and it asks us to calculate to a leading order. That means we have to calculate to the first non-zero leading term Some problems might need to make you go further down
If the leading correction is a quadratic, you have to work to that order
There's over a week for this, so he's considering it a homework. Only one question on perturbation theory
There's one question on angular momentum. Orginal angular momentum there's only integers Spin angular momentum is half
Leave solving terrible integrals for the end, at at least get to those points. 8 homeworks 25% on homework, 25% on tests, 30% for the final.
Not dropping nothing
The grades are going to be histogram'ed, first group get's an A, etc etc. If you sit between a group you get pushed up.
It sounds like there was leniency to the homework submission
The grader is gonna upload the solutions to homework 7 and 8
We can also send him an email
What's the best way to study
Don't just cram the night before the exam and pray. Go over the homeworks we'e done, look at the questions. See if you can sketch a solution to it. Compare to the solution, then go again. (Do the same with the tests)
Back to last time with the hydrogen atom in a capacitorThis means that our energized state isWe get the first excited state asWhich means our first energy isOur first perturbed energy is thenTo solve for this, we'd need to solve<img alt="../../../../../Supplemental Files/images/Spherical Harmonics Chart.png" src="supplemental-files/images/spherical-harmonics-chart.png" target="_self">
Using the above, we can then solve out the integral to find that the first perturbed energy is zero.How did we pull our sperical harmonics from that?
I think it has to do with them corresponding to the eigenstate <br>This means we have to go to second order <a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">3.3 Introduction to Perturbation Theory &gt; ^energyOf2ndEps</a><a data-href="3.3 Introduction to Perturbation Theory#^energyOf2ndEps" href="school/physics/quantum-1/notes/3.3-introduction-to-perturbation-theory.html#^energyOf2ndEps" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 3.3.5 (Second Perturbed Energy)</a> What you find, is that the second sum diverges which means that it's not small! That's not good, that's nasty and not helpful. We can see that in the general form
Theorem 3.3.5 (Second Perturbed Energy). In the ground state, the second perturbed The easy way to deal with that, we're going to diagonalize the matrixWhy does diagonalization helpWe're going to define aIn the degenerate case, the reason for the diverging, the can be anything that isn't . But it can be which means that the difference in the denominator is zero. That makes it all blow upThe notation we're using for the matrix is thathas the th entry as Calculating these out (knowing that ) for , means that our matrix isI still don't see how diagonalizing solves our problem? Is it cause we're finding new eigenstates? Because in our larger space, we have degeneracies in our basis vectors, we're instead solving for the energy of the subspace. With the subspace, the basis vectors are linearly independant, and we're saying that our second perturbed energy state is the same are the same. This space also models how the
We find the eigenstates of asThe eigenstates which diagonalize the matrix, are the ones with unique energies. Because it's a very sparse energy, only two of the states are changed. More perturbation terms might evolve the bottom two states based on how the matrix evolves
What is this quantum 1?
Part of this is quantum. 2 for most people. All this angular momentum work has theorems that greatly reduce their complexity
He seemed like he was genuinely unsure
]]></description><link>school/physics/quantum-1/notes/3.6-final-day-and-degenerate-perturbation-theory.html</link><guid isPermaLink="false">School/Physics/Quantum 1/Notes/3.6 Final Day and Degenerate Perturbation Theory.md</guid><pubDate>Thu, 05 Dec 2024 00:00:00 GMT</pubDate><enclosure url="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExa3l5aHZhM2xzMmk5OHV3MjA3MGdkbDFyamFhaWEwbnNqcGRjc213byZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xT0GqgeTVaAdWZD1uw/giphy.gif" length="0" type="image/gif"/><content:encoded>&lt;figure&gt;&lt;img src="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExa3l5aHZhM2xzMmk5OHV3MjA3MGdkbDFyamFhaWEwbnNqcGRjc213byZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xT0GqgeTVaAdWZD1uw/giphy.gif"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[🟩 Overall QIS Class Notes 🟩]]></title><description><![CDATA[Hey y'all! These are my notes from when I took the Quantum Information Science at UT with professor Scott Aaronson from '24-'25.
The <a data-href="0.1 Class Overview" href="school/physics/qis/notes/0.1-class-overview.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">0.1 Class Overview</a><a data-href="0.1 Class Overview" href="school/physics/qis/notes/0.1-class-overview.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">0.1 Class Overview</a> contains a list of every theorem we learned in class, but due to an issue with my website publishing workflow the equations are broken on that page. They still exist in their original notes.]]></description><link>school/physics/qis/notes/🟩-overall-qis-class-notes-🟩.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/🟩 Overall QIS Class Notes 🟩.md</guid><pubDate>Mon, 20 Oct 2025 19:48:28 GMT</pubDate></item><item><title><![CDATA[0.1 Cheat Sheet Notes]]></title><description><![CDATA[For the density matrices, do not actually fully calculate the outer product. Instead, leave in form. Then you take the projections on the relevant orthonormal basis for the other qubits. Those outer products are just like what occurs with measurement!Run through shor's algorithmWrite out all the possible outer products for the existing states, the matrices Shors for when Q/s isn’t an integerAlgorithms need:
Circuit diagram
Classical complexity analysis Classical random Quantum Complexity
Definition 0.1.2 (Deutsch’s Algorithm).
Where Me and <a data-tooltip-position="top" aria-label="../../../../../Personal/People/Ayden Gertiser" data-href="../../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Ayden</a><a data-tooltip-position="top" aria-label="../../../../../Personal/People/Ayden Gertiser" data-href="../../../../../Personal/People/Ayden Gertiser" href="personal/people/ayden-gertiser.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Ayden</a>'s Guess on what's going on:The qubits after testing on the quantum composer, all have the same result. With the gate, it's interesting that it doesn't affect the outcome, but the gate might just be reflecting all the superpositions. Because up to that point it's maximally entangled, flipping the superpositions is just a symmetry, so the does nothing.
Real explanation
The input qubit is the first qubit, while the output is the zeroth qubit. This was the first quantum Computing algorithm. David Deutsch was one of the father's of quantum computing Definition 1.3.1 (Deutsch's Algorithm). Start out with Set output register to Apply Hadamard gates to all qubits
Apply another set of hadamards to all the qubits
Measure the input register
If the output is 0, the function is constant, otherwise it's balanced
Below is a table of the black-box of functions. Using the gates listed above, you'd make this diagram!<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240905163741.png" src="supplemental-files/images/pasted-image-20240905163741.png" target="_self">
Below is an implementation of the quantum protocol<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240905164620.png" src="supplemental-files/images/pasted-image-20240905164620.png" target="_self"> Birthday paradox explanation
Best for collision functions
Euclid's GCD alg
Definition 2.4.1 (Euclid's algorithm). If I wanna know the GCD(40,95), I can always perform integer division small to large, and take the remainder.
In this case, it's 15.
Then we know that (Because if a number can divide 40 and 95, of course it can divide the difference).
You just keep going until you hit the bottom Once one number divides the other, the smaller one is the GCD! Repeated squaring]]></description><link>school/physics/qis/notes/0.1-cheat-sheet-notes.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/0.1 Cheat Sheet Notes.md</guid><pubDate>Thu, 12 Dec 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.8,1.9 Superdense Coding and QKD]]></title><description><![CDATA[Most encryption assumes a shared secret key
The OTP has perfect information theoretic security
We can use this with the secret word, so that it can be perpetually reused
Shannon- Needs a very long, pre-shared key for information security.
The OTP protocol is what eventually evolved into public key cryptography.How can alice and bob have private communication without having to already agree on a OTP in advance?
This was the question conceived when BB84 was made
Could you DIY your own BB84 device? Physically probably notWhat if I'm not confident in the original OTP security method? What can I do then?email: <a data-tooltip-position="top" aria-label="mailto:pmigdal@gmail.com" rel="noopener nofollow" class="external-link is-unresolved" href="mailto:pmigdal@gmail.com" target="_self">pmigdal@gmail.com</a>
This could be a fun side-quest? What are we sending the email for... Work? Maybe I can just introduce myself, say what classes I've taken, and work from there? I prob need my resume updated. Did that!
Maybe just ask if theres more papers they rec, or anything I'd be able to do to help?
Dear ---,
My name is Azal Amer, I am a Physics-CS double major studying at UT Austin. I recently came across quantumflytrap, and was a huge fan of your website. The interface is so intuitive, and I would have really appreciated a tool like this when i was first learning about quantum optics. A personal project of mine has been to make websites demonstrating different physical phenomena, and coming up with a good pedagogy to use when writing websites for quantum behaviors has been something I've struggled with. I was wondering if you could point me in the direction of any papers that helped motivate the creation of the site? Quantumflytrap has such a high level of polish, and I'd love to learn how to make similar tools.
I've attached my resume which includes my quantum-optics experience if that helps.
Hope you're doing well, and thank you so much for your time!
Sincerely,
Azal Amer (he/him) The goal is that Alice randomly selects a basis to prepare her signal in, and then inside that basis the orthogonal axis are labelled 0,1. Bob receives the signal ,randomly measures the bits. Then they publicly announce what gates they both used, and keep the resulting bits. If Eve was monitoring at any useful rate, Alice and Bob can just announce a portion of their key and see if it matches. If the bits don't match at a certain rate, then you assume an intruder, and repeat the procedure.
This generates the OTP, which you can then use a classical channel to transmit information over!
On average, you retain qubits after you want to run the final security step.
90% of the difficulty with a quantum computer, is implementing identity
pmigdal@gmail.com<br>
<img alt="../../../../../Supplemental Files/images/Pasted image 20240919145142.png" src="supplemental-files/images/pasted-image-20240919145142.png" target="_self">Theorem 1.8.1 (Holevo's Theorem (1973)).
By sending Bob qubits, Alice can communicate classical bits of her choice*
for if Alice and Bob have pre-shared entanglement
If Alice and Bob have some preshared qubits in advance, they can actually send information over by a factor of two. There's no savings to be had if we want to send qubits along, as opposed to classical bits
<br>Notice that <a data-href="#^45ead5" href="#^45ead5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^45ead5</a><a data-href="#^45ead5" href="#^45ead5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.8.1 (Holevo's Theorem (1973))</a> had the asterisk of entangled bits, this is why:Definition 1.8.2 (Superdense Coding (Bennett-Wiesner)).Make sure you look at all the possible bell states<br> Suppose Alice and Bob share an entangled <a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation > ^9fbf0d" data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">bell state</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation > ^9fbf0d" data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">bell state</a> , Additionally, they share 1 entangled bit.
With 1 qubit and 1 ebit, Alice can now communicate two classical bits over to Bob Definition 5.1.1 (Bell States).
States that we can use as a basis to make quantum bits in superposition, seperable Coming from last time, let's say Alice measures some qubits, bob measures them, etc. It's just BB84
How can we prove the "No Communication Theorem"But then how can Bob work out what circuit to use to send this? Well Bob can just use a The reason why this can be so useful, is that the density of your communication per packet, is doubled. Even if the number of bits to qubits is the same for fixed information, you can get it there at twice the speed.“This isn’t useful, but it’s kind of interesting in that, well it proves a point😁”
-Aaronson
Alice: :
If x - 1, apply if y=1, apply From this binary coding,
The input bell state maps to ]]></description><link>school/physics/qis/notes/1.8,1.9-superdense-coding-and-qkd.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.8,1.9 Superdense Coding and QKD.md</guid><pubDate>Tue, 17 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.11 EPR and Bell Inequality]]></title><description><![CDATA[Class on what was described in <a class="original-internal-link" data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality.md" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html" target="_self" rel="noopener nofollow" style="display: none;">Hidden Variables and Bell's Inequality</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality.md" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html" target="_self" rel="noopener nofollow">Hidden Variables and Bell's Inequality</a>, ironically both use the same textbook of <a class="original-internal-link" data-href="../Class Files/qclec.pdf" href="school/physics/qis/class-files/qclec.html" target="_self" rel="noopener nofollow" style="display: none;">qclec</a><a class="internal-link mathLink-internal-link" data-href="../Class Files/qclec.pdf" href="school/physics/qis/class-files/qclec.html" target="_self" rel="noopener nofollow">qclec</a>, so both work for this topicIf I have a teleportation protocol implemented, and I have a qubit. Alice has a time evolving unitary which rotates the qubit along the plane, Bob starts with a time evolving unitary rotating it in the plane. Alice prepares and sends the qubit information to Bob, while they both have their initial unitaries. At the moment of sending, Alice uses a classical channel to tell bob to switch his Unitary. Bob starts using for his Unitary rotation when the qubit teleports, but before he receives Alice's measurement data and applies it. Which unitary has the influence on the final state? Can't we say that the identity of the qubit, is with whomsoever has an acting Unitary? Like we can send multiple qubits at known states , and perform QST at Bob. Depending on the state, we know which unitary applied more to the state, and how long they applied for. The EPR question<br>
Start with the <a data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Semester 1/5.1 Quantum Teleportation &gt; ^9fbf0d</a><a data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5.1.1 (Bell States)</a> With this qubit $\ket{\psi}$, Alice knows immediately based on the result of her measurement what the state of Bob's qubit was. This doesn't transmit information, because the information the Alice gets is still random. Bob never knows if Alice has measured so it isn't even a trigger of a state.
But what if Alice measures in the Hadamard's basis with the following gate? <br>Definition (CHSH Game).
<img alt="../../../../Supplemental Files/images/Pasted image 20240711142824.png" src="supplemental-files/images/pasted-image-20240711142824.png" target="_self">
Charlie gives a single digit 0 or 1 to Alice, represented by , and another random digit to Bob. Alice picks some response from that , and Bob picks . To win the game AND should be equal to XOR .
or the same thing is But like how would Alice and Bob communicate their answers for an infinity of all possible basis's? That's a ridiculous amount of information for two qubits to hold, but it's what a local hidden variable needs.Bohr then came along in 1930's, and was like "Bro just deal with it" (HE USED THE ORIGINAL EPR PAPER TITLE FOR HIS LOLL)
Bohmian Mechanics was proposed, seen below
Definition (Bohmian Mechanics).
Essentially a particle in superposition has some "real" location, which is simply guided by the behavior of the superposition. For this to work, we need a rule on how the "guiding" works. The rule must have the property that if anyone does measure the particle, they'll see what QM predicted for it. This theory is a Nonlocal Hidden Variable Theory Definition (Bell's theorem).
Bell's theorem was written to prove that all hidden-variable theories must be non-local.
Bell was the first to ask: do local hidden variables have any empirical consequences that disagree with the predictions of
quantum mechanics? Is there an actual experiment that could
rule out the possibility of local hidden variables? Bell showed up like 30 years later, and basically said, "wtf y'all were NOT done with this argument, there is more to say"The win probability of CHSH is in any LHV theoryDefinition 1.11.1 (Lake Wobegone Principle).
A town where everyone is above average is impossible. Someone must be below average to set it.
"“The human tendency to overestimate one's achievements and capabilities in relation to others."<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://udayton.edu/blogs/erma/2022/06/lakewobegon.php" target="_self">https://udayton.edu/blogs/erma/2022/06/lakewobegon.php</a>
<br>Definition 1.11.2 (Tsirelson's Inequality (1980)).
With any quantum strategy employed for the <a data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality#^0f5bbd" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html#^0f5bbd" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Hidden Variables and Bell's Inequality &gt; ^0f5bbd</a><a data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality#^0f5bbd" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html#^0f5bbd" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5 (CHSH Game)</a> , their probability of winning the CHSH game is at most If you could beat CHSH with a rate above 85%, then QM must be wrong, not just classical We don't get this result tho ]]></description><link>school/physics/qis/notes/1.11-epr-and-bell-inequality.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.11 EPR and Bell Inequality.md</guid><pubDate>Thu, 26 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.12 Density Matricies Again]]></title><description><![CDATA[We introduced the utility of using density matrices to analyze entangled states. This lends us to the idea of entanglement performing the same effects as measurement on a system. This has a really useful intersection with <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Deferred_measurement_principle" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Deferred_measurement_principle" target="_self">The Principle of Deferred Measurement</a>.Density matrices with EntanglementTo calculate Bob's density matrix, you use "Partial Trace"For bob, it's thenAll this is, is a mixed state. Imagine what happens if Alice measures, and then the answer clears up.Theorem 1.12.1 (Density Matrix for an Entangled State and Partial States).
Given any arbitrary entangled state defined below, you can find Bob's density matrix through More generally, make a set which contains all entries in the iterator , then maps to . Then Definition 1.12.2 (No Communication Theorem).
Given that Bob and Alice share an arbitrary entangled pair, no choice of Alice's measurement can affect , given . <br>Proof of <a data-href="#^e940d6" href="#^e940d6" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^e940d6</a><a data-href="#^e940d6" href="#^e940d6" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.12.2 (No Communication Theorem)</a>.
First Alice applies some unitary to her qubitNow look at We initially know that <br>through <a data-href="#^539520" href="#^539520" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^539520</a><a data-href="#^539520" href="#^539520" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.12.1 (Density Matrix for an Entangled State and Partial States)</a> Now Alice applies some unitary measurement to her qubit□]]></description><link>school/physics/qis/notes/1.12-density-matricies-again.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.12 Density Matricies Again.md</guid><pubDate>Thu, 03 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.12 Information and Entanglement]]></title><description><![CDATA[We can quantify the amount of entanglement in a given quantum system through the amount of information in the system. This note is lacking in qualityGiven some mixed state density matrix, is it possible to find out if it's just Alice's part of a whole shared entangled state?
This is called purification.how much entanglement do these two people share this stateThen]]></description><link>school/physics/qis/notes/1.12-information-and-entanglement.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.12 Information and Entanglement.md</guid><pubDate>Tue, 08 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.14 Computing with Quantum States]]></title><description><![CDATA[Today we talked about the actual motivation to create quantum computers at all, and also covered important theorems like <a data-href="#^6dbb59" href="#^6dbb59" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^6dbb59</a><a data-href="#^6dbb59" href="#^6dbb59" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.14.7 ((Gottosen, Knill) Simulating Clifford Gates is in )</a> . "Scott's travelling this week, sort of saving the world from AI, so I'm taking over"
- Nick Hunter Jones
Feynman was the first guy to bring quantum computing up:Say you wanted to simulate a quantum system, we know that If I want to simulate this classically, I have to keep track of a lot of numbers. There's 's for n-qubit state. Pretty soon this scales up to the size of the observable universe.
If I wanted to simulate 260 qubits, then it's , which is the number of atoms in the universe."If you want to simulate a quantum system, you should probably just use a quantum system."The question, is can we then use a quantum system, to simulate a classical problemEven if I can construct a quantum state whereThis just collapses to a single output, since we have to make a measurement.
Our only hope is to "choreograph an interference pattern". Just a a note, is just some arbitrarily small coefficient. Can be polynomial or wtv.
You want a way to make your incorrect answers have a very low probability, while your good solutions have a high one.
But how do we build these unitaries? The key thing, is that these unitaries encode the program.
We want to use k-level gates , things like 1 qubit gates or 2 qubit gates. This is just more practical cause it's easier to act on a few qubits at once, plus it's just modular. is the space complexity, which is the number of qubits, similar to the number of bits is the number of gates in the circuit, or the depth
How do we know it's possible to build n-qubit unitaries out of lower qubit gates?
What a great segway azal 💀, that's next!
The fundamental question is, are there a set of gates which can be used to compose any ?
The analogous classical picture is building up any boolean function from <br>THIS makes sense from <a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" data-href="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" href="school/miscillaneous/tidbit-facts/cook-levin-theorem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Cook-Levin Theorem</a><a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" data-href="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" href="school/miscillaneous/tidbit-facts/cook-levin-theorem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Cook-Levin Theorem</a>, cause any algorithm maps to a boolean one, which then is represented with a series of gates. So then a SAT solver would eject solutions to an arbitrary algorithm.
What then is our fundamental set for quantum? is our gate set. is the cardinality of the set.For some gate set to be universal, our arbitrary n-qubit unitary must be able to be implemented through any qubits Definition 1.14.1 (Exact Universality).
A gate set has exact universality, when any unitary on a qubit of size , can be produced by tensoring gates in the set together. Theorem 1.14.2 (The Standard Gate Set is Universal).
The gate set defined as . Note that must be continuous, so since the cardinalities of the set must match, the set must also be continuous. Can find this in Nielsen and Chuang Quantum Computation and Quantum Information
The issue with Exact Universality, is that it can be really difficult to construct every possible transformation on a qubit, while in a lab.Can we find a universal gate set, which is approximately universal? Definition 1.14.3 ((Approximate) Universal Gate Set). A finite gate set is approximately universal if for any , there exists such that For a smaller , you'd just apply more gates from the set arbitrarily.
Where That is to say, the error is smaller than our resolution of measurement.
Shatton Infinity Norm, or the biggest eigenvalue in the operator.<br>
An example can be found in <a data-href="#^9dfc33" href="#^9dfc33" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^9dfc33</a><a data-href="#^9dfc33" href="#^9dfc33" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.4 (Clifford + T Gate set)</a> One possible such set isWhich is called the Clifford +T<br>Definition 1.14.4 (Clifford + T Gate set). This is an example of <a data-href="#^c11659" href="#^c11659" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^c11659</a><a data-href="#^c11659" href="#^c11659" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.3 ((Approximate) Universal Gate Set)</a> The reason for the relevance of the gate is is a non-orthogonal rotation, being Definition 1.14.5 (Clifford Gates and Clifford Group).
The set of all unitaries generated by All possible combinations of elements in the set, form the Clifford Group.
This is NOT universal. Another similar but distinct problem, is using a finite number of matrices to simulate all of the possible transformations
<br>"This is because the rationals are dense in the reals, you can approximate any rational number"
- <a data-tooltip-position="top" aria-label="../../../../../Personal/People/Aravind Karthigeyan" data-href="../../../../../Personal/People/Aravind Karthigeyan" href="personal/people/aravind-karthigeyan.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Aravind</a><a data-tooltip-position="top" aria-label="../../../../../Personal/People/Aravind Karthigeyan" data-href="../../../../../Personal/People/Aravind Karthigeyan" href="personal/people/aravind-karthigeyan.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Aravind</a>
Another (approximately) universal gate setWhat is the that defines this?Non universal gate sets<br>Note that is just rotation matrices, but it's a weaker version of universality called <a data-href="#^a54159" href="#^a54159" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^a54159</a><a data-href="#^a54159" href="#^a54159" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.6 (Encoded Universal)</a> Definition 1.14.6 (Encoded Universal).
Any given gate set , s.t you can simulate an arbitrary qubit computation, with ancillas <br>What allows <a data-href="#^toffoliGates" href="#^toffoliGates" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^toffoliGates</a><a data-href="#^toffoliGates" href="#^toffoliGates" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.14.6)</a> to be universal, while <a data-href="#^dac7b9" href="#^dac7b9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dac7b9</a><a data-href="#^dac7b9" href="#^dac7b9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.5 (Clifford Gates and Clifford Group)</a> isn't? The only difference is that you can control on an additional bit?
It's not uniquely obvious in the math, esp with the computational basis. It's one of those things you'll need to grind math out for.
<br>Theorem 1.14.7 ((Gottosen, Knill) Simulating Clifford Gates is in ).
Any quantum circuit made from <a data-href="#^dac7b9" href="#^dac7b9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dac7b9</a><a data-href="#^dac7b9" href="#^dac7b9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.5 (Clifford Gates and Clifford Group)</a> , is classically simulatable in <br>Proof of <a data-href="#^6dbb59" href="#^6dbb59" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^6dbb59</a><a data-href="#^6dbb59" href="#^6dbb59" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.14.7 ((Gottosen, Knill) Simulating Clifford Gates is in )</a>. Exercise 1.14.8 (AT HOME: Try and prove this, or at least read the proof).□]]></description><link>school/physics/qis/notes/1.14-computing-with-quantum-states.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.14 Computing with Quantum States.md</guid><pubDate>Tue, 15 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.15 More on Universal Gate Sets]]></title><description><![CDATA[Went through the more theorems on Universal Gate sets, and the different types of circuit complexity. = Minimal number of gates from required to approx. to Definition 1.14.3 ((Approximate) Universal Gate Set). A finite gate set is approximately universal if for any , there exists such that For a smaller , you'd just apply more gates from the set arbitrarily.
Where That is to say, the error is smaller than our resolution of measurement.
Shatton Infinity Norm, or the biggest eigenvalue in the operator.
An example can be found in <a data-href="#^9dfc33" href="#^9dfc33" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^9dfc33</a><a data-href="#^9dfc33" href="#^9dfc33" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.4 (Clifford + T Gate set)</a> <br>But how do we find the minimal possible distance between some Unitary, and the <a data-tooltip-position="top" aria-label="1.14 Computing with Quantum States > ^dac7b9" data-href="1.14 Computing with Quantum States#^dac7b9" href="school/physics/qis/notes/1.14-computing-with-quantum-states.html#^dac7b9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Clifford gates</a><a data-tooltip-position="top" aria-label="1.14 Computing with Quantum States > ^dac7b9" data-href="1.14 Computing with Quantum States#^dac7b9" href="school/physics/qis/notes/1.14-computing-with-quantum-states.html#^dac7b9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Clifford gates</a>?
Neilson Information Geometry - People who study the geometry of the Unitary group
How it might be related
Theorem 1.15.1 ((Soloway-Kitaev) Arbitrary Unitary Algorithmic Complexity).
Any -qubit unitary can be implemented with an exponential number of gates, within precision using at most Where is some constant less than 3.97, which depends on the gate set.
This also assumes that your gate-set includes inverses! finding that was a discovery in the 90s, but was recently improved upon
What gate set had the lowest value ?
There are things called "Magic" gate sets, which have , and that's the provable limit. For a long time, it was thought that the upper limit on was 3.97, but was recently found to be (Kuperberg '23) <br>Yes, being. the golden ratio! <a href=".?query=tag:goldenRatio" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#goldenRatio">#goldenRatio</a>
<br>Are there inverse free gate-sets which obey <a data-href="#^83c502" href="#^83c502" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^83c502</a><a data-href="#^83c502" href="#^83c502" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.15.1 ((Soloway-Kitaev) Arbitrary Unitary Algorithmic Complexity)</a> ?
We can prove their existence, but the proof is non-constructive
For any unitary , the complexity Theorem 1.15.2 (Most n-qubit unitaries have circuit complexity which is exponential in ). This basically says, that most unitaries in the Unitary group, are inaccessible is the number of gates in your gateset How do you define "most"?
It's beyond the space of the class, but you'd use a probabilistic proof
We can fill this space with little epsilon balls, to denote our resolution of observation. We can't actually parse the difference between each unitaryHow many size-T circuits are there?
It's if you can apply two-qubit operations to any qubits
Otherwise replace with 1 if it's only to neighbors
Most Unitaries are innaccessibleThe ones that are accessible are are easy for a QC = exp(n) are hard for QCThis is interesting, cause I guess it means practically we're just not getting general purpose QC's. Classical computers are discrete in nature, so we can exhaust the gate set and implement it. That's not the case for quantum computer. The gate-set can't be exhausted, only approximated. Both use gates to implement algorithms, but only one in practice, can implement all the algorithms in its space.
This might be more of an equal disadvantage, because this means that some algorithm just exhaust large quantities of time, just like classical
Framework, we use boolean functions .
How do we learn properties of ?
Notes describe this as "global properties" of the function
We do this by querying Definition 1.15.3 (Query Complexity).
The number of queries sent to to learn about a specific property
Ex: In the case of binary search, it takes queries to determine if an element is in a set. A unitary , where is a boolean function,Our inputs are , and the ancilla qubit is where the output of the function gets dumped.
the inputs aren't the same when they leave the channel though (generally). You'd need to have a way to apply an inverse operation to only a component to the system, which would violate some stuff I thinkDefinition 1.15.4 (XOR Oracle). We change a gate based on a condition Every time you use , you add one to your query complexity.Definition 1.15.5 (Phase Oracle).
Anj oracle which takes an input, and returns it's output in the phase of the qubit We're going to prove in a later day, that Phase Oracle's are XOR Oracles.<br>
Rossalier Algorithm for Unitary Synthesis is a tool that tries to beat <a data-href="#^83c502" href="#^83c502" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^83c502</a><a data-href="#^83c502" href="#^83c502" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.15.1 ((Soloway-Kitaev) Arbitrary Unitary Algorithmic Complexity)</a>, it has a terminal interface.THIS ALL IGNORES ERROR, WE ASSUME PERFECT GATES]]></description><link>school/physics/qis/notes/1.15-more-on-universal-gate-sets.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.15 More on Universal Gate Sets.md</guid><pubDate>Thu, 17 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.1 Deutsch-Jozsa and Computing]]></title><description><![CDATA[This class introduced our first quantum algorithm that provided some speedup over classical, the Deutsch-Jozsa problem.Theorem 2.1.1 ((Yao 1993) The quantum circuit model is analogous to the quantum turing machine model).If we don't have any gates which take us out of a classical digital basis
What's the best way to then implement the unitary transformation you care about from <a data-href="1.15 More on Universal Gate Sets#^83c502" href="school/physics/qis/notes/1.15-more-on-universal-gate-sets.html#^83c502" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.15 More on Universal Gate Sets &gt; ^83c502</a><a data-href="1.15 More on Universal Gate Sets#^83c502" href="school/physics/qis/notes/1.15-more-on-universal-gate-sets.html#^83c502" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.15.1 ((Soloway-Kitaev) Arbitrary Unitary Algorithmic Complexity)</a>?
What subset of gates can you implement using only a polynomial number of gates
Definition 1.15.3 (Query Complexity).
The number of queries sent to to learn about a specific property
Ex: In the case of binary search, it takes queries to determine if an element is in a set. This is much easier to quantify than the number of possible gates required to set it up
It takes approx gatesAre there different universal gate sets which can reach different groups of circuits in a lower time complexity?
All the circuits in one universal gate set, can be emulated in an alternative set in finite time if both are universal. This is also the same for digital computers, the emulator argument
He's mentioning the superposition principle, so the basic operations in nature from which you can engineer complexity, are locally.Assume some magical oracle, which
In homework 7, we prove that<br>
<a data-href="1.15 More on Universal Gate Sets#^0d375f" href="school/physics/qis/notes/1.15-more-on-universal-gate-sets.html#^0d375f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.15 More on Universal Gate Sets &gt; ^0d375f</a><a data-href="1.15 More on Universal Gate Sets#^0d375f" href="school/physics/qis/notes/1.15-more-on-universal-gate-sets.html#^0d375f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.15.5 (Phase Oracle)</a> and <a data-href="1.15 More on Universal Gate Sets#^47218c" href="school/physics/qis/notes/1.15-more-on-universal-gate-sets.html#^47218c" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.15 More on Universal Gate Sets &gt; ^47218c</a><a data-href="1.15 More on Universal Gate Sets#^47218c" href="school/physics/qis/notes/1.15-more-on-universal-gate-sets.html#^47218c" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.15.4 (XOR Oracle)</a> are the same.Why is this a good model for querying ? this is important in classical reversible computing (Which had interest in the 1980s), and more generally in QC's.The Toffoli gate can simulate the AND and OR logic gates.OHH this is so that we can hide the result of the oracle. By dropping the qubit into the ancilla, then we can just run the dagger for.
But why is it even important? Well turns out cleanup is part of the key speedup of a quantum computer.
Basically, we end up losing information because of the garbage produced that's left behind, because it becomes entangled with your result.Definition 2.1.2 (Deutsch-Jozsa Algorithm (1985 1991)).
Given some function The function can be the identity function, the NOT function, the constant 1 function, or the constant zero function
Task:
Compute Essentially, you want to know if the function of constant or balanced. How many accesses to do we need.
Classically, the query complexity of the Deutsch-Jozsa task is .
The quantum query complexity, is . The reason why, is that we use superposition to query the both possible states.Definition 2.1.3 (Generalized Deutsch-Jozsa). Goal We can use the regular Deutsch-Jozsa to get the parity of then etc. Then you take all those results, then XOR those results (in a classical) to get your final answer with queries. We're not going to count those extra XOR's, because we didn't need to access again.
Can you do better than ?
Parity has an underlying recursive structure, I could keep applying Deutsch-Jozsa to the new processed bits until I end up finishing? The issue, is uncomputing! Your factor of 2 speedup, is balanced out by the need to uncompute the garbage at each layer. This just gives us query complexity again.
Theorem 2.1.4 (Any quantum algorithm for computing the parity of -bits requires queries).How can we understand this in terms of interference? The two contributions to the wrong answer cancel out, but the real contributions add together. Essentially, the different contributions to the right answer point the same way, while the wrong answer contributions are made to flip.Between this and then, another generalization occurred, Then we promise a property about Promise: is either constant (all one number) or balanced (equal number)
Problem: To decide which
Classically, you'd need at worst. But in reality, if you had a probabilistic alg, you could pick at random till you see one of the balanced outputs]]></description><link>school/physics/qis/notes/2.1-deutsch-jozsa-and-computing.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.1 Deutsch-Jozsa and Computing.md</guid><pubDate>Thu, 24 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.2 Bernstein-Vazirani]]></title><description><![CDATA[This class introduced an algorithm to find the XOR mask which defines a one-to-one function.Today we want to cover an actually impressive quantum algorithmDefinition 2.2.1 (Bernstain Vazerani).
Given a blackbox Promise: , Problem: Find This is the problem that the algorithm wants to solve. Classical query complexity of Bernstein-Vazerani problem is .
Now want to give a quantum algorithm, which can solve using one query to , using a linear number of gates.
The algorithm is just to apply hadamards to every qubit twioce, once before and once after the function The goal of this problem, is to find the XOR mask Proof of <a data-href="#^778829" href="#^778829" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^778829</a><a data-href="#^778829" href="#^778829" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.2.1 (Bernstain Vazerani)</a>. We're now going to take some bit string and apply this same thingWe get a total normalization and representation asThen the solution just falls into our lap! The amplitude has some fixed phase attached to it, so we just wanna find itIn order□<br>How did we not just violate <a data-href="1.8,1.9 Superdense Coding and QKD#^45ead5" href="school/physics/qis/notes/1.8,1.9-superdense-coding-and-qkd.html#^45ead5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8,1.9 Superdense Coding and QKD &gt; ^45ead5</a><a data-href="1.8,1.9 Superdense Coding and QKD#^45ead5" href="school/physics/qis/notes/1.8,1.9-superdense-coding-and-qkd.html#^45ead5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.8.1 (Holevo's Theorem (1973))</a> ? The thing is ,that we just measured qubits, even if there was only one query. We didn't just get bits on the results for free, we had to measure every output
Bernstein-Vazerani is an vs speedup]]></description><link>school/physics/qis/notes/2.2-bernstein-vazirani.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.2 Bernstein-Vazirani.md</guid><pubDate>Tue, 29 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.3 Simon's Problem and Factoring]]></title><description><![CDATA[The rest of the office hours In Simon's problem, you want to find some XOR mask on the string , which will givethe probability of any arbitrary will satisfy our linear equations is As ling as your number of equations is large compared to length of the string,The unique thing about Simon's problem that with some black box, we learned something about the function's internal structure. If we can do that, we can find periodicity. If we can do that, then we can factor prime numbers.Definition 2.3.1 (AKS Primality Test).
Not going into details here, but this is a deterministic primality testing algorithm, in polynomial time, which doesn't rely on the reinmann hypothesis.
Below is the definition of a multiplicative group mod(n)Definition 2.3.2 (Multiplicative group mod(n)). How many numbers from 1- are relatively prime to N. If you knowThenTheorem 2.3.3 (Prime Number theorem).
The number of primes up to is roughly Simon's Algorithm makes queries, exponential improvementDefinition 2.3.4 (Simon's Problem).
Given : Promised: if . is the period of our function, and values only return on the range twice if it satisfies that condition.
]]></description><link>school/physics/qis/notes/2.3-simon's-problem-and-factoring.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.3 Simon's Problem and Factoring.md</guid><pubDate>Thu, 31 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.4 Introduction Shor's Algorithm]]></title><description><![CDATA[Today we introduced a hero to some, a menace to many: Shor's algorithm. We reduced the problem of factoring to period finding, allowing us to draw parallels to <a data-href="2.3 Simon's Problem and Factoring#^92798f" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html#^92798f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Simon's Problem and Factoring &gt; ^92798f</a><a data-href="2.3 Simon's Problem and Factoring#^92798f" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html#^92798f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.3.4 (Simon's Problem)</a>.Given some number , where are prime numbers, find .
We found out last time, that the order of some mod group formed with is in the form<br>See more from <a data-href="2.3 Simon's Problem and Factoring#^cardinalityOfMod" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html#^cardinalityOfMod" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Simon's Problem and Factoring &gt; ^cardinalityOfMod</a><a data-href="2.3 Simon's Problem and Factoring#^cardinalityOfMod" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html#^cardinalityOfMod" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.5)</a>
To break RSA, we need to make the following operations efficientDefinition 2.4.1 (Euclid's algorithm). If I wanna know the GCD(40,95), I can always perform integer division small to large, and take the remainder.
In this case, it's 15.
Then we know that (Because if a number can divide 40 and 95, of course it can divide the difference).
You just keep going until you hit the bottom Once one number divides the other, the smaller one is the GCD! Above is just an example of recursion! This was written about in Euclid's elements
Breaking RSA is guaranteed to be Factoring. Our whole system is based on factoring being super hard.No one has proven the converse isn't true! It might be possible to break RSA without solving factoring classicallyDefinition 2.4.2 (Period Finding Problem).
Given Promise: is a periodic function. It means Which. is to say, two values of are never going to be equal, unless is a multiple of. the period of Problem: Find (the smallest) This is different from simons problem, because we were promised the period was , butSo we're doing real addition, not bitwise addition.Classical Query Complexity- It's a bit hard to just state the complexity objectively, since the period can be anywhere on the natural numbers.This then means that the query complexity is bounded by s or getting it right instantly.Definition 2.4.3 (Birthday Paradox).
FUTURE AZAL: Define it here
With a randomized algorithm, then we can once again exploit the birthday paradox! We start by guessing that Then we take all possible inputs up to Then query random points in that interval. Then you get to stop the moment that there's a collision.
Then given the collisionWe know from the given promise thats is a factor of the different.
Another thing we can just do is just do this a few different times, and calculate the gcd.
This then means, that our number of queries grows1994
There is a quantum algorithm for period finding that makes only O(1) queries to Circuit Complexity is also small.
This leads to a quantum alg. to factor bit numbers in time Just this year, the time complexity got reduced to power We can also say that Factoring Period-Finding. The two problems are connected. But how?<br>In Shors algorithm, modular exponentiation function is key. <a data-href="2.3 Simon's Problem and Factoring#^ef9fa8" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html#^ef9fa8" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Simon's Problem and Factoring &gt; ^ef9fa8</a><a data-href="2.3 Simon's Problem and Factoring#^ef9fa8" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html#^ef9fa8" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.3.2 (Multiplicative group mod(n))</a>
Note before going into this, not all will work. Its provable you don't have to wait that long.We then want to define a REALLY IMPORTANT FUNCTIONDefinition 2.4.4 (Modular Exponentiation Function). We know that is efficiently computable through repeated squaring.<br> is also periodic because there is a finite possible outputs, with infinite inputs. <a href=".?query=tag:Pigeonhole" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#Pigeonhole">#Pigeonhole</a> principle. This means that we have our period . will always divide the order of the multiplicative group. Lagrange's theorem.
But how do we use the period to get the factors of ?We know that if we found We're taking two leaps of faith is even (for any there's a 50-50 shot so like...) Difference of squares This says that this difference of squares is an integer multiple of . Either, one of the two terms is already an integer multiple of <br>
Second leap of faith: OR they're multiples of the prime factors Now if the factors are just split in this way, I can just calculate the GCD of them both with <a data-href="#^beb0e8" href="#^beb0e8" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^beb0e8</a><a data-href="#^beb0e8" href="#^beb0e8" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.4.1 (Euclid's algorithm)</a> Smallest power of 2 larger than Where is the number I wanna factor. I will make a superposition over all teh integers Just like Simons, Hadamard all the qubitsIn our second register of qubits as an ancilla. Then we apply our To implement , we would build this out of a Toffoli gate.
After this, just like in Simon's algorithm, the next step is measuring the input register. We throw that out, but we care about it's effect.]]></description><link>school/physics/qis/notes/2.4-introduction-shor's-algorithm.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.4 Introduction Shor's Algorithm.md</guid><pubDate>Tue, 05 Nov 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.7 What Else can Shor do, and Grover]]></title><description><![CDATA[Would aliens have known about Shor's algorithm?
QM let's us factor numbers, which is sick
Shor's algorithm does something really unique, it can find the period of any black box function.The first public key cryptography systemDefinition 2.7.1 (Diffe-Hellman System). Alice chooses a HUGE random prime number ,and a number from a value . She also sends Bob now sends back How can they generate a secret key?
Alice calculates And Bob calculates This is their shared secret key!
But what about Eve? Well Eve knows neither (Note the use of <a data-href="2.4 Introduction Shor's Algorithm#^9d499f" href="school/physics/qis/notes/2.4-introduction-shor's-algorithm.html#^9d499f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.4 Introduction Shor's Algorithm &gt; ^9d499f</a><a data-href="2.4 Introduction Shor's Algorithm#^9d499f" href="school/physics/qis/notes/2.4-introduction-shor's-algorithm.html#^9d499f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">2.4 Introduction Shor's Algorithm &gt; ^9d499f</a> )
Definition 2.7.2 (Discrete Logarithm).
Given find s.t . Below it's deno Example The best known classical algorithm comes from the number field sieve. The runtime of this algorithm is Any developments in better factoring or cryptography, is often met by improvements to discrete logarithms.Definition 2.7.3 (Elliptic Curve Cryptography (CVV)).
An elliptic curve is the set of solutions to an equation in the form Whenever you have an elliptic curve, you have some special points on it in a group. There's a fancy type of multiplication which takes two points in a group, and takes you to the result also on the curve.
Given , an attacker wants to find those 3 points
The fastest known discrete-log algorithms that we do know, have a complexity of Theorem 2.7.4 (Abelion Groups).
Any set field of numbers where Theorem 2.7.5 (Kitaev 1995).
Shor's algorithm can tell you basically anything about Abilene group
Simon's Algorithm's Abelian group is Shor'sWhy do we even want systems which use Abelion groups?
Constructing our groups so nicely, actually relied on being Abelion
Exercise 2.7.6 (AT HOME: Review this again. I think I'm a bit lost on what Abelion groups are).The OTP is STILL SECURE!🎉🎉🎉 🥳🥳QKD is also still secure, since it doesn't involve any computation.
Private key cryptography also still works. That can be based on any one-way function. One-way functions can exist if pseudo-random-functions exist. Those take a number , and return a number so obfuscated no method can efficiently tell it wasn't randomIt would be a hilarious result if quantum computers break all our existing cryptography, just to produce a system to fix it. Spread the disease and sell the cure.Definition 2.7.7 (Resistant Cryptography).
A whole field defined on post-quantum public key crypto systems.
At UT, Brent Waters is the leading expert
The most promising forms of this are systems involving lattices, and LWE (learning with errors)Definition 2.7.8 (Lattice (Math)).
FUTURE AZAL: Make this much better Definition 2.7.9 (Lattice Based Cryptography). The idea, is that the public key is a "Bad basis", which can still help you generating those selected points. Just in the last year, there was a paper which came very close to breaking lattice-based-cryptography. After the first week it was retracted over a bug.If you can generalize Shor's algorithm from Abelian groups to non-abelian groups, then you can break lattice based cryptography.If you can generalize Shor's algorithm to the dihedral group, then you can break lattice-based crypto. If you can generalize it it to all possible groups, then it can solve the graph isomorphism problem all in polynomial time.Definition 2.7.10 (Graph Isomorphism problem).
Given two graphs, is there a way of rearranging the vertices and renaming, in such a way to prove the graphs are isomorphic
I never worked on this. It just looked like Vietnam, more and more troops sent in to no avail. A common misinterpretation of Shor's algorithm, is that it just tests every superposition. Then whichever one has the answer just like, calls out?
This isn't how Shor works, but it is how Grover's does!Definition 2.7.11 (Search Problem).
Given a function Decision Version: Is there an s.t Search Version (Promised at least 1 s.t ) : Find is called a marked item
A simple description, is I guarantee that there is treasure in one of boxes, finding which box there's treasure in. If I solved the Search Version, I can solve decision by just knowing. The algorithm will just never find an entry so we know the decision version.If I can efficiently solve the decision version, how can I use that to solve the search. Well just use binary search! Split boxes in half, ask if there's an item in first or second half. Keep shrinking divisions.Classical Algorithms
Deterministic algorithms: Upper bound of complexity as . You just search every box
Randomized Algorithm: Doesn't really improve things, with search <br>Theorem 2.7.12 (Grover's Algorithm (1996)).
There is an query quantum algorithm for <a data-href="#^186cf5" href="#^186cf5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^186cf5</a><a data-href="#^186cf5" href="#^186cf5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.7.11 (Search Problem)</a>. The space complexity is <br>This is why quantum computers have a guaranteed speedup! SAT solvers are just search problems. <a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Satisfiability Problem</a><a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Satisfiability Problem</a>
Wait that's true right ^?
yep. Literally just tack it on there and you speed up by Optimistically, with quantum error correctionShor's algorithm has this problem too, but QC's still win with much lower values of <br><img alt="../../../../../Supplemental Files/images/Pasted image 20241114150353.png" src="supplemental-files/images/pasted-image-20241114150353.png" target="_self">Assume: is a power of 2
Assume there's a unique marked item After your first query, 's amplitude becomes flipped! Grover then designed the Grover Diffusion Operator , "Inversion about the Average"Definition 2.7.13 (Grover Diffusion Operator).
The Grover diffusion operator is designed to take our qubits, and invert them about the average. Let's say that we had some amplitude on one component and we wanted to map it toIn a matrix, this is represented byWitThen, we just apply our again, which flips, then our diffusion operator . We repeat that times]]></description><link>school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.7 What Else can Shor do, and Grover.md</guid><pubDate>Thu, 14 Nov 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.9 Applications of Grover's Algorithm]]></title><description><![CDATA[Today we basically learned about every single useful aspect of Grover's algorithm, and associated theorems in the history of quantum search. Work for combinatorial search problems like the <a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Satisfiability Problem</a><a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Satisfiability Problem</a> Our complexity goes from .<br>
Because of the <a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" data-href="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" href="school/miscillaneous/tidbit-facts/cook-levin-theorem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Cook-Levin Theorem</a><a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" data-href="../../../../Miscillaneous/Tidbit Facts/Cook-Levin Theorem" href="school/miscillaneous/tidbit-facts/cook-levin-theorem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Cook-Levin Theorem</a>, you can tack grover on anything to get a speedup Searching a physical database x
Classically we'd just do1for i to n:2	if a[i]==1:3 return i4	nextBut if we want to do this quantumly, we'd need some kind of qRAM which allowsWhere we can also modify our qRAM on a classical computer.
If we were to put a bunch of microcontrollers at each index, which could tell when accessed and return a quantum state, then the search is trivial. At that point you can search in They don't know I run quantum MinecraftIs it possible to search in ?Theorem 2.9.1 (Bennet, Bernstein, Brassord, Vazirani (1994) - BBBV). For the problem of black box searching for an unordered list of elements, Grover's algorithm is optimal. queries needed<br>
<a data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 What Else can Shor do, and Grover &gt; ^f2faf4</a><a data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.7.12 (Grover's Algorithm (1996))</a> They showed this before Grover's algorithm was even created.
BBBV were suspicious of a failure in their proof, that their lower bound was instead of being the same as . Then Grover came along and proved that there was an algorithm for it.<br>
The proof is in the <a data-tooltip-position="top" aria-label="../Class Files/qclec.pdf" data-href="../Class Files/qclec.pdf" href="school/physics/qis/class-files/qclec.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">lecture notes</a><a data-tooltip-position="top" aria-label="../Class Files/qclec.pdf" data-href="../Class Files/qclec.pdf" href="school/physics/qis/class-files/qclec.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">lecture notes</a> on page 189.<br>Theorem 2.9.2 (Abrams-Lloyd 1998).
If QM had a non-linear term, then <a data-tooltip-position="top" aria-label="^c61d35" data-href="#^c61d35" href="#^c61d35" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">BBBV</a><a data-tooltip-position="top" aria-label="^c61d35" data-href="#^c61d35" href="#^c61d35" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">BBBV</a> is false. Then you could beat <a data-tooltip-position="top" aria-label="2.7 What Else can Shor do, and Grover > ^f2faf4" data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">grover's algorithm</a><a data-tooltip-position="top" aria-label="2.7 What Else can Shor do, and Grover > ^f2faf4" data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">grover's algorithm</a> Classical Query Complexity How about quantum?
We can just run Grover on each row! Another way to get to is if we say that we do have some classical algorithm which checks a singular row, and we apply it to the superposition of rows. Within each Grover iteration, we have to make queries. We apply grover to this, times Instead of the classical algorithm checker, we can replace it with another Grover's algorithm. We have an outer Grover loop, and an inner Grover loop. Our outer Grover runs by , and our outer grover also runs . Therefore, we've reduced our search time to !
The inner loop runs over all the columns, and searches for a zero. Then the outer loop runs over all those results, looking for a 1.
With the above, you need to consider the error building in the inner loop, which initially people thoguht would make you have , but later it was proved to just be What about arrays This is really useful for games! You can represent games as decision trees. Let's say you have some range of the board, and you want to know what the path is to your victory. You search the leaf nodes for where you can have success. Then you search for one level before the final move. What positions were there? Then repeat that until you reach the current state.
These are called Games of Alternation. This is how ML models used to work, it's how Deep Blue beat the best chess player in the world.What if we try Grover-ing this? Well we'd get a crap load of error propagation, so we have to keep amplifying. It doesn't take long in that proves that the Grover speedup vanishes.
(Additionally, we assume that there exists some oracle which can tell us if the board has been won)
The calculation of showing the error, is that to be sufficient for our probability amplitudes, we know that we need runs. Additionally, we need to uncompute, so multiply by 2. That gives us . , so these factors build up and keep making the runtime bigger.
Because of this, it was conjectured that there was no speedup with Grover.Theorem 2.9.3 (Forhi,Goldstone, Gutmonn (2007):). some algorithm which always runs any decision tree , where is the number of leaves at the end of the node<br>
<a data-tooltip-position="top" aria-label="https://arxiv.org/abs/quant-ph/0702144" rel="noopener nofollow" class="external-link is-unresolved" href="https://arxiv.org/abs/quant-ph/0702144" target="_self">Source</a> Their algorithm was contingent on their experience as particle physicists.
Because of this, Chess might actually be totally solvable. Shannon conjectured that there were chess positions, which means a quantum computer only needs to have iterations. One of those sizes is substantially bigger than the other. We routinely search spaces of that later order of magnitude classically.
Theorem 2.9.4 (Ambainis (1999)).
The quantum query complexity really is Definition 2.9.5 (The Collision Problem).
Given (N is even)
Promise: is either -to- or -to-
Variant: I tell you is -to-1, find a collision pair I.e ,s.t This is closely related to the Birthday Paradox <br>Also related to <a data-href="2.3 Simon's Problem and Factoring" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Simon's Problem and Factoring</a><a data-href="2.3 Simon's Problem and Factoring" href="school/physics/qis/notes/2.3-simon's-problem-and-factoring.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">2.3 Simon's Problem and Factoring</a>
a 2-to-1 function means every output has exactly two inputs
The Classical Query Complexity:
Randomized: Birthday Paradox means Quantum Query Complexity:
At most cause it has to match classical, but also you can just use Grover's algorithm on a specific case.
Can you run any classical algorithms in on a quantum computer?
This is to say, can you always reliably say that any theoretical quantum algorithm is upper-bounded by the classical complexity?
We can see that with just one query through our problem, we can get a superposition of answers. But we just have no way of knowing that it's a superposition, nor what it's elements are. Where That being said, at least our lower bound is Theorem 2.9.6 (Brassord-Hoyer-Tapp (1997)). There is an efficient way to solve this problem in ]]></description><link>school/physics/qis/notes/2.9-applications-of-grover's-algorithm.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.9 Applications of Grover's Algorithm.md</guid><pubDate>Thu, 21 Nov 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[0.1 Class Overview]]></title><description><![CDATA[Definition (Lake Wobegone Principle ).
A town where everyone is above average is impossible. Someone must be below average to set it.
"“The human tendency to overestimate one's achievements and capabilities in relation to others."
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://udayton.edu/blogs/erma/2022/06/lakewobegon.php" target="_self">https://udayton.edu/blogs/erma/2022/06/lakewobegon.php</a>
Definition (Tsirelson's Inequality (1980)).
With any quantum strategy employed for the <a data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality#^0f5bbd" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html#^0f5bbd" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Hidden Variables and Bell's Inequality &gt; ^0f5bbd</a><a data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality#^0f5bbd" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html#^0f5bbd" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 5 (CHSH Game)</a> , their probability of winning the CHSH game is at most Definition (No Communication Theorem).
Given that Bob and Alice share an arbitrary entangled pair, no choice of Alice's measurement can affect , given .
Definition (Von Neuman Entropy).
A measure of how much uncertainty there is in regarding which pure state that we have. It also can be used as a measure of entanglement between two particles.<br>
$$
Definition (LOCC).
Local Operations, Classical Communication
Definition (NP-Hard).
Any problem which is at least as hard, as the <a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Satisfiability Problem</a><a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Satisfiability Problem</a> with a polynomial addition.
Definition (Measurement Problem).
How can you have both Unitary transformations, which are time-reversible, and measurement, in the same universe?
$$
Definition (Copenhagen Interpretation of Quantum Mechanics).
There is this micro-world which obeys unitary evolution, but we live in the macro-world with probabilistic experiences. Measurement is the macro-world reaching in and interrogating the micro-world.
There is some boundary between the macro, and the micro
Definition (Wigner's Friend Thought experiment.).
Imagine yourself in a thought experiment as a superposition between two thoughts
$$
Definition (Exact Universality).
A gate set has exact universality, when any unitary on a qubit of size , can be produced by tensoring gates in the set together.
$$
Definition ((Approximate) Universal Gate Set). A finite gate set is approximately universal if for any , there exists such that
$$
Definition (Clifford + T Gate set).
$$
Definition (Clifford Gates and Clifford Group).
The set of all unitaries generated by All possible combinations of elements in the set, form the Clifford Group.
This is NOT universal.
Definition (Encoded Universal).
Any given gate set , s.t you can simulate an arbitrary qubit computation, with ancillas
Definition (Query Complexity).
The number of queries sent to to learn about a specific property
Ex: In the case of binary search, it takes queries to determine if an element is in a set.
Definition (XOR Oracle).
| Uancilla qubit |
Definition (Phase Oracle).
Anj oracle which takes an input, and returns it's output in the phase of the qubit
$$
Definition (Wiesner's Quantum Money).
Each bill has a standard serial number which is any number of bits.<br>
The bank has a secret mapping from these public serials to bits. The states then encode the hidden strings .
Definition (Superdense Coding (Bennett-Wiesner)).
Suppose Alice and Bob share an entangled <a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation > ^9fbf0d" data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">bell state</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation > ^9fbf0d" data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation#^9fbf0d" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html#^9fbf0d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">bell state</a> ,
$$
Definition (Deutsch-Jozsa Algorithm (1985 1991)).
Given some function $$
Definition (Generalized Deutsch-Jozsa ). Goal We can use the regular Deutsch-Jozsa to get the parity of then etc. Then you take all those results, then XOR those results (in a classical) to get your final answer with queries. We're not going to count those extra XOR's, because we didn't need to access again.
Definition ( Ladner's theorem).
If , then there are problems which exist that aren't in either
Definition (PSPACE).
A complexity class, which contains the set of all algorithms that run with a polynomial amount of memory
Definition (Hamming Cube).
Below is the example for a 3 bit repetition code. You can prove that with only 1 error, if your start points are , then the verticies that are one unit away, are disjointed
| 2.10 2024-12-03 15.02.52.excalidraw
⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠ You can decompress Drawing data with the command palette: 'Decompress current Excalidraw file'. For more info check in plugin settings under 'Saving' |
Definition (Bernstain Vazerani).
Given a blackbox $$
Definition (AKS Primality Test).
Not going into details here, but this is a deterministic primality testing algorithm, in polynomial time, which doesn't rely on the reinmann hypothesis.
Definition (Multiplicative group mod(n)).
$$
Definition (Simon's Problem).
Given : Promised: if . is the period of our function, and values only return on the range twice if it satisfies that condition.
Definition (Period Finding Problem).
Given
$$
Definition (Birthday Paradox).
FUTURE AZAL: Define it here
Definition (Modular Exponentiation Function).
$$
Definition (Diffe-Hellman System).Definition (Discrete Logarithm).
Given find s.t . Below it's deno
$$
Definition ( Elliptic Curve Cryptography (CVV)).
An elliptic curve is the set of solutions to an equation in the form
$$
Definition (Resistant Cryptography).
A whole field defined on post-quantum public key crypto systems.
At UT, Brent Waters is the leading expert
Definition (Lattice (Math)).
FUTURE AZAL: Make this much better
$$
Definition (Lattice Based Cryptography).Definition (Graph Isomorphism problem).
Given two graphs, is there a way of rearranging the vertices and renaming, in such a way to prove the graphs are isomorphic
Definition (Search Problem).
Given a function Decision Version: Is there an s.t Search Version (Promised at least 1 s.t ) : Find is called a marked item
A simple description, is I guarantee that there is treasure in one of boxes, finding which box there's treasure in.
Definition (Grover Diffusion Operator).
The Grover diffusion operator is designed to take our qubits, and invert them about the average.
$$
Definition (The Collision Problem).
Given (N is even)
Promise: is either -to- or -to-
Variant: I tell you is -to-1, find a collision pair I.e ,s.t This is closely related to the Birthday Paradox
<br>Theorem (Density Matrix for an Entangled State and Partial States).
Given any arbitrary entangled state defined below, you can find Bob's density matrix through
$$
Theorem (The Standard Gate Set is Universal).
The gate set defined as . Note that must be continuous, so since the cardinalities of the set must match, the set must also be continuous. Theorem ((Gottosen, Knill) Simulating Clifford Gates is in ).
Any quantum circuit made from <a data-href="#^dac7b9" href="#^dac7b9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dac7b9</a><a data-href="#^dac7b9" href="#^dac7b9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^dac7b9</a> , is classically simulatable in Theorem ((Soloway-Kitaev) Arbitrary Unitary Algorithmic Complexity).
Any -qubit unitary can be implemented with an exponential number of gates, within precision using at most Where is some constant less than 3.97, which depends on the gate set.
This also assumes that your gate-set includes inverses!
Theorem (Most n-qubit unitaries have circuit complexity which is exponential in ).
$$
Theorem (No Cloning Theorem).
Given a qubit , there is no operator which will produce two copies of the state.
$$
Theorem (Holevo's Theorem (1973)).
By sending Bob qubits, Alice can communicate classical bits of her choice*
for if Alice and Bob have pre-shared entanglement
If Alice and Bob have some preshared qubits in advance, they can actually send information over by a factor of two.
Theorem ((Yao 1993) The quantum circuit model is analogous to the quantum turing machine model).Theorem (Any quantum algorithm for computing the parity of -bits requires queries).Theorem (Valiant-Vazerani Theorem).
If you can guarantee that a given boolean function has at least one satisfying answer, then there exists some randomized solving algorithm for it. At the same time, it's still computationally hard regardless
Theorem (Shor 1995).
It is sufficient to detect bit-flips and phase flips (Pauli ). If we can, then everything else is handled
Theorem (Von Neumann (1950): You can build an arbitrary reliable circuit from unreliable AND,OR,NOT gates as long as:). the failure probabilities are independent
Below some constant failure probability Theorem (Threshold Theorem Aharanov &amp; Ben-Or 1996 , Zurek,...). s.t can do an arbitrary reliable quantum computation, even if at every qubit, at every time needed to apply one gate (time-step), suffers from independent noise . Assume you can perform measurements in the middle of the computation and react to them We can perform extremely fast, errorless classical computation This in particular is a bit of a challenge! The quantum-errors happen in nanoseconds We have plenty of fresh qubits that we can utilize. Used in the event that we need to throw something out We can perform parallel operations Meaning I can perform gates on all the qubits at the same time. This is needed because we're assuming errors can happen everywhere in parallel What all of this mean thermodynamically, is that our quantum-computer is now an open system which generates heat. "If nature was a demon, and went HMM I wanna pick 1% of errors to screw with, that kills this" No one knows how to do QC fault tolerance in the face of correlated noise Theorem (Prime Number theorem).
The number of primes up to is roughly $$
Theorem (Abelion Groups).
Any set field of numbers where<br>
$$
Theorem (Kitaev 1995).
Shor's algorithm can tell you basically anything about Abilene group
Theorem (Grover's Algorithm (1996)).
There is an query quantum algorithm for <a data-href="#^186cf5" href="#^186cf5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^186cf5</a><a data-href="#^186cf5" href="#^186cf5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^186cf5</a>. The space complexity is Theorem (Bennet, Bernstein, Brassord, Vazirani (1994) - BBBV). For the problem of black box searching for an unordered list of elements, Grover's algorithm is optimal. queries needed<br>
<a data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 What Else can Shor do, and Grover &gt; ^f2faf4</a><a data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 2.7.12 (Grover's Algorithm (1996))</a>
Theorem (Abrams-Lloyd 1998).
If QM had a non-linear term, then <a data-tooltip-position="top" aria-label="^c61d35" data-href="#^c61d35" href="#^c61d35" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">BBBV</a><a data-tooltip-position="top" aria-label="^c61d35" data-href="#^c61d35" href="#^c61d35" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">BBBV</a> is false. Then you could beat <a data-tooltip-position="top" aria-label="2.7 What Else can Shor do, and Grover > ^f2faf4" data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">grover's algorithm</a><a data-tooltip-position="top" aria-label="2.7 What Else can Shor do, and Grover > ^f2faf4" data-href="2.7 What Else can Shor do, and Grover#^f2faf4" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^f2faf4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">grover's algorithm</a>
Theorem (Forhi,Goldstone, Gutmonn (2007):). some algorithm which always runs any decision tree , where is the number of leaves at the end of the node<br>
<a data-tooltip-position="top" aria-label="https://arxiv.org/abs/quant-ph/0702144" rel="noopener nofollow" class="external-link is-unresolved" href="https://arxiv.org/abs/quant-ph/0702144" target="_self">Source</a>
Theorem (Ambainis (1999)).
The quantum query complexity really is Theorem (Brassord-Hoyer-Tapp (1997)). There is an efficient way to solve this problem in | Grover |
Exercise (AT HOME: Try and prove this, or at least read the proof).Exercise (AT HOME: Prove this is the subpace).
The easiest trick is to show some linear combinations give you the pure extraction of the components. Then you can show linearly combining those is mixing and matching your error
Exercise (AT HOME: Review this again. I think I'm a bit lost on what Abelion groups are).Does Alice need to know what was in ?
NO! that's the utility here. Given , if Alice knew then she can just purely use the classical channel to arbitrary precision. This is useful when Alice doesn't know
Why must the below inequalities be true? $$ If I have a teleportation protocol implemented, and I have a qubit. Alice has a time evolving unitary which rotates the qubit along the plane, Bob starts with a time evolving unitary rotating it in the plane. Alice prepares and sends the qubit information to Bob, while they both have their initial unitaries. At the moment of sending, Alice uses a classical channel to tell bob to switch his Unitary. Bob starts using for his Unitary rotation when the qubit teleports, but before he receives Alice's measurement data and applies it. Which unitary has the influence on the final state? Can't we say that the identity of the qubit, is with whomsoever has an acting Unitary? Like we can send multiple qubits at known states , and perform QST at Bob. Depending on the state, we know which unitary applied more to the state, and how long they applied for. But if they split off into two, what happens to ?
Where did these specific probabilities come from?<br>
$$
What happens to conservation rules if the unvierse duplicates each time
Well the expectation value of energy is preserved, you just have to weight the energy of one world, by the probabilities in the amplitude
How do we know it's possible to build n-qubit unitaries out of lower qubit gates?
What a great segway azal 💀, that's next!
What is the that defines this?What allows <a data-href="#^toffoliGates" href="#^toffoliGates" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^toffoliGates</a><a data-href="#^toffoliGates" href="#^toffoliGates" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^toffoliGates</a> to be universal, while <a data-href="#^dac7b9" href="#^dac7b9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^dac7b9</a><a data-href="#^dac7b9" href="#^dac7b9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^dac7b9</a> isn't? The only difference is that you can control on an additional bit?
It's not uniquely obvious in the math, esp with the computational basis. It's one of those things you'll need to grind math out for.
What gate set had the lowest value ?
There are things called "Magic" gate sets, which have , and that's the provable limit.
Are there inverse free gate-sets which obey <a data-href="#^83c502" href="#^83c502" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^83c502</a><a data-href="#^83c502" href="#^83c502" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^83c502</a> ?
We can prove their existence, but the proof is non-constructive
How do you define "most"?
It's beyond the space of the class, but you'd use a probabilistic proof
Why is this only using one qubit? Don't you need several runs to get a confidence interval?
The idea is that is the number where the tail ends of the normal distributions are far enough apart, that one measurement has the confidence baked in.
How can alice and bob have private communication without having to already agree on a OTP in advance?
This was the question conceived when BB84 was made
Are there different universal gate sets which can reach different groups of circuits in a lower time complexity?
All the circuits in one universal gate set, can be emulated in an alternative set in finite time if both are universal. This is also the same for digital computers, the emulator argument
Can you do better than ?
Parity has an underlying recursive structure, I could keep applying Deutsch-Jozsa to the new processed bits until I end up finishing? The issue, is uncomputing! Your factor of 2 speedup, is balanced out by the need to uncompute the garbage at each layer. This just gives us query complexity again.
Do we also have ? Yep, but Are we talking about query complexity in ?
We are. You can throw Grover at an NP complete problem to help constrain your search space, then run through your existing classical algorithm
Why do I need to do a literal measurement over a CNOT? (I did ask this in FRI, but I think there wasn't good time to get into it)<br>
In the real world, all the extra syndrome qubits are also evolving their own error. By keeping everything How would I then CNOT a logical qubit? Do I just put the node on the original physical qubit?What does need to be for error correction to kick inHow would I go about doing a non-local operation if you can only work with neighbors?
You'd have to use CSWAP on each qubit along the road Well then how do you get parallelism if every qubit needs to be subsequently teleported
With a lot of difficulty and layers Do they not need to worry about error correctipn then?
Their measurements then entangle two photons, but doing their measurements then induce errors.
How did we not just violate <a data-href="1.8,1.9 Superdense Coding and QKD#^45ead5" href="school/physics/qis/notes/1.8,1.9-superdense-coding-and-qkd.html#^45ead5" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.8,1.9 Superdense Coding and QKD &gt; ^45ead5</a><a data-href="1.8,1.9 Superdense Coding and QKD#^45ead5" href="school/physics/qis/notes/1.8,1.9-superdense-coding-and-qkd.html#^45ead5" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.8.1 (Holevo's Theorem (1973))</a> ? The thing is ,that we just measured qubits, even if there was only one query. We didn't just get bits on the results for free, we had to measure every output
Smallest power of 2 larger than Where is the number I wanna factor. I will make a superposition over all teh integers
$$
In the way that when Hadamard acts on a two-state system, it takes us to the maximally mixed state, does for a state system also take us to the maximally mixed state?
Yep! In a lot of ways it makes more sense to think of our current Hadamard as the special 2-state case.
What happens with odd powers of ? What if the number isn't a exponential of 2?
It's way more complicated, so we're focussing on the silly small case From Soloway-Kitaev, wouldn't the Fourier transform to be of a more complex space complexity? We don't have arbitrary control phase gates rightWhat is , ? is a root of unity where . is some possible measurement result on the output register
Would aliens have known about Shor's algorithm?
QM let's us factor numbers, which is sick
Why do we even want systems which use Abelion groups?
Constructing our groups so nicely, actually relied on being Abelion
Wait that's true right ^?
yep. Literally just tack it on there and you speed up by How does inverting about the average for every element of a set , change ?Well there's no value which will get us to that entire peak, is never rational. We can implement fractional implementations of Grover's algorithm
What if I don't know the value of ?Why doesn't this extra query complexity add a log slowdown?
The claim is that this only modifies our initial algorithm by a constant
How do we pick the best exponential backoff?
It's a coming homework problem...
Is it possible to search in ?What about arrays Can you run any classical algorithms in on a quantum computer?
This is to say, can you always reliably say that any theoretical quantum algorithm is upper-bounded by the classical complexity?
<br>Strongest response that Everettians have to the wave-function branching, is that "Well we can't explain the Born Rule, but you can't either""Scott's travelling this week, sort of saving the world from AI, so I'm taking over"
- Nick Hunter Jones
"This is because the rationals are dense in the reals, you can approximate any rational number"
- <a data-tooltip-position="top" aria-label="../../../../../Personal/People/Aravind Karthigeyan" data-href="../../../../../Personal/People/Aravind Karthigeyan" href="personal/people/aravind-karthigeyan.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Aravind</a><a data-tooltip-position="top" aria-label="../../../../../Personal/People/Aravind Karthigeyan" data-href="../../../../../Personal/People/Aravind Karthigeyan" href="personal/people/aravind-karthigeyan.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Aravind</a>
Quote
A man calls 911 and says "Help! I think my friend is dead!"
The operator says "Okay, first make sure he's really dead."
BANG
The man gets back on the phone and says "Okay, now what?"
A big question is "How can we implement a quantum computer which implements the identity operator"I'm getting a journalist calling me everyday and I'm like "yeah it's good!"Whatever happens now, to the world, what I can say is that factoring will still have a polynomial time quantum algorithm Aaronson I never worked on this. It just looked like Vietnam, more and more troops sent in to no avail.Aaronson's idea for his future Sci-Fi book
The climax: The good guys are holed up in the fortress, surrounded by the enemy. The fate of the world depends on if they can break a crypto code in time (symmetric key). Best they can do is attack with grover. Grover hasn't run through enough iterations yet, and they're running out of time. Either they measure now and risk everything, or they wait another minute for it to finish.
Strongest response that Everettians have to the wave-function branching, is that "Well we can't explain the Born Rule, but you can't either"I never worked on this. It just looked like Vietnam, more and more troops sent in to no avail.“This isn’t useful, but it’s kind of interesting in that, well it proves a point😁”
-Aaronson
]]></description><link>school/physics/qis/notes/0.1-class-overview.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/0.1 Class Overview.md</guid><pubDate>Mon, 09 Dec 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.3 Quantum Gates and Circuits,]]></title><description><![CDATA[First recitation is Friday GDC 4.302, second is Monday 4-5 GDC 4.304
HW 1 is all about basic rules of quantum states, how to manipulate them, etc.
<img alt="../../../../../Supplemental Files/images/Bloch Sphere.png" src="supplemental-files/images/bloch-sphere.png" target="_self">
The definition of a unitary is any operator such thatIt preserves norm.
To check if an arbitrary matrix is a UnitaryProofFor to be a unitary, it has to be invertible
The only way that expected value is preserved, is ifThe evolution of any quantum system, is time reversible
For a matrix to be stochastic, each column needs to add to one, and the whole thing needs to be non-negative.
The set of unitaries forms a group.
All operators have to be square because they have to have an inverse.
Unitaries are any matricies that preserves inner products. They basicThe hamiltonian is the evolution of the Unitary operator over time.Definition 1.3.1 (Stochastic Matrix).
A matrix where all entries are non-negative, where each column sums to 1
Definition 1.3.2 (Permutation Matrix).
Any matrix obtained by rearranging the rows of an identity matrix. Each row and column only has one non-zero element, which must be 1
Ex: ]]></description><link>school/physics/qis/notes/1.3-quantum-gates-and-circuits,.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.3 Quantum Gates and Circuits,.md</guid><pubDate>Thu, 05 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.4 Quantum Gates, Elitzur-Vaidman Bomb]]></title><description><![CDATA[
We don't want to write giant unwieldily matrices, so keeping things factored to the tensor product is a good idea
Quantum Circuits are just a visual notation for expressing a large unitary transformation
We're just talking about how to go about writing quantum states to a diagramHow do we get from Dirac notation, all the way up to wave-particle duality? So far this just feels like a funky particleDefinition 1.4.1 (Matrix representation of the Pauli Matricies).
The below representation are in the diagonalized basis There's also the CC-Not, the Toffoli gate (Page 31 in the textbook). This is an 8x8 matrix, which behaves just like an AND gate using the two input bits.Note that this is different than , because unitaries MUST be reversible. That means you can't just destroy information (unless you measure).Exercise 1.4.1 (Assume you have the state ).
What happens if you measure both states at the same time? But now what happens when you measure them one after the other? We're going to measure the first qubit. What the new state of the second qubit is, then affects what the output of the first qubit is. What happens if I measure the first qubit in a different basis that isn't the digital basis? I think you just rewrite the basis of the first qubit into the new basis, write the possible states after measurement, then use that to determine your results.
That or you just apply the measurement observables to the qubit you're going to measure, then work from there.
I think entanglement finally made sense in my headDefinition 1.4.2 (Watched Pot Effect). Let's say we have a vector , and we have our qubit naturally drifting from the zero to the one state. If we're an experimentalist, we want to know this is happening, so we keep watching the qubit, waiting for it to drift.
Let's say the qubit rotates by radians. Nature applies the below unitary to the qubit continuously The experimenter will never see the qubit rotate! Without the measurements, the qubit would be rotating. That being said, the experimenter measures discretely, which means Squaring from the already low probability, means the probability of the qubit snapping to one is astonishingly small.
If we measure consistently over time and is linear, we make measurements. That means over one rotation, the probability of snapping to 1 becomes Definition 1.4.3 (Zeno's Effect).
Given a qubit now locked at , and I want to somehow convert it to a qubit with no gates. To do that, I can apply measuring in infinite basis with angle. That would slowly rotate the darn thing
"Perhaps an everyday-life analog would be asking a stranger to have coffee with you, then to go dancing, etc.—there’s a higher probability of success than if you just immediately ask them to marry you!" Scott Aaronson ]]></description><link>school/physics/qis/notes/1.4-quantum-gates,-elitzur-vaidman-bomb.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.4 Quantum Gates, Elitzur-Vaidman Bomb.md</guid><pubDate>Tue, 10 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.10 Quantum Teleportation]]></title><description><![CDATA[This lecture covered the concept of "Quantum Teleportation". This is a communication protocol which allows us to move one qubit to another source through a combination of pre-shared entanglement and classical communication. Pre-shared ebits are like paper. Conceived in 1991.
<a class="original-internal-link" data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation.md" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html" target="_self" rel="noopener nofollow" style="display: none;">5.1 Quantum Teleportation</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum Computing/Semester 1/5.1 Quantum Teleportation.md" href="school/physics/quantum-computing/semester-1/5.1-quantum-teleportation.html" target="_self" rel="noopener nofollow">5.1 Quantum Teleportation</a>
The goal is to transmit a qubit to bob, by sending only classical bits. To do this, you need a pre-shared entangled bit.
The basic formula isWith entanglement, Alice and Bob can use a classical channel, to transmit quantum states.
This doesn't violate the "no superluminal communication" rule, because we're still constrained by classical communication. Does Alice need to know what was in ?
NO! that's the utility here. Given , if Alice knew then she can just purely use the classical channel to arbitrary precision. This is useful when Alice doesn't know
Alice takes the measurement of the state and her state, then sends those measurements to Bob.This is our state, now Alice measures her two qubits, which can give her 4 possible outcomes, Look at the quantum state to see what Bob gets.Each outcome has a probability of . Without the classical communication, Bob is in a state of complete ignorance on which one of these measurements he has.
What's so useful about this, is that you can get much higher fidelity measurements on the qubit, since you only need to send down two classical bits.
Where was in-between Bob receiving the quantum state, and getting the classical gate (columns 2 and 3)?Why must the below inequalities be true? If you make them have a better exchange rate, then you can chain them together and teleport like infinite information
We basically snap a line each time, to make a new one at adjacent vertices.
By running this, Bob and Diane are entangled.]]></description><link>school/physics/qis/notes/1.10-quantum-teleportation.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.10 Quantum Teleportation.md</guid><pubDate>Tue, 24 Sep 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.13 Interpretations of Quantum Mechanics and Entanglement]]></title><description><![CDATA[Covering the various interpretations of quantum mechanics, and more on the entropy of multi-qubit statesFor a density matrix, who's state has been acted on by a unitary , you can describe the new density matrix asWhereGiven the most basic density matrix, diagonalization is the most basic operation to do to the matrix.Definition 1.13.1 (Von Neuman Entropy).
A measure of how much uncertainty there is in regarding which pure state that we have. It also can be used as a measure of entanglement between two particles. Part of the utility of the above concept, is it lets you measure the amount of entanglement between two people, given some pure state.Given the above entangled state in the basis
The interest of the entropy of entanglement, is You don't lose generality by doing this, because the phases can be wrapped into the eigenstates
The entropy of Alice's mixed state, equals the entropy of Bob's mixed state. Suppose that Charlie's out at a party, and his qubit left with him.
Can Alice and Bob see that their qubits are entangled without Charlie.
When Charlie is out of the picture, you can assume that measurement has occurred, meaning we can model this with a mixed stateYou can only have any entanglement if you compare outcomes of all 3 players! Otherwise there's no information on what's inside the dots. Definition 1.13.2 (LOCC).
Local Operations, Classical Communication
To increase the entropy of entanglement, at some point a qubit has to pass between Alice and Bob, which means you can only re-entangle Alice and Bob with quantum information or operations.What happens when we have a mixed state between to possible entangled statesTHIS STATE IS NOT ENTANGLED
Theres an equal probability to and , which means that we can only derive information from <a data-href="#^unentangledDensityMatrix" href="#^unentangledDensityMatrix" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^unentangledDensityMatrix</a><a data-href="#^unentangledDensityMatrix" href="#^unentangledDensityMatrix" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.13.6)</a>
A mixed state is unentangled, if it can be written as a mixture of product states.What aboutIs it possible to write this density matrix, as a mixture of product states?
YES!Determining if a mixed state is entangled, is NP-Hard. <br>Definition 1.13.3 (NP-Hard).
Any problem which is at least as hard, as the <a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Satisfiability Problem</a><a data-tooltip-position="top" aria-label="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" data-href="../../../../Miscillaneous/Tidbit Facts/Satisfiability Problem" href="school/miscillaneous/tidbit-facts/satisfiability-problem.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Satisfiability Problem</a> with a polynomial addition. If Alice and Bob both have spaces of size , then the density matrix can only be written in combinations.All forms of physics have their own interpretations drawn from the math, but quantum mechanics has a unique problem: measurement.Definition 1.13.4 (Measurement Problem).
How can you have both Unitary transformations, which are time-reversible, and measurement, in the same universe? How does nature when to suspend the first rule, and apply the second?
Is the problem Physics, or philosophy?
We can get molecules large enough to Carbon-60, to perform the double slit experiment and be in super-position.
The way that people approach solving this problem is through 4 possible interpretations:Comes from the city which QM generally originated from.Definition 1.13.5 (Copenhagen Interpretation of Quantum Mechanics).
There is this micro-world which obeys unitary evolution, but we live in the macro-world with probabilistic experiences. Measurement is the macro-world reaching in and interrogating the micro-world.
There is some boundary between the macro, and the micro
The obvious response, is why should there be a boundary. It's where Schrödinger's cat comes from. Why can't a macroscopic object be in a superposition. They tended to have very sophisticated ways of saying, "Shut up and Calculate" (David Merman)<br>"Shut up and Calculate" without the "Shut up" part. Whole philosophy of <a href=".?query=tag:instrumentalism" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#instrumentalism">#instrumentalism</a>. The underlying idea is that the goal of sciecne, is to predict the outcome of experiments. If you're not happy with that, the problem isn't with QM, but with you.Definition 1.13.6 (Wigner's Friend Thought experiment.).
Imagine yourself in a thought experiment as a superposition between two thoughts Wigner might feel like he's already made a decision, but then a friend comes along and measures in the basis. To , Wigner never made a decision at all. There was no measurement
Then World War 2 happened, and got distracted by like, war, so this became pretty stupid. But then 1950's Hugh Everett, a grad student at Princeton (student of Wheeler), had another ideaThe Unitary Evolution Only picture- "What if we take unitary operations literally?"During a measurement, there must be some physical interaction between a qubit, and a measuring device , and then you . Measurement if you think about it, acts like a CNOT between the qubit and the measuring apparatus. They get entangled. Interaction becomes entanglement.The superposition initially confined to on electron or state, has now spread.
In principle though, everything that has happened is still reversible. You applied a unitary transformation to get down there, then you can undo it.
But practically, you don't have control over all the degrees of freedom involved. You can't exert the dagger operation on every single propagation. You'd need to decrease the entropy of the quantum state.
That's why measurements are irreversible in practice.BUT WHAT ABOUT ME?? I still need to perceive the outcome, or what good is the measurement device?This is where Everett bites a crazy bulletThere is nothing in the Unitary evolution law that says one of the branches. But why don't we perceive the either branch? Well you only exist in the one branch. Once the branches have split off, they keep having a time-evolving unitary kick off and break them out more.<br>But if they split off into two, what happens to ?
Where did these specific probabilities come from? How do you derive the <a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/4.1 Multi Qubit States > ^1f115f" data-href="../../Quantum Computing/Semester 1/4.1 Multi Qubit States#^1f115f" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html#^1f115f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Born Rule</a><a data-tooltip-position="top" aria-label="../../Quantum Computing/Semester 1/4.1 Multi Qubit States > ^1f115f" data-href="../../Quantum Computing/Semester 1/4.1 Multi Qubit States#^1f115f" href="school/physics/quantum-computing/semester-1/4.1-multi-qubit-states.html#^1f115f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Born Rule</a> from the Unitary part of QM??
Your identity splits into two branches, but they don't split evenly. They split weighted to What happens to conservation rules if the unvierse duplicates each time
Well the expectation value of energy is preserved, you just have to weight the energy of one world, by the probabilities in the amplitude
Strongest response that Everettians have to the wave-function branching, is that "Well we can't explain the Born Rule, but you can't either"His original Paper was "Wave Mechanics Without Probability"Agrees with Many worlds, which is that there is one evolving quantum state throughout the whole universe. There is nothing so primitive as measurement, but then it adds a hidden variable.
Definition (Bohmian Mechanics).
Essentially a particle in superposition has some "real" location, which is simply guided by the behavior of the superposition. For this to work, we need a rule on how the "guiding" works. The rule must have the property that if anyone does measure the particle, they'll see what QM predicted for it. This theory is a Nonlocal Hidden Variable Theory <br>
<a data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality#^23fe58" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html#^23fe58" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum Computing/Hidden Variables and Bell's Inequality &gt; ^23fe58</a><a data-href="../../Quantum Computing/Hidden Variables and Bell's Inequality#^23fe58" href="school/physics/quantum-computing/hidden-variables-and-bell's-inequality.html#^23fe58" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2 (Bohmian Mechanics)</a>
Then what Bohm did, is that you can come up with a diffeq, with how particles can move that always shows that our quantum-mechanics is true. It evolves by unitary evolution and all, but there's also the actual positions of all the particles, which is where our one and only world comes from.<br>This means there's two wave-functions. One which is hyper-non-local. I do something here and it changes how someone else measures something in the Andromeda Galaxy. And the other hyper-local, through <a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation &gt; ^ba33b7</a><a data-href="../../Quantum 1/Notes/1.6 Working with the Schrödinger Equation#^ba33b7" href="school/physics/quantum-1/notes/1.6-working-with-the-schrödinger-equation.html#^ba33b7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.6.2 (Schrödinger Equation)</a> See Page 98 of Aaronson's Lecture Notes.None of These Interpretations is good, QM is wrong
There must be something yet to be discovered, so that the wave-function undergoes an actual physical collapse. A pure state evolves to a mixed state. Nature can't stably keep a cat alive and dead.
This is one of the only views that makes a physical prediction. We can keep scaling up, and at some point either QM breaks, or is right.]]></description><link>school/physics/qis/notes/1.13-interpretations-of-quantum-mechanics-and-entanglement.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/1.13 Interpretations of Quantum Mechanics and Entanglement.md</guid><pubDate>Thu, 10 Oct 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.5 Fast Fourier Transform and QFT]]></title><description><![CDATA[We're doing more work to build up to Shor's algorithm, this time through assistance from the man himself.Whatever happens now, to the world, what I can say is that factoring will still have a polynomial time quantum algorithm Aaronson Continuing from last time, recall
Definition 2.4.4 (Modular Exponentiation Function). Why is it important that we uncompute the garbage?
Our first goal with Shor's alg is to make an equal superposition over an arithmetic of numbers(Note that is our inputted number)
In our above register, we only really need quits. There are two registers. The first register is the size of the input, and the second register has the length of the log of the output.Make the state and measure it to get <a data-href="#^periodicR" href="#^periodicR" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^periodicR</a><a data-href="#^periodicR" href="#^periodicR" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.5.1)</a>Suppose that along with , there was some garbage register which we dropped everything into. If there was some pieces of the function embedded in the other components, then we can't pull the information out of the system. It doesn't matter if you look at them or not, it's still there. The garbage register is still entangled into our current register. Look at an EPR pairThe first qubit is in the maximally mixed state. Entanglement has the same effect as measurement,Entanglement has the same effect as measurement, this is a fundamental property of quantum mechanicsThis is our amplitude vector, we want to find a way to measure our function in some sort of way which makes this periodicity our result. ITS THE FOURIER TRANSFORM GUYSOn a coming homework we're going to prove that this is actually a unitary matrix.<br>We are able to construct the above entires through <a data-href="#^FourierMatrixConstruction" href="#^FourierMatrixConstruction" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^FourierMatrixConstruction</a><a data-href="#^FourierMatrixConstruction" href="#^FourierMatrixConstruction" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.5.6)</a> from earlier, where are the rows and columns of the matrixIn the way that when Hadamard acts on a two-state system, it takes us to the maximally mixed state, does for a state system also take us to the maximally mixed state?
Yep! In a lot of ways it makes more sense to think of our current Hadamard as the special 2-state case.
You're given a vector , what is the naive upper bound complexity for this? The point of the FFT, is that we're going to find some structure in that will let us compute in .<br><a data-tooltip-position="top" aria-label="https://www.aimath.org/news/congruentnumbers/howtomultiply.html" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.aimath.org/news/congruentnumbers/howtomultiply.html" target="_self">Gauss actually discovered the FFT before Bell labs did,</a> in the 1800s!
To find this, we're just going to stare at and see if we can exploit structureTo make this more obvious to see, we're going to swap the two middle columns. Denoting the swap is THERE ARE SNEAKY HADAMARDS IN HERE!When we apply the swapping, and it's going to be hard to see, butWhat happens with odd powers of ? What if the number isn't a exponential of 2?
It's way more complicated, so we're focussing on the silly small case
GenerallyWhen we multiply in To figure out the runtime of this recursion, we say
thatWe know that we are bounded at the bottom, so we are going to bound it. We apply twice on We can make that last jump by expanding to infinity, which can stop being applied after operations. Then the only thing that doesn't fall out is our term. Our goal before was , but it's different now. We have a statIt's easier to do, because now the answer is like implicit. It's a physical consequence being done to your amplitudes.
The goal is also just harder though in terms of efficiency. For Shor's algorithm, we need a number of gates which is polynomial in <br>
To find that, we're going to use the FFT vibe. Specifically, we want to translate <a data-href="#^translatedPart" href="#^translatedPart" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^translatedPart</a><a data-href="#^translatedPart" href="#^translatedPart" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.5.13)</a> into the language of quantum circuits.We're going to assume we have a quantum circuit already for , because if we can do that we're just going to recurse.We can decompose the matrix into single qubit operations based on orders of decreasing magnitude. Yet again, the fact that is so helpful.<br>
THEN BOOM HADAMARDS FOR THE LAST CONVERSION TO <a data-href="#^translatedPart" href="#^translatedPart" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^translatedPart</a><a data-href="#^translatedPart" href="#^translatedPart" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.5.13)</a><br>Note that the rotations quickly get infinitesimal, which might become increasingly difficult with <a data-href="1.14 Computing with Quantum States#^c11659" href="school/physics/qis/notes/1.14-computing-with-quantum-states.html#^c11659" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.14 Computing with Quantum States &gt; ^c11659</a><a data-href="1.14 Computing with Quantum States#^c11659" href="school/physics/qis/notes/1.14-computing-with-quantum-states.html#^c11659" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.14.3 ((Approximate) Universal Gate Set)</a>, but we can just use what we know about the being unrecognizable, and know that after a point rotations make no effect.
Essentially from the below, we can see that the amplitudes of , get wrapped into the phase.Then finally:]]></description><link>school/physics/qis/notes/2.5-fast-fourier-transform-and-qft.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.5 Fast Fourier Transform and QFT.md</guid><pubDate>Thu, 07 Nov 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.6 More Shor's Algorithm]]></title><description><![CDATA[Today we covered how to interpret measurements from Shor's algorithm, with a cameo from number theory.Reviewing Fourier from last time From Soloway-Kitaev, wouldn't the Fourier transform to be of a more complex space complexity? We don't have arbitrary control phase gates right
Theorem 1.15.1 ((Soloway-Kitaev) Arbitrary Unitary Algorithmic Complexity).
Any -qubit unitary can be implemented with an exponential number of gates, within precision using at most Where is some constant less than 3.97, which depends on the gate set.
This also assumes that your gate-set includes inverses! If I'm a person running on hour days, the clocks that always point the same way will be those which equally divide .Say Now let's imagine each clock, and below we imagine a thumb tack right underneath. The pin is moved in the direction of where you started the previous day, to where you started the current one.
With a 24 hr clock, you eventually make it back to where you began.
With a 26 hour clock, you get constructive interference. All the contributions to this movement add up.
Same with the 13 hour clock.
With the math, We want to apply , and understand what that does.
We're about to make an absurd assumption. We're going to say that evenly divides This is absurd because is a power of , so is as well in this assumption. If we knew that we could just guess.We're going to generalize later.What is , ? is a root of unity where . is some possible measurement result on the output register
Notice that we're adding up all the phases from each possible offset from , all onto a value , Here, is our thumbtack. is our clock
Just looking at the inner sumNow the question is, is a multiple of or not? Remember, is a root of unity!
If , then If this isn't true, then we observe the same clock behavior. As we go through a clock period, we eventually hit the origin.
Observe:
Random s.t Remember our assumption, which was that . This means that , so we can actually observe that result. Imagine that I measure at some point. Then running nth times, we'd get And then we can just take the GCD with <a data-href="2.4 Introduction Shor's Algorithm#^beb0e8" href="school/physics/qis/notes/2.4-introduction-shor's-algorithm.html#^beb0e8" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.4 Introduction Shor's Algorithm &gt; ^beb0e8</a><a data-href="2.4 Introduction Shor's Algorithm#^beb0e8" href="school/physics/qis/notes/2.4-introduction-shor's-algorithm.html#^beb0e8" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.4.1 (Euclid's algorithm)</a>!!
Definition 2.4.1 (Euclid's algorithm). If I wanna know the GCD(40,95), I can always perform integer division small to large, and take the remainder.
In this case, it's 15.
Then we know that (Because if a number can divide 40 and 95, of course it can divide the difference).
You just keep going until you hit the bottom Once one number divides the other, the smaller one is the GCD! Suppose that takes the formwe want to determine which is now ASSUME: <br>Repeating the steps from <a data-href="#^summationDudes" href="#^summationDudes" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^summationDudes</a><a data-href="#^summationDudes" href="#^summationDudes" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.2)</a>The question now, is how the hell do we use this probability distribution to find ??<br>Going back to <a data-href="#^form" href="#^form" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^form</a><a data-href="#^form" href="#^form" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.5)</a>From our original definition of , That means that our real ratio , is a rational number nearby which has a much smaller denominator.
If we find , then if we find then With this, we can then find our from the same gcd method<br>How do we find that closest number with the smaller denominator. We use <a href=".?query=tag:NumberTheory" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#NumberTheory">#NumberTheory</a> !
Let's use as an example. Write that as a fractionWe basically keep recursing that above process, until the next coming fraction is less then .
This is provably done in polynomial time.
Now that we've obtained ]]></description><link>school/physics/qis/notes/2.6-more-shor's-algorithm.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.6 More Shor's Algorithm.md</guid><pubDate>Tue, 12 Nov 2024 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.8 Grovers Algorithm]]></title><description><![CDATA[Continuing from <a data-href="2.7 What Else can Shor do, and Grover#Grover's Algorithm" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#Grover's Algorithm" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 What Else can Shor do, and Grover &gt; Grover's Algorithm</a><a data-href="2.7 What Else can Shor do, and Grover#Grover's Algorithm" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#Grover's Algorithm" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">2.7 What Else can Shor do, and Grover &gt; Grover's Algorithm</a>Definition 2.7.11 (Search Problem).
Given a function Decision Version: Is there an s.t Search Version (Promised at least 1 s.t ) : Find is called a marked item
A simple description, is I guarantee that there is treasure in one of boxes, finding which box there's treasure in. How does inverting about the average for every element of a set , change ?The diffusion operator is trying to put more and more probability mass on the marked item.
Let's say we keep applying the operator, and watch how the amplitude of our special item evolves.We can then observe that the probability of measuring the correct outcome becomes<br><a data-href="2.7 What Else can Shor do, and Grover#^5bad13" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^5bad13" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.7 What Else can Shor do, and Grover &gt; ^5bad13</a><a data-href="2.7 What Else can Shor do, and Grover#^5bad13" href="school/physics/qis/notes/2.7-what-else-can-shor-do,-and-grover.html#^5bad13" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.7.13 (Grover Diffusion Operator)</a> Let our input be the maximally mixed stateThen we define asTo get from the all zero state<br>Then we apply that to <a data-href="#^diffusionStart" href="#^diffusionStart" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^diffusionStart</a><a data-href="#^diffusionStart" href="#^diffusionStart" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.8.4)</a>We can see thatThen our original diffusion operator can be written asWhere is The reason this is an OR function, is that it acts like a phase oracle. If our input state was then it would have an amplitude of 1 (it would act from the top right). If there was any in the state, it would have an an amplitude of -1.
Then it's easy to see how you can get this from the Toffoli gates.
Expanding out our grover search algorithmWe can't just apply the diffusion operator and get probability forever thoughAll action happens in a 2=dim subspace spanned by and We know that at the beginning, and are almost orthogonalIn our 2D subspace, we're flipping our new vector about the axis
Where . Inversion about the average is just rotating us on this subspace.
We want to rotate a total of to get to . And we also with each iteration of , we increase by , soNotice, that if we run it for too long, we end up having no idea what the marked item was! We end up orthogonal to it.Well there's no value which will get us to that entire peak, is never rational. We can implement fractional implementations of Grover's algorithm
Aaronson's idea for his future Sci-Fi book
The climax: The good guys are holed up in the fortress, surrounded by the enemy. The fate of the world depends on if they can break a crypto code in time (symmetric key). Best they can do is attack with grover. Grover hasn't run through enough iterations yet, and they're running out of time. Either they measure now and risk everything, or they wait another minute for it to finish.
3 items are marked.
We should hope that Grover's Algorithm still works, and it would be nice if it works faster. Classically, this is by . The more items are marked, the less "hay you need to sift through before you get lucky and find a needle".
In our new subspace, we define asThe number of iterations is then fromSo we getWhat if I don't know the value of ?In general, we have no idea in advance how many items are marked. The success probability isn't monotonic, it goes up and down. The period of oscillation depends on the number of marked items. It's totally possible that we pick a number of iterations that with some value gives us perfect success, and another value gives guaranteed failure.
We can get at least one, since it's the base frequency. Want: iterations to find 1 marked item out of with high probability, despite not knowing k in advance.
Assume that when we get any measurement outcome from the search, just plug it back in to the original search function.Try: (Every item is marked)
If we don't find the marked item with this condition, decrease the possible value of with exponential backoffOnce we're within 10% of the correct value of , we'll be near the peak of the relevant periodic function. Why doesn't this extra query complexity add a log slowdown?
The claim is that this only modifies our initial algorithm by a constant
<br>Our success probability from <a data-href="#^probabilityBackoff" href="#^probabilityBackoff" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^probabilityBackoff</a><a data-href="#^probabilityBackoff" href="#^probabilityBackoff" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.8.15)</a> isWell the second term is a constant! That's an infinite series, so it converges! It's important to note that we can still have the correct answer with wrong values of . The closer we get, the higher our success. How do we pick the best exponential backoff?
It's a coming homework problem...
How do we even construct any ?
There are two main ways you can imagine applying grover's algorithm on a QC is computed by some quantum circuit: We have an algorithm which can figure out if is a marked item or not, then un-computes. Ex: Combinatorics Find s.t Classical: This takes time complexity
Grovers: In this setting, the quantum speedup is a conjecture. is just sitting in actual memory somewhere. This is a provable speedup. Requires qRAM (Memory which can store classical information, but can be implemented quantumly) ]]></description><link>school/physics/qis/notes/2.8-grovers-algorithm.html</link><guid isPermaLink="false">School/Physics/QIS/Notes/2.8 Grovers Algorithm.md</guid><pubDate>Tue, 19 Nov 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Can find the Syllabus <a data-tooltip-position="top" aria-label="../Class Content/PHY 355 Syllabus - Fall 2024.pdf" data-href="../Class Content/PHY 355 Syllabus - Fall 2024.pdf" href="school/physics/qis/modern-physics/class-content/phy-355-syllabus-fall-2024.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Content/PHY 355 Syllabus - Fall 2024.pdf" data-href="../Class Content/PHY 355 Syllabus - Fall 2024.pdf" href="school/physics/qis/modern-physics/class-content/phy-355-syllabus-fall-2024.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a>
Prof. Thomas is the honorific she uses, but Dr. Thomas works too
Only requirements are Kickoff event, and meet 6 times total
Class is recorded, so we can see the recordings there, just don't share.The goal of the course is to provides a conceptual foundation for physics discovered in the early 20th centuryClassical Physics could explain macroscopic objects at standard speeds, and that's why it was unchallenged for centuries.
Office hours with Prof
Tues 3-4pm, or other times by appointment
Locations are zoom or in person
Office hours with TA
Monday 4-5pm
Lowest two homeworks are dropped, do your homework yourselfMuch of this class period was spent teaching everyone the basics of python]]></description><link>school/physics/qis/modern-physics/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/0.1 Introduction.md</guid><pubDate>Tue, 27 Aug 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 Random Walks]]></title><description><![CDATA[Early 20th century, Physicists found out that many otherwise VERY complicated systems, can be approximated through the behavior of a random walk.Definition 1.2.1 (Random Walk).
Given a cartesian graph with nodes, and a target node, a random walk is the behavior of the target node as it follows the following steps: Pick a random direction to move on the graph, among the nodes adjacent to you
Move in that direction
Repeat until instructed to terminate
Random walks can be done in any space, in any number of dimensions.
While you are guaranteed to return to your starting point over an infinite time in in the cases , it isn't guaranteed at 1import random2import math3import matplotlib.pyplot as plt4NSTEPS = 405position = [0.]6for step in range(NSTEPS):7	motion = 08	randomChoice = random.random()9	if randomChoice&gt;.5:10 motion = 111	else:12 motion =-113	newpos = position[-1] +motion14	position.append(newpos)15print(position)16plt.plot(position)17plt.grid()18plt.title('Random Walk Example on a Line')19plt.xlabel('Time (iterations)')20plt.ylabel('Position')21plt.show()Definition 1.2.2 (ensemble). A system of different random walks
Below is how we'd code an ensable1import random2import math3import matplotlib.pyplot as plt4import numpy as np5def randomWalk(samples):6	position = 07	for step in range(NSTEPS):8 motion = 09 randomChoice = random.random()10 if randomChoice&gt;.5:11 motion = 112 else:13 motion =-114 position = position+motion15	return position16print(randomWalk(40))17##Now we write our ensamble code18def ensemble(runs = 500,steps = 50):19	finalPos = []20	for i in range(runs):21 finalPos.append(randomWalk(steps))22	return finalPos23runs = 200024steps = 100025ensembleResult=ensemble(runs = runs, steps = steps)26std = np.std(ensembleResult)27mean = np.mean(ensembleResult)28plt.hist(ensembleResult,bins = 50,label = f'$\\sigma$ = {round(std,2)}\n $\mu$ = {round(mean,2)}')2930plt.grid()31plt.title(f'Random Walk Result Histogram\n with {runs} runs, and {steps} steps per run')32plt.xlabel('Time (iterations)')33plt.ylabel('Position')34plt.legend()35plt.show()36The graph is forming a normal distribution around the center (zero). You cam make the following two observationsPlaying around with the code, you can modify the ensemble function to them plot things like the standard deviation as a function of time, or the mean as a function of time.Really useful news, is that instead of having to run the code times to characterize the behavior of our ensemble, we can instead find a way to characterize the gaussian distribution directly.
Many systems are possible to approximate thorough a random walk, such as potentially modeling hard-body gas systems. 1print(ensemble())We just didn't know that atoms existed, but when we zoomed in on dust, it seemed to be jittering about.Here we're going to implement a simple random walk in 1import random2def random2(steps):3	position_x = [0.]4	position_y = [0.]5	for i in range(steps):6 choice = random.randint(0,1)7 direction = random.choice([-1,1])89 match choice:10 case 0:11 newX = position_x[-1]+direction12 newY = position_y [-1]13 case 1:14 newX =position_x[-1]15 newY = position_y[-1]+direction16 position_x.append(newX)17 position_y.append(newY)18	return position_x,position_y19steps = 120020x,y = random2(steps)21plt.plot(x,y,color = 'green',alpha = .25)22plt.grid()2324plt.title(f'Random Walk in $R^2$ with {iterations} steps')25plt.scatter(x[0],y[0],label = 'start')26plt.scatter(x[-1],y[-1],label = 'end')27plt.axhline(y=0,color = 'black',linewidth = '2')28plt.axvline(x=0,color = 'black',linewidth = '2',label = 'Origin')29scale = 303031plt.legend()32plt.show()]]></description><link>school/physics/qis/modern-physics/notes/1.2-random-walks.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.2 Random Walks.md</guid><pubDate>Thu, 29 Aug 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.3 Kinetic Theory of Ideal Gasses]]></title><description><![CDATA[Definition 1.3.1 (Ideal Gas Model).
An ideal gas is assumed to be a gas where The molecules are small relative to the total volume of the gas
No interactions between molecules except inelastic collisions (no charge interactions)
Molecules are perfectly hard and don't rotate
There are elastic collisions with the walls of the container Definition 1.3.2 (Ideal Gas Law). Where is the pressure of the gas is the volume of the container is the number of mols is the ideal gas constant is the absolute temperature in Kelvin
Every molecule can be described with the position and velocity of the molecules
Definition 1.3.3 (Principle of Indifference).
There is no reason to favor one microstate over the other
Definition 1.3.4 (Ergodic Hypothesis).
A system will eventually take "every possible state" that is consistent with it's macroscopic properties
You can then predict long ter behavior through consideration of all possible states
Average time behavior is the same as the average behavior between all states
Definition 1.3.5 (Statistical Equilibrium).
The system is not in an extremely unlikely state (all molecules are on one side)
It is much easier to describe equilibrium states with a few macroscopic parameters since you can wave away edge cases
How do we "count" the number of states to be consistent with the ergodic hypothesis
Start with N particles, initialize each particle randomly with a position and velocity
Extrapolate forward using velocities using if hits wall, reverse position
if two particles are close enough, they have to bounce off
Repeat for time-steps How would you go about making this more efficient. This seems to have runtime.Is this simulation stable at infinity? Other than shortening the timestamp, how do you avoid energy from blowing up?
Better way of asking, is this numerically stable?
It seems like it is! Compared to other numerical methods, these events occurring are discrete not continuous. That means the occurrence of each event can be relatively well tracked, compared to how RK4 and Euler methods use linear approximations to discretely describe continuously changing systems.
Something interesting is that in the graph of energy over time on the left side of a box, it seems to oscillate with a base frequency. One explanation form <a data-tooltip-position="top" aria-label="../../../../../Personal/People/Caden Walters" data-href="../../../../../Personal/People/Caden Walters" href="personal/people/caden-walters.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">Caden</a><a data-tooltip-position="top" aria-label="../../../../../Personal/People/Caden Walters" data-href="../../../../../Personal/People/Caden Walters" href="personal/people/caden-walters.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Caden</a>, is that in a randomly arranged box, it's possible one box has higher kinetic energy than the other side. That kinetic energy will then oscillate back and forth from side to side, making the energy fluctuate.
How would you determine the frequency of the kinetic energy oscillation?
This is seriously so interesting to think about, with such an obvious answer. 10/10 Caden moment
Where is the number of collisions, is the area of the surface that the particle bounces off of, is the change in momentum over time.
How do we determine the number of collisions in a given time? Start with one molecule<br>Proof of <a data-href="#^932978" href="#^932978" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^932978</a><a data-href="#^932978" href="#^932978" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.3.6 (The Average Kinetic Energy of a Molecule in an Ideal Gas)</a>.
Then the pressure form one molecule isThen Where is the squared average velocity over all molecules
Then you can assume that due to randomnessSo Then where is the number of mols, and is the absolute number of molecules. Because they are both the same number with a scaled component, we can then cancel it out and refactor.
From here, we can break this down toTheorem 1.3.6 (The Average Kinetic Energy of a Molecule in an Ideal Gas). This is true for any molecule at a temperature, regardless of it's mass or personal properties
Temperature is the kinetic energy of a gas.
Where is Boltzmann's constant (Which is ). This means that energy is uniquely dependent on the Temperature. □
Temperature is the kinetic energy of a gas.
This is just the average kinetic energy of a molecule in an ideal gas.
This also means that the average speed of a molecule at is 500.
The in the is related to the number of degrees of freedom. More generally<br>Definition 1.3.7 (Equipartition Principle).
From <a data-href="#^932978" href="#^932978" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^932978</a><a data-href="#^932978" href="#^932978" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.3.6 (The Average Kinetic Energy of a Molecule in an Ideal Gas)</a>, for n-dimensions, the amount of energy in each dimension is equally split. where is the degrees of freedom. In In an ideal-gas, the standard deviation of the velocities is just the velocity squared.There's so much brain-rot in my head, that when she says "sigma", I go into fight. or flight
This meansAnd we can then solve for to getFor our normal distribution then, we can plug in for velocity in the func, and then in the denominator of the coefficient of the Gaussian, we plug in our upper equation for REVIEW THIS DERIVATION
I'm wary on how we got , and then how we derived the final expression for a Maxwell-Boltsman Distibution
]]></description><link>school/physics/qis/modern-physics/notes/1.3-kinetic-theory-of-ideal-gasses.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.3 Kinetic Theory of Ideal Gasses.md</guid><pubDate>Thu, 05 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.4 Statistical Mechanics]]></title><description><![CDATA[Definition 1.4.1 (Statistical Mechanics).
Explains macroscopic properties such as temperature, pressure, etc. in terms of microscopic states of a system
If the spin is aligned, we make it , and if anti-aligned then The total energy isWe also assume the particles don't interact with each other
For a fixed number of particles, we can define the magnetization asWe can then find the total number of possible states for Exercise 1.4.2 (For , , what is the number of accessible states). The number of possible states is Definition 1.4.3 (Micro-canonical ensemble).
Any system where we know the number of particles, and the total energy. This means we can write out all the possible states.
The energy that a system states, is directly proportional to the number of micro statesFor any split system, the below statement must be trueWhere is the number of micro states. This is the condition of equilibrium. ]]></description><link>school/physics/qis/modern-physics/notes/1.4-statistical-mechanics.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.4 Statistical Mechanics.md</guid><pubDate>Tue, 10 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.5 Spin Systems and Microcanonical Ensemble]]></title><description><![CDATA[Definition 1.4.3 (Micro-canonical ensemble).
Any system where we know the number of particles, and the total energy. This means we can write out all the possible states.
In statmech, we define a small chunk so that we can make the degrees of freedom inside the system discrete. That way we can count the arrangement of continuous variables. We're literally imposing a grid.Momentum of particle is constrained by the energy the system can take. This is a maximum momentum. We can define the total energy to beThe total momentum is thusThis then defines energy in terms of a hypersphere, where each axis is the momentum on one particle.This means that the total allowed momentum states Theorem 1.5.1 (The Surface Area of a Hyper-Sphere).
Given a hypersphere in , the surface area of a hypersphere is You can derive this through taking surface integrals in of the hyper-spherical-gaussian This surface area is proportional to the number of momentum states available
The number of momentum micro states is thenWhere is a small chunk size of momentum for each particle
Then the number of Energy micro-states isAs it turns outWhere is planks constantHow can you define if the point was an arbitrary grid system?
We need for statmech to work at all, so historically we just picked values for those that were arbitrarily small. Later we were able to get a measurement If I'm understanding the history right, for statmech to work at all you need a discretized system. Measuring planks constant came later
to resolve Gibbs paradox, we divide the number of states by . Then we'd use Stirling's approximation]]></description><link>school/physics/qis/modern-physics/notes/1.5-spin-systems-and-microcanonical-ensemble.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/1.5 Spin Systems and Microcanonical Ensemble.md</guid><pubDate>Thu, 12 Sep 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.1 The Need for Quantization]]></title><description><![CDATA[What fails statmech seems to be energy being continuous
Diatomic molecules have additional degrees of freedom, which mean that their heat capacity has more degrees of freedom then What we find is that a certain amount of energy is needed to access a specific degree of freedom. This is true even for solids.]]></description><link>school/physics/qis/modern-physics/notes/2.1-the-need-for-quantization.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/2.1 The Need for Quantization.md</guid><pubDate>Tue, 01 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.2 The Components of the Atom]]></title><link>school/physics/qis/modern-physics/notes/2.2-the-components-of-the-atom.html</link><guid isPermaLink="false">School/Physics/QIS/Modern Physics/Notes/2.2 The Components of the Atom.md</guid><pubDate>Thu, 03 Oct 2024 00:00:00 GMT</pubDate></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Syllabus is <a data-tooltip-position="top" aria-label="../Class Official Files/Syllabus_Sp_25.pdf" data-href="../Class Official Files/Syllabus_Sp_25.pdf" href="school/physics/electrodynamics/class-official-files/syllabus_sp_25.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Official Files/Syllabus_Sp_25.pdf" data-href="../Class Official Files/Syllabus_Sp_25.pdf" href="school/physics/electrodynamics/class-official-files/syllabus_sp_25.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a><br>
Textbook is Griffiths found <a data-tooltip-position="top" aria-label="../Class Official Files/David J. Griffiths - Introduction to Electrodynamics 4th edition - libgen.li.pdf" data-href="../Class Official Files/David J. Griffiths - Introduction to Electrodynamics 4th edition - libgen.li.pdf" href="school/physics/electrodynamics/class-official-files/david-j.-griffiths-introduction-to-electrodynamics-4th-edition-libgen.li.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../Class Official Files/David J. Griffiths - Introduction to Electrodynamics 4th edition - libgen.li.pdf" data-href="../Class Official Files/David J. Griffiths - Introduction to Electrodynamics 4th edition - libgen.li.pdf" href="school/physics/electrodynamics/class-official-files/david-j.-griffiths-introduction-to-electrodynamics-4th-edition-libgen.li.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a>
Office hours: PMA 11.324 Tuesday 9-11am
You can also meet via appointment on zoom.<br>
Instapoll link <a data-tooltip-position="top" aria-label="https://polls.la.utexas.edu/course/4790/student" rel="noopener nofollow" class="external-link is-unresolved" href="https://polls.la.utexas.edu/course/4790/student" target="_self">here</a><br>
Course Canvas is <a data-tooltip-position="top" aria-label="https://utexas.instructure.com/courses/1406291" rel="noopener nofollow" class="external-link is-unresolved" href="https://utexas.instructure.com/courses/1406291" target="_self">here</a>
<br><img alt="../../../../Supplemental Files/images/Pasted image 20250112152929.png" src="supplemental-files/images/pasted-image-20250112152929.png" target="_self">
Important dates: Monday February 17, Midterm #1 on Ch. 1-2
Monday March 10, Midterm #2 on Ch. 3-4
Monday April 14, Midterm #3 on Ch. 5-6
Final exam: Thursday, May 1, 8:00 am-10:00 am First day we're just doing introductions, please no. Oh. Well.
Criteria
Few seconds, name, one thing they want people to know
"My name is Azal, and I like to read"
Why's it importantThe goal is to reach at the end EM waves. Lectures are recorded online.
Midterms occur in a 12 hour window, when you open it you have two hours.
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Midterm 1 (Ch 1-2) ⏳2025-02-17 🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Midterm 2 (Ch 3-4) ⏳ 2025-03-10🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Midterm 3 (Ch 5-6) ⏳ 2025-04-14🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Final (Ch 5-6) 8:00-10:00am ⏳ 2025-05-01🆔 PHY 352K
1 homework, and 1 midterm get dropped. Tenerani ur a heroBi-weekly homework assignments (They're probably long then)
You can use a scientific calculator, but nothing else including graphing calculators (?!?!?!?) <br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #1 10:00PM⏫ 📅 2025/01/17🆔 PHY 352K ✅ 2025-02-06
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #2 10:00PM⏫ 📅 2025/01/31🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #4 10:00PM ⏫ 📅 2025/02/14🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #4 10:00PM ⏫ 📅 2025/02/28🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #5 10:00PM ⏫ 📅 2025/03/14🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #6 10:00PM ⏫ 📅 2025/03/28🆔 PHY 352K
<br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> HW #7 10:00PM ⏫ 📅 2025/03/28🆔 PHY 352K
I can probably make a homepage, which just lists my tasks for the week and their due dates by category. That and then homepages for each class which includes local tasks and calendars. <br><a href=".?query=tag:task" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#task">#task</a> Texas Mindset Reflection 🔽 📅 2025-01-15 🆔 PHY 352K ✅ 2025-02-06
]]></description><link>school/physics/electrodynamics/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/0.1 Introduction.md</guid><pubDate>Sun, 12 Jan 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.1 Reviewing Vectors]]></title><description><![CDATA[Reviewing vectors, vector algebra, and coordinate systems. This class is very much review of existing required vector knowledge, so reviewing this isn't mandatory.Definition 1 (Vector).
A quantity with direction and magnitude.
Ex: Directions, the position of something, velocity(?) Exercise 1.1.1 (How far has our person travelled?). We want to represent our movement with a displacement vector . In this case our displacement vector is . For distance, we get the magnitude of the vector There are two representationsThis idea of the coordinate representation originating from projections scales .
From this, we extend to the generalizing fact that given a space of basis vectors , and a vector within that space where is the projection onto that basis vector.Vectors can be summed, commute, and can be multiplied by a scalar.Just like how you can represent vectors in a geometric approach and coordinate approach, so too can you use those for addition.In the coordinate approachSubsequently this can be applied to subtraction as wellLike any other addition, vectors can only be linearly combined if their units match
You can't just add a displacement vector to acceleration vector
Additionally, vectors obey the distributive lawWe then move to defining the dot product, which is a vector operation which takes two vectors and maps them to a scalar. Associated note <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">here</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">here</a>. The dot product gives you the projection of one vector onto another.Definition 1.1.2 (Vector Dot Product).
Given that , the dot product is defined as The dot product itself represents the projection of one vector onto another
<br>From <a data-href="#^c716d7" href="#^c716d7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^c716d7</a><a data-href="#^c716d7" href="#^c716d7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.1.2 (Vector Dot Product)</a> , we can show thatTheorem 1.1.3 (Dot Product-Magnitude Identity).
The dot product of a vector with itself, is the magnitude squared <br>Proof.@ <a data-href="#^92e8b2" href="#^92e8b2" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^92e8b2</a><a data-href="#^92e8b2" href="#^92e8b2" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.1.3 (Dot Product-Magnitude Identity)</a>
Given that , we know that <br>Additionally from <a data-href="#^c716d7" href="#^c716d7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^c716d7</a><a data-href="#^c716d7" href="#^c716d7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.1.2 (Vector Dot Product)</a> Therefore□
Geometrically, the dot product isDefinition 1.1.4 (Cross Product for Vectors).
For vectors , the cross product takes two vectors and maps them to a mutually orthogonal vector. Geometrically is defined as where is pulled from the right hand rule<br>
In the coordinate approach it's derived as The cross product, unlike <a data-href="#^c716d7" href="#^c716d7" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^c716d7</a><a data-href="#^c716d7" href="#^c716d7" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.1.2 (Vector Dot Product)</a> only operates in The magnitude of the cross product can be interpreted as the area of the parallelogram spanned by Definition 1.1.5 (Separation Vector).
Given two vectors , we define the separation vector as The magnitude of our separation vector is The direction of the separation vector is then The coordinate system we've been using is the Cartesian Coordinate System. Translations to other coordinate systems will be found in the lecture notes.]]></description><link>school/physics/electrodynamics/notes/1.1-reviewing-vectors.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.1 Reviewing Vectors.md</guid><pubDate>Wed, 15 Jan 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.3 Differential Operators]]></title><description><![CDATA[Last time they discussed differential operators, gradients, curl, divergence, etc.
We're reviewing:
coordinate systems (Spherical and Cylindrical)
Nabla operators in those coordinate systems
Line integrals
This is appreciated, because I didn't get much from Beckner
Friday we're reviewing the classic vector calc theorems.
This has a divergence of 1. because the direction of the vector never changes, it is defined with a fixed direction.
In general we start with some vector whereTo get the unit vector, you divide the vector by its magnitudeDefinition 1.3.1 (Unit Vector).
For any given vector , the unit vector is defined such that it lies along the same direction as , with magnitude 1. To get the divergence of our vectorA non-zero divergence is equivalent to to having field aligned divergences and the direction of the flow changes outward. A divergence can be zero if the two terms compensate for each other. The strength changes, but the field spreads out and then comes back in. This is why divergence is a scalar product! It explains variations on a field form all directions.Question
Can you really product rule in this way? The divergence operator feels different from the gradient operator
What does it mean to take. the gradient of a scalar?
the magnitude. isa multivariable function so we just take the gradient as we would normally.
Example 1.3.2 (Find the divergence of ).
The divergence has a first term of zero, and the field is anti-aligned across the component's axis which. is also zero. Example 1.3.3 (Div = 0, but dield lines aren't straight : ). Notice how even though the direction of the vector. is changing, we seem to flow in a specific direction AT HOME, work this tragic thing through with the gradients
Why did we do this at all? This seems more complicated than the standard way of calculating the divergence
It's just to build a visual intuition for the behavior, and how they do the same thing
An aside, I just called tennerani torabi, I'm gonna explode actually. Definition 1.3.4 (Gradient Operator).
Given some function , who's orthonormal basis is spanned by the set of , we define the gradient as Definition 1.3.5 (Divergence).
Given some vector we define the divergence ( ) as Definition 1.3.6 (Curl).
Given some vector we define the curl ( ) as Example 1.3.7 (Given : Find ).
In other words, describe this VVF in spherical coordinates. We'd just use the Jacobian right? To do this, recall the following conversion identities I'm actually crashing out getting a name wrong is so embarrassing I swear I was just thinking about girl day To solve it into spherical coordinates, you use these identities to solve for the angles. I don't want to type that out, but it happens through taking projections. Take the dot product of your cartesian components, with your spherical basis vectors. See more at <a data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection#^956507" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection &gt; ^956507</a><a data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection#^956507" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 6.2.1 (Projection)</a> and <a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">6.2 Dot Products, Cross Products, and Projection</a><a data-tooltip-position="top" aria-label="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" data-href="../../../Math/Linear Algebra/6.2 Dot Products, Cross Products, and Projection" href="school/math/linear-algebra/6.2-dot-products,-cross-products,-and-projection.html" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">6.2 Dot Products, Cross Products, and Projection</a>
Why are we doing it so complicated?
I think because it's a review day, she's really going ground up <br>Example 1.3.8 (AT HOME: Given a function : Find ).
This is exactly like <a data-href="#^e0fde1" href="#^e0fde1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^e0fde1</a><a data-href="#^e0fde1" href="#^e0fde1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Example 1.3.7 (Given : Find )</a> <br>How does electromagnetism behave in ? Maxwell's equations still need to work
<a data-tooltip-position="top" aria-label="http://www.gauge-institute.org/Vector/MagneticMonopoles.pdf" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.gauge-institute.org/Vector/MagneticMonopoles.pdf" target="_self">This</a> straight up says that the curl operation in takes your result ot <br>
This is a <a data-tooltip-position="top" aria-label="https://physics.stackexchange.com/questions/21678/maxwell-in-multiple-dimensions-what-happens-to-curl" rel="noopener nofollow" class="external-link is-unresolved" href="https://physics.stackexchange.com/questions/21678/maxwell-in-multiple-dimensions-what-happens-to-curl" target="_self">StackOverflow answer</a>
We define some path length differential . In spherical, we'd have an increment . Cylindrical has We also know that with the chain rule]]></description><link>school/physics/electrodynamics/notes/1.3-differential-operators.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.3 Differential Operators.md</guid><pubDate>Wed, 22 Jan 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.4 Vector Integrals]]></title><description><![CDATA[Today is the last boring class
We're covering surface &amp; volume integrals
Fundamental theorems
Dirac Delta Function
<a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Del_in_cylindrical_and_spherical_coordinates#Del%20formula" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Del_in_cylindrical_and_spherical_coordinates#Del%20formula" target="_self">This link</a> from wikipedia has a nice table which is helpfulWe're integrating over structures normally.Definition 1.4.1 (Line Integral).
Given a curve and a function ,we can describe a line integral as integrating along it's path . If it is a vector-valued-function, you'd take a dot product To calculate this, you: Parameterize the curve with one variable Solve for the values of using the parameterization Integrate your function over s Given that you have some parameterization for asand your function in , the formula isThe comes from the fact that you're integrating along the magnitude. If , then that's essentially finding the length of your curve. Think of as a density function! If the density is , and you only vary the length, the mass is the length!Same procedure as before, but you don't take the magnitude of .Example 1.4.2 (Given a function and a curve ). [!example] Calculating a Line Integral along a fixed curve
She wants us to calculate a line integral along a straight line in space, for In general, is parallel to the vector from towards Just like a line integral, a surface gets parameterized by .Definition 1.4.3 (Surface Integral).
Given a surface and a function ,we can describe a line integral as integrating along it's path . If it is a vector-valued-function, you'd take a dot product To calculate this, you: Parameterize the surface with two variables Solve for the values of using the parameterization Calculate using and then get the magnitude. (That's because the magnitude of a cross product, is the enclosed area!)
Integrate your function over This is equivalent to taking the flux over the surfaceDefinition 1.4.4 (The Direction of a Surface).
The normal of any surface, is defined as the vector perpendicular to the surface at a given point YOU ALWAYS NEED TO REMEMBER THE RELEVANT JACOBIAN FOR THE COORDINATE SYSTEM In this class, Tenerani uses the below conventionto save time.
Divergence
Stolkes
Gradient tTheorem
Theorem 1.4.5 (Gradient Theorem).
The line integral of the gradient of some fuunction, is just the difference of the function defined at the endpoint. This is how we get conservative forces. Theorem 1.4.6 (Divergence Theorem).
The curl through a colume is equivalent to the surface integral of the fieeld Theorem 1.4.7 (Stokes Theorem).
The total microscopic circulation is equal to the total circulation on the outer boundary Exercise 1.4.8 (Given the following function ). Calculate the Divergence
<br>Calculate the volume integral of the integral by using the <a data-href="#^281900" href="#^281900" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^281900</a><a data-href="#^281900" href="#^281900" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.4.6 (Divergence Theorem)</a> ]]></description><link>school/physics/electrodynamics/notes/1.4-vector-integrals.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.4 Vector Integrals.md</guid><pubDate>Fri, 24 Jan 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/f9eYHQ8RZ4zfc4unXx.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/f9eYHQ8RZ4zfc4unXx.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.9 Electric Potentials]]></title><description><![CDATA[We're covering our first maxwell equation
The div and curl of The electric potentialShe highly recommends we study:
Gauss's law,
how to calc electric fields from charge distros electric potentials
The exam is basically a canvas quiz, and then she reads through your work for the MCQ. It's designed to take the full two hours with a 10 minute upload margin
Gauss's law relates the flux of the electric field through a closed surface, to the net charge inside the surface. With the above electric field and the gaussian surface, then our electric field us just radially symmetric. We pick an imaginary height of the surface Good news is that our fake height cancels out!If we had a plane with infinite surface charge, then we'd use a square. Only the parts of the square orthogonal have a non-zero value, which is two sides. Gauss's law helps us calculate the electric field when we have a nice symmetry. It leads us to the first Maxwell equation!
Proof of <a data-href="#^702fc1" href="#^702fc1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^702fc1</a><a data-href="#^702fc1" href="#^702fc1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.9.1 (Maxwell's First Equation)</a>.
The goal is to combine gauss' law and the divergence theoremThis gives us the below relation<br>Now from <a data-href="#^electricfieldatDist" href="#^electricfieldatDist" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^electricfieldatDist</a><a data-href="#^electricfieldatDist" href="#^electricfieldatDist" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.1)</a> we can see that the term is like a gradientIn electrostatics, the electric field is irrotational!□Theorem 1.9.1 (Maxwell's First Equation).
In electrostatics, the divergence of your vector field is directly proportional to the charge density. The curl is always zero. We can reduce our problem to solving for a scalar function over a vector!
<br>The curl being zero is equivalent to the statement that the line integral of is zero by <a data-href="1.4 Vector Integrals#^8fe60f" href="school/physics/electrodynamics/notes/1.4-vector-integrals.html#^8fe60f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.4 Vector Integrals &gt; ^8fe60f</a><a data-href="1.4 Vector Integrals#^8fe60f" href="school/physics/electrodynamics/notes/1.4-vector-integrals.html#^8fe60f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.4.7 (Stokes Theorem)</a> The integral is path invariant
The electric field is just equal to the difference in the potentialThe electrostatic field is then the gradient of the scalar function, via the definition of a conservative field.By analogy it's a lot like the gravitational field<br>Theorem 1.9.2 (Electric potential for a point charge).
Following from <a data-href="#^702fc1" href="#^702fc1" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^702fc1</a><a data-href="#^702fc1" href="#^702fc1" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.9.1 (Maxwell's First Equation)</a> , the porential of a point charge is The general electric potential is<br>Exercise 1.9.3 (Find the electric field everywhere of a charged cylinder with density ).
I'm not solving this because it's really trivial, but outside the cylinder we treat it as a wire like from <a class="original-internal-link" data-href="#E field of Line charge" href="school/physics/electrodynamics/notes/1.9-electric-potentials.html#E_field_of_Line_charge_0" target="_self" rel="noopener nofollow" style="display: none;">E field of Line charge</a><a class="internal-link mathLink-internal-link" data-href="#E field of Line charge" href="school/physics/electrodynamics/notes/1.9-electric-potentials.html#E_field_of_Line_charge_0" target="_self" rel="noopener nofollow">E field of Line charge</a>, then inside we integrate like normal
Outside the cylinder it'sTo calculate lambda you integrate over for the thingyThen we divide by our hypothetical height to get the charge densityThen for the inside it's little r and linear]]></description><link>school/physics/electrodynamics/notes/1.9-electric-potentials.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.9 Electric Potentials.md</guid><pubDate>Fri, 07 Feb 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/3KWDnCHTYVmPyyGl99.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/3KWDnCHTYVmPyyGl99.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.10 More Electric Potential]]></title><description><![CDATA[Electric potential Cont
Conductors vs Insulators
Brutal force, integrate over the distribution <a data-href="1.9 Electric Potentials#^electricfieldatDist" href="school/physics/electrodynamics/notes/1.9-electric-potentials.html#^electricfieldatDist" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.9 Electric Potentials &gt; ^electricfieldatDist</a><a data-href="1.9 Electric Potentials#^electricfieldatDist" href="school/physics/electrodynamics/notes/1.9-electric-potentials.html#^electricfieldatDist" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.9.1)</a>
Gauss's Law- This is the most likely
Gradient of the potential
The potential is also related to the work per unit charge, this is voltage!The potential is convention wise, assumed zero at infinityThe potential with a continuum of point charges, is given by the below expression
Conductors permit electrons to flow freely, charge is typically distributed along the surface to make the electric field along the interior of the conductor zero.
<br>How long does it take to measure the moving of charges in a conductor when it wants to approach equilibrium?
<a rel="noopener nofollow" class="external-link is-unresolved" href="https://physics.stackexchange.com/questions/86658/how-long-does-it-take-for-a-metal-to-reach-equilibrium" target="_self">https://physics.stackexchange.com/questions/86658/how-long-does-it-take-for-a-metal-to-reach-equilibrium</a> Insulators prevent the free flow
Outside the conductor, the induced electric field doesn't need to cancel with the applied field. This is how we get ourselves to a faraday cage! The equipotential lines are always perpendicular to the electric field lines. No work is required to move a charge along an equipotential surface. On the surface of a conductor, electric field lines always point normal.How do you calculate the surface charge along a closed conductor given an external electric field?
*crickets*
Example 1.10.1 (Potential of a Conducting Sphere).
The electric field on the inside is zero The magnitude of the E field is discontinuous at the edge of the sphere, but the potential is constant on the interior since the E field is zero inside! Email Andeen lauren notes ]]></description><link>school/physics/electrodynamics/notes/1.10-more-electric-potential.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.10 More Electric Potential.md</guid><pubDate>Mon, 10 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.11 Boundary Conditions and Energy]]></title><description><![CDATA[We're talking about boundary conditions to describe the discontinuous changes in the electric field at surfaces, and electrostatic energy.
Can't browse online
Cant use generative AI (it fails anyway lol)
Don't do with peers
Questions are essentially "do the integral", so do the integral yourself.
Midterm is open note
Midterm is on the style of the second homework other than the first one. Up until chapter 2.4.1
Your work has to be intelligible
There are 4 main questions, with subsections. Nothing unfamiliar with other upperdivsConductors only have surface charges, no bulk charges. Additionally because they have mobile charges, you can induce charge distributions onto a conductor.
The electric field to the right of an infinite charged plate isThe electric field is discontinuous if the plane was completely thin, but you can't be discontinuous. See <a data-href="1.10 More Electric Potential#^4ee782" href="school/physics/electrodynamics/notes/1.10-more-electric-potential.html#^4ee782" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 More Electric Potential &gt; ^4ee782</a><a data-href="1.10 More Electric Potential#^4ee782" href="school/physics/electrodynamics/notes/1.10-more-electric-potential.html#^4ee782" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Example 1.10.1 (Potential of a Conducting Sphere)</a> for a visual of a discontinuous field.
How do you determine the jump you can have between two regions?I DIDN'T KNOW THE PROFESSOR DESKS COULD RISE AND FALL. THAT WAS MAGICTo do this, construct a gaussian pillbox of infentesimal height We construct an infinitesimal pillbox with height .We construct a gaussian surface to get fluxThen take The only closed charge that will contribute here as we approach 0 is the surface charge! As the volume tends to zero, the charge volume distribution won't contribute.<br><a data-href="#^discontinuous" href="#^discontinuous" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^discontinuous</a><a data-href="#^discontinuous" href="#^discontinuous" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.4)</a> The electric field is discontinuous if there is a surface charge on our contour. Otherwise it is continuous.But in real life it can't be. How do we resolve the discontinuity
Probably because of the skin depth. There is no delta function of charge distribution, it is distributed along the surface with narrow depth.
For a conducting sphere, this then means that isBefore we did the perpendicular field, now we want the parallel.Now similar to before, we're going to take a line integral over our new loop . It's a closed loop. We know that the voltage around the loop has to be zero.The tangential component of an electric field has to be continuous.
The electric field inside the conductor must be zero, therefore the only non-zero component is the perpendicular one just off of the surface.
This states that our electric field only goes up after we exit the surfaceFor a generic E-field and arbitrary path, the work done moving a charge between two points If I have a set of charges in a spacial configuration, the work I did to put those charges in that arrangement is equal to the energy contained by the system.
This is what you would expect.<br>
Proof.@ <a data-href="#^690926" href="#^690926" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^690926</a><a data-href="#^690926" href="#^690926" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.11.1 (The Energy Contained by a Collection of Charges)</a> With more than two charges, place them into some set . is composed of every unique subset of with length 2. The energy contained by isThis is another example of the superposition principle! Another way of thinking about it is a fully interconnected graph, and you simply sum up the energy to construct all edges.
Arbitrarily it'sWhy the less than or equals?
The reason why is because otherwise an edge gets it's energy accounted when it's AND . Double counting!
Now we do a trick, we're excluding the duplicates anyway so it's the same as dividing by two!
□Theorem 1.11.1 (The Energy Contained by a Collection of Charges).
For a set of charges in the list , the total potential of the system is: Now we're moving from the discrete description, to the continuum. This will show the energy really is in the electric field
For a continuous distribution of charge, we can write it as<br><a data-href="#^690926" href="#^690926" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^690926</a><a data-href="#^690926" href="#^690926" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.11.1 (The Energy Contained by a Collection of Charges)</a> can be rewritten asNotice how our separated function is just the potential of .Now we want to move to a continuum"The infinitesimal energy at a point is equal to the potential at that location, times the charge density at that location."
We know that for conductors, the charge is splattered across the surface.Next time we will go from here, to the expression involving the electric field.]]></description><link>school/physics/electrodynamics/notes/1.11-boundary-conditions-and-energy.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.11 Boundary Conditions and Energy.md</guid><pubDate>Wed, 12 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.6 Conductors vs Dielectrics]]></title><description><![CDATA[There will be class Monday the day of the midtermA Dipole embedded in a uniform E-field feels a torqueIf the electric field is not uniform, it can be written asIf the field is changing, we can expand a taylor series at and Exercise 2.6.1 (AT HOME: If I wanted to verify, I could take what we know about the taylor series about a scalar field, but for a directional derivative!).Definition 2.6.2 (Dielectric).
Unlike a conductor, the charges are bound. The molecules or atoms can deform or rearrange, but the charges themselves are mostly stationary (Orders of magnitude smaller than conductors, smaller) Because charges are bound, there are at most two ways that atoms or molecules feel the presence of an electric field. They can stretch (inducing a dipole moment)
Whether or not you have an existing dipole in the material, the response will be different.
When an atom or molecule acquires a dipole moment, we say the dipole is induced.Qualitatively, within the dielectric there are a multitude of mini dipoles. When an external electric field is applied the molecules partially align with the field. Like magnetic dipoles! <a href=".?query=tag:magneticFields" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#magneticFields">#magneticFields</a><br><img src="supplemental-files/images/pasted-image-20250303103341.png" target="_self">
Each mini dipole is parallel to . All the mini dipoles are uniformly distributed. In the bulk, they will cancel out, but at the interface there is going to be an imbalance. the overall polarization is induced that generated a return field The total electric field at equilibrium will be The constant is the dielectric constant. If the dielectric fills the entire space between 2 plates (a capacitor), by extension we haveIf is the dipole moment of a given molecule or arom, the dielectric polarization is ^eee7ad<br>
<img src="supplemental-files/images/pasted-image-20250303104143.png" target="_self">
The average is over the small volume centered at is charge number density at the given molecule represents the dipole moment per unit volume
Reminder from before, for a dipole at the origin the potential is given by
The generalized potential at position <br>Why are we covering this derivation. It's just like, shifting all the terms from <a data-href="#^e47beb" href="#^e47beb" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^e47beb</a><a data-href="#^e47beb" href="#^e47beb" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.6.9)</a> <br>The field of a polarized object is then the sum of all the individual contributions is converting <a data-href="#^eee7ad" href="#^eee7ad" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^eee7ad</a><a data-href="#^eee7ad" href="#^eee7ad" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^eee7ad</a> to integral formReducing yields<br><img src="supplemental-files/images/pasted-image-20250501081317.png" target="_self">
]]></description><link>school/physics/electrodynamics/notes/2.6-conductors-vs-dielectrics.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/2.6 Conductors vs Dielectrics.md</guid><pubDate>Mon, 03 Mar 2025 00:00:00 GMT</pubDate><enclosure url="https://i.giphy.com/nUdpTf5XWtbUI.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src="https://i.giphy.com/nUdpTf5XWtbUI.webp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.6 The Electric Field]]></title><description><![CDATA[Today we're going over
The Electric Field
Charge Distribution
E-Field from charge distribution
It's convenient to introduce a continuous charge distribution to simplify the calculations.Definition 1.6.1 (Columb's law).
Columb's law is a fundamental theorem in electrostatics. It tells us that between two point charges, the electric force is The little is our test charge, and is our source.The ratio of the force to the charge is what we call the electric field
This also meansWhat happens with multiple charges.Definition 1.6.2 (The Superposition Principle).
The superposition principle states that the electric field on some charge by a set of charges , is the sum of all the individual force interactions superimposed Positive charges make field lines which are emitted, negative charges make field lines which absorb.Guys I just had my first conversation with no words, I didn't understand anything past "I'm sleepy", but we did do a Azal: "What's up "
Harshini: "Im sleepy"
Azal: Agrees
Harshini: Does some weird glaring
Harshini: Does more
Exercise 1.6.3 (Find the magnitude of the electric field drawn at ). Our field then gets pulled down as if there was a charge above it, with twice the magnitude. First I calculate the angle below ^angleComponent
That's the vertical component. Then we just multiply by the electric field strength from each &gt;charge, given by the below Now to to evaluate our projection, we plug in our solved angle ]]></description><link>school/physics/electrodynamics/notes/1.6-the-electric-field.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.6 The Electric Field.md</guid><pubDate>Wed, 29 Jan 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.12 Capacitors and Electrostatics]]></title><description><![CDATA[We wrapped up our previous lecture on electrostatic energy, by proving <a data-href="#^7d3a65" href="#^7d3a65" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^7d3a65</a><a data-href="#^7d3a65" href="#^7d3a65" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.12.1 (Energy contained in charge distribution)</a>.Midterm is released 11:30am Monday, open till 11:30PM. Can't submit after 11:30.
Monday's lecture is pre-recorded<br>From <a data-href="1.11 Boundary Conditions and Energy#^2a436d" href="school/physics/electrodynamics/notes/1.11-boundary-conditions-and-energy.html#^2a436d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.11 Boundary Conditions and Energy &gt; ^2a436d</a><a data-href="1.11 Boundary Conditions and Energy#^2a436d" href="school/physics/electrodynamics/notes/1.11-boundary-conditions-and-energy.html#^2a436d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(1.11.11)</a>, we can see that the energy is dependance on volume. But if we draw an arbitrary volume to integrate over, it's charge density difference is zero so the integral stays at the normal surface.
From here we use gauss lawWhy does the integral cancel out? Well the goes by , goes by , and the surface goes by . That means our net integral goes by Theorem 1.12.1 (Energy contained in charge distribution). <br>Exercise 1.12.2 (Electrostatic energy of a charged sphere. Calc teh electrostatic energy of a uniformly charged sphere of radius by building the distribution up by shells.).
<img src="supplemental-files/images/pasted-image-20250214101640.png" target="_self">
Method 1: Brute Force<br>
We'll call is the work it takes to bring a shell at from infinity to our previous shell. We then just integrate this over Method 2: Using <a data-href="#^7d3a65" href="#^7d3a65" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^7d3a65</a><a data-href="#^7d3a65" href="#^7d3a65" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Theorem 1.12.1 (Energy contained in charge distribution)</a> , we integrate over the electric field and need volume We're integrating to infinity, but inside and outside are different! We need to split the integral Capacitors are any two charged surfaces with a potential difference.
If you have a capacitor connected to a source of charge, then it can have a fixed voltage with unlimited charge. That's why they're used in so many experimental applications for pulsed energy.
Capacitors are rlly important trust.
The capacitance of a capacitor is the ratio between stored charge, and the potential difference.The unit is the Farad.
For a charged conducting sphere, the capacitance isFor funsies you calculate your own capacitance. Approximate yourself as a sphere. ]]></description><link>school/physics/electrodynamics/notes/1.12-capacitors-and-electrostatics.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/1.12 Capacitors and Electrostatics.md</guid><pubDate>Fri, 14 Feb 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.4 Introduction to Multipole Expansion]]></title><description><![CDATA[Conclusion of separation of variables
Field of a dipole
Multipole expansion of electric potentialI am so sleepyIs the example from last time unique to the specific problem, or was there a uniqueness we exploited
I think it was general, the boundary conditions impose totally descriptive constraints on the behavior
When you're very far from the source of a given electric field, it can be approximated as
A single clumped charge
A dipole
Ideal Dipoles - A physical and positive charge separated by a distance An ideal dipoleCalculating the electric field and potential of an ideal diponeIt's key that because the dipoles aren't point chargesNow we're going to take the limitNow we're going to taylor expand around . This is what it means to take the multipole expansionMore math then gets done to help us find the below potential of a dipoleNotice that the potential of a monopole has a potential dropping by It's best done in spherical coordinates, see class notes]]></description><link>school/physics/electrodynamics/notes/2.4-introduction-to-multipole-expansion.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/2.4 Introduction to Multipole Expansion.md</guid><pubDate>Wed, 26 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.5 Multipole Expansion of Electric Potential]]></title><description><![CDATA[Theorem 2.5.1 (Coorndinate Free Dipole Representatio). ]]></description><link>school/physics/electrodynamics/notes/2.5-multipole-expansion-of-electric-potential.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/2.5 Multipole Expansion of Electric Potential.md</guid><pubDate>Fri, 28 Feb 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[Electro Final]]></title><description><![CDATA[<img src="supplemental-files/images/pasted-image-20250501084447.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084456.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084500.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084504.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084510.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084513.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084517.png" target="_self"><br>
<img src="supplemental-files/images/pasted-image-20250501084521.png" target="_self">]]></description><link>school/physics/electrodynamics/notes/electro-final.html</link><guid isPermaLink="false">School/Physics/Electrodynamics/Notes/Electro Final.md</guid><pubDate>Mon, 20 Oct 2025 19:48:20 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[index]]></title><description><![CDATA[Use the sidebar on the left to navigate all the courses I've taken thus far.
I'm still working on getting equation-numbering to work online. If you have any suggestions let me know!Note that any pdfs or mp4s were removed to respect copyright of respective publishers.
Additionally, all homework assignments are removed for similar reasons!]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Mon, 20 Oct 2025 19:44:21 GMT</pubDate></item><item><title><![CDATA[3.1 Heat Engines]]></title><description><![CDATA[Efficiency of a heat engine is bounded by the second law. The definition is Definition 3.1.1 (Efficiency (Heat Engine)).
The ratio of the useful work by the input heat. <img src="supplemental-files/images/pasted-image-20251017112552.png" target="_self">
This is an example of a maximum efficiency process. If you could go through step by step and compute the work with heat exchange it does, you'd obtain the maximum efficiencyThe Carnot cycle is reversible unlike many processes. This is how Carnot conceived of this. He didn't have the language of entropyDoes that mean if I pump heat in it'll induce a temperature differential?
Yeah! That's how a refrigerator works. Once reason the Stirling engine is important is that it's pretty close to being the carnot efficiency. If you drew out the Carnot cycle as it would just be a box!]]></description><link>school/physics/statistical-mechanics/notes/3.1-heat-engines.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/3.1 Heat Engines.md</guid><pubDate>Fri, 17 Oct 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2.7 Pressure and Entropy]]></title><description><![CDATA[Salty waterPure watereh salt watereh salt]]></description><link>school/physics/statistical-mechanics/notes/2.7-pressure-and-entropy.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/2.7 Pressure and Entropy.md</guid><pubDate>Mon, 13 Oct 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.6 Mechanical Equilibrium and Pressure]]></title><description><![CDATA[the electromagnetic field can't occupy a = negative temperature state. How does blackbody radiation work with negative temperature? We use IR cameras all the time to see temperature in a room
The EM field doesn't seem to be able to occupy negative temperature states, which means that even it has limits. Thus the reason why the EM field won't emit characteristic blackbody information is the same reason why a regular thermometer fails
Are there exceptions? Are there other fields which can support negative temperatureIt'll be easier to answer both of these things whne we have a boltzmann distribution]]></description><link>school/physics/statistical-mechanics/notes/2.6-mechanical-equilibrium-and-pressure.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/2.6 Mechanical Equilibrium and Pressure.md</guid><pubDate>Fri, 10 Oct 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.5 Paramagnetism]]></title><description><![CDATA[<a class="original-internal-link" data-href="../../Quantum 1/Notes/3.5 Induced Dipole Dipole Interaction.md" href="school/physics/quantum-1/notes/3.5-induced-dipole-dipole-interaction.html" target="_self" rel="noopener nofollow" style="display: none;">3.5 Induced Dipole Dipole Interaction</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum 1/Notes/3.5 Induced Dipole Dipole Interaction.md" href="school/physics/quantum-1/notes/3.5-induced-dipole-dipole-interaction.html" target="_self" rel="noopener nofollow">3.5 Induced Dipole Dipole Interaction</a> Nuclear spins have a very long relaxation time against their environment. It's very weak in their mutual interaction. That means we can use them as an analogous model to how we construct our paramagnetism.]]></description><link>school/physics/statistical-mechanics/notes/2.5-paramagnetism.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/2.5 Paramagnetism.md</guid><pubDate>Wed, 08 Oct 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.4]]></title><description><![CDATA[The <a data-href="2.2 Entropy#^75059d" href="school/physics/statistical-mechanics/notes/2.2-entropy.html#^75059d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.2 Entropy &gt; ^75059d</a><a data-href="2.2 Entropy#^75059d" href="school/physics/statistical-mechanics/notes/2.2-entropy.html#^75059d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.2.1 (Sackur–Tetrode Equation)</a> gives us the absolute value in the entropy (and also has a quantum mechanics reference), but also because our previously derived expression <a data-href="2.3 Entropy and Heat#^e4365f" href="school/physics/statistical-mechanics/notes/2.3-entropy-and-heat.html#^e4365f" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.3 Entropy and Heat &gt; ^e4365f</a><a data-href="2.3 Entropy and Heat#^e4365f" href="school/physics/statistical-mechanics/notes/2.3-entropy-and-heat.html#^e4365f" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">(2.3.5)</a> only gives the change in entropy.The assumptions that go into Sackur-Tetrode are the same as the ideal gas. As it cools they cease to be an ideal gas (The issue in Sackur tetrode would be going negative, but it breaks before than)So then if this breaks down when cold, how do we describe the absolute entropy of a system in those thresholds?In this system, we know that the total change in entropy is the sum of both changes in entropies.
The heat is For the sum, ^f1dc5d
Because the sun is much hotter than the Earth, we can already see that the entropy goes up. <br>It doesn't seem likely we can even use the formula selected in <a data-href="#^f1dc5d" href="#^f1dc5d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^f1dc5d</a><a data-href="#^f1dc5d" href="#^f1dc5d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^f1dc5d</a> , but in that paradigm we don't violate the second law.The alternative for our above system is the Virial TheoremDefinition 2.4.1 (Virial Theorem).
If then It's useful in statistical mechanics when the system of kinetic energies can be described by the equipartition theorem. The equipartition theorem still applies to the quadratic degrees of freedom.
This means that for equipartition
Oh so this is sick. That makes sense too. <br><a data-tooltip-position="top" aria-label="https://www.eng.uc.edu/~beaucag/Classes/AdvancedMaterialsThermodynamics/Books/Arieh%20Ben-Naim%20-%20A%20Farewell%20To%20Entropy_%20Statistical%20Thermodynamics%20Based%20On%20Information-World%20Scientific%20Publishing%20Company%20(2008).pdf" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.eng.uc.edu/~beaucag/Classes/AdvancedMaterialsThermodynamics/Books/Arieh%20Ben-Naim%20-%20A%20Farewell%20To%20Entropy_%20Statistical%20Thermodynamics%20Based%20On%20Information-World%20Scientific%20Publishing%20Company%20(2008).pdf" target="_self">This textbook</a> has a really cool derivation of <a data-href="2.2 Entropy#^75059d" href="school/physics/statistical-mechanics/notes/2.2-entropy.html#^75059d" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">2.2 Entropy &gt; ^75059d</a><a data-href="2.2 Entropy#^75059d" href="school/physics/statistical-mechanics/notes/2.2-entropy.html#^75059d" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.2.1 (Sackur–Tetrode Equation)</a> on page 353<br>This makes our heat capacity is NEGATIVE for a gravitational system?? Wow that's sick because for gravity in <a data-href="#^f903fa" href="#^f903fa" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^f903fa</a><a data-href="#^f903fa" href="#^f903fa" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 2.4.1 (Virial Theorem)</a> ]]></description><link>school/physics/statistical-mechanics/notes/2.4.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/2.4.md</guid><pubDate>Mon, 06 Oct 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[2.3 Entropy and Heat]]></title><description><![CDATA[<a class="original-internal-link" data-href="2.2 Entropy.md" href="school/physics/statistical-mechanics/notes/2.2-entropy.html" target="_self" rel="noopener nofollow" style="display: none;">2.2 Entropy</a><a class="internal-link mathLink-internal-link" data-href="2.2 Entropy.md" href="school/physics/statistical-mechanics/notes/2.2-entropy.html" target="_self" rel="noopener nofollow">2.2 Entropy</a> we learned how to relate entropy and energy. We then invoke the first law of thermodynamics to claim that^cbc28a
if no work is being done on the system.
Then we connect that to heat capacity via it's definition.
We know that <br>Plugging into <a data-href="#^cbc28a" href="#^cbc28a" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^cbc28a</a><a data-href="#^cbc28a" href="#^cbc28a" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^cbc28a</a> gives^646690
This allows us to measure changes in entropy via changes in temperature given the heat capacity. We're assuming here, what is the range along which this is valid?<br>Thanks to this, we can determine the absolute value of entropy by integrating <a data-href="#^646690" href="#^646690" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^646690</a><a data-href="#^646690" href="#^646690" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^646690</a> from Oh and then within our correct rangeOur final entropy expression though is]]></description><link>school/physics/statistical-mechanics/notes/2.3-entropy-and-heat.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/2.3 Entropy and Heat.md</guid><pubDate>Fri, 03 Oct 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[CheatSheet 1]]></title><description><![CDATA[Example of using combination formula
Van der Walls formula]]></description><link>school/physics/statistical-mechanics/notes/cheatsheet-1.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/CheatSheet 1.md</guid><pubDate>Mon, 22 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.11 The Second Law]]></title><description><![CDATA[Absent any other information, the second law of thermodynamics applies in both directions. What it means is that in the past, we were also more likely to be in a higher multiplicity macrostate
Wait that's weird why does it apply to both the future and the past.
The second law tells us that if we see a an unlikely state. At any moment, the most likely situation is that we're at a minima of entropy. Often though, we know other things. This is the Boltzmann brain paradox!
The most probably fluctuation that we'd produce the entire observable universe with all it's history is a further fluctuation from equilibrium. Again though, this assumes no prior assumptions. If we can explain this with initial conditions then
There's an infinite number of measures
Detailed balance
We're going to focus on a dipole electromagnet change, represented as either up or down. THey're drawn as a line to delineate but it isn't really important. We know that in this case, the maximum number of microstates is when the two spins are equal^42ec10
We want to use this at the large value approximation to find the probability of a value From here we then use <a data-href="1.10 The Second Law#^9a9481" href="school/physics/statistical-mechanics/notes/1.10-the-second-law.html#^9a9481" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">1.10 The Second Law &gt; ^9a9481</a><a data-href="1.10 The Second Law#^9a9481" href="school/physics/statistical-mechanics/notes/1.10-the-second-law.html#^9a9481" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.10.1 (Stirling's Approximation)</a> in conjunction with <a data-href="#^42ec10" href="#^42ec10" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^42ec10</a><a data-href="#^42ec10" href="#^42ec10" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^42ec10</a>. ^9851a9
Where ,Then we take the probabilities from multiplicities. See the slides for the thorough walkthrough.
The total number of micro-states isSo then our probability is <br>Then we taylor expand the logarithm from Stirling's approximation in <a data-href="#^9851a9" href="#^9851a9" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^9851a9</a><a data-href="#^9851a9" href="#^9851a9" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^9851a9</a> withWe're doing both a Taylor series (who's truncation will make answers as ) and Stirlings. Won't those errors go faster?
It's important to note that if then in Stirling's so these might actually "cancel" out
When you crank it out, this becomes a gaussian! The real function is probably similar for the same reason the binomial distribution approaches the gaussian as well.
There's also a nice reason to have the third term, it baked the normalization into the final probability for us.
Without it we'd need to renormalize ourselves. ]]></description><link>school/physics/statistical-mechanics/notes/1.11-the-second-law.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.11 The Second Law.md</guid><pubDate>Fri, 19 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.12 Midterm]]></title><link>school/physics/statistical-mechanics/notes/1.12-midterm.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.12 Midterm.md</guid><pubDate>Mon, 22 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.10 The Second Law]]></title><description><![CDATA[Thermodynamic limit: In the age of the universe you won't see a break from the limit. It's where the gaussian for the multiplicity of the system approaches the dirac delta limit in ratio to the average. The FWHM does get bigger, but the fraction of energy shifting between the two ends goes to zero. <a data-href="../../Quantum 1/Notes/1.8 Translation and Momentum#^0fb5c4" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^0fb5c4" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">../../Quantum 1/Notes/1.8 Translation and Momentum &gt; ^0fb5c4</a><a data-href="../../Quantum 1/Notes/1.8 Translation and Momentum#^0fb5c4" href="school/physics/quantum-1/notes/1.8-translation-and-momentum.html#^0fb5c4" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.8.2 (Dirac Delta Function)</a> <br>Definition 1.10.1 (Stirling's Approximation). <img src="supplemental-files/images/pasted-image-20250917114143.png" target="_self">
]]></description><link>school/physics/statistical-mechanics/notes/1.10-the-second-law.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.10 The Second Law.md</guid><pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1.9 Einstein Model of Solids]]></title><description><![CDATA[The Einstein model represents modelling systems in solids as sequences of harmonic oscillators. We know that the energy levels of a harmonic oscillator are discretized, so the microstate amount is]]></description><link>school/physics/statistical-mechanics/notes/1.9-einstein-model-of-solids.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.9 Einstein Model of Solids.md</guid><pubDate>Mon, 15 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.7 More Compression Work, Heat Capacities]]></title><description><![CDATA[Example 1.7.1 (Bile tire inflating, pressure compressed to 7 atm. What's the final volume of the air if it's mainly oxygen an dnitrogen. All degrees of freedom are accessible. Adiabatic). Because it is adiabatic we can use We know that There are 7 degrees of freedom for . Then we just solve this ]]></description><link>school/physics/statistical-mechanics/notes/1.7-more-compression-work,-heat-capacities.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.7 More Compression Work, Heat Capacities.md</guid><pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.6 Compression Work]]></title><description><![CDATA[Last time we learned that the first law was Then we learned the equipartition theoremIf we know that the volume is constant, the work done is zero. Then combining with the equipartition theorem we getOne nice result of the above expressions is that the heat capacity divided by should yield the number of degrees of freedom!^46430b
More specifically, this has an output space of integers in the form If we want to see how long it will take to make a cup of water boil in a 600-watt microwave oven assuming complete energy dump. 1 cup water is 200g (18g molar mass)
Find the energy needed to increase water's temperature by 1˚C ()
Assume a starting temp, chug
Should we factor in the fact that the water is radiating back heat? No! We know the relaxation time of a cup of water is experimentally about 30 minutes which is an order of magnitude larger than the time taken to heat it up. We can approximate it out.
Quasi-static processes are big compared to the speed of sound in the material or the internal relaxation time. The system itself has to remain in internal equilibrium to be able to integrate your curve. That is super fast though, science we're probably not going anywhere near the speed of sound. Can I use <a data-href="#^46430b" href="#^46430b" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^46430b</a><a data-href="#^46430b" href="#^46430b" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">^46430b</a> with more complex macromolecules to determine the number of degrees of freedom they may have, and approximate the number of atoms? Or are they far past the reasonable ideal gas paradignIf you want an adiabatic process, perform a quick process relative to the relaxation time to the environment, like why we can ignore the environmental radiation from the water in the microwave. ]]></description><link>school/physics/statistical-mechanics/notes/1.6-compression-work.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.6 Compression Work.md</guid><pubDate>Mon, 08 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.5 Equipartition Principle]]></title><description><![CDATA[These are all quadratic degrees of freedom by their energy terms
Assume all degrees of freedom are active at all temperatures (even though we know this isn't true, see <a class="original-internal-link" data-href="../../Quantum 2/Notes/2.12 Born Oppenheimer 2.md" href="school/physics/quantum-2/notes/2.12-born-oppenheimer-2.html" target="_self" rel="noopener nofollow" style="display: none;">2.12 Born Oppenheimer 2</a><a class="internal-link mathLink-internal-link" data-href="../../Quantum 2/Notes/2.12 Born Oppenheimer 2.md" href="school/physics/quantum-2/notes/2.12-born-oppenheimer-2.html" target="_self" rel="noopener nofollow">2.12 Born Oppenheimer 2</a>)Are flex vibrational modes quadratic
Well we can assert that they are approximately quadratic at low enough energies
Well how do you draw that line in the sand?
In practice you wouldn't need to. Once you get to the point where the higher order terms are relevant, you're near where the molecule disassociates. But you'd just calculate the energy with equipartition theorem, then compare to the function to see if it was effective.
EAT FINGER EAT FINGER why does my stomach hurt. i am so sure ive eaten]]></description><link>school/physics/statistical-mechanics/notes/1.5-equipartition-principle.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.5 Equipartition Principle.md</guid><pubDate>Fri, 05 Sep 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.2 Thermal Equilibrium]]></title><description><![CDATA[
You’ve got a cup of coffee that’s too hot! Conveniently, you’ve also got an ice cube. You’re going to get up and use the bathroom while the coffee cools off. Should you put the ice cube in now or after you get back?
My answer was: "Now since the greatest rate of heat transfer is when the temperature differential is highest. The coffee is also a good conductor compared to air."Definition 1.2.1 (Newton's Law of Cooling).
The speed that something cools down is related to the change in temperature between the heat engine and receiver As it turns out, in <a data-href="#^114e52" href="#^114e52" class="original-internal-link" target="_self" rel="noopener nofollow" style="display: none;">^114e52</a><a data-href="#^114e52" href="#^114e52" class="internal-link mathLink-internal-link" target="_self" rel="noopener nofollow">Definition 1.2.1 (Newton's Law of Cooling)</a> is a function of temperature so the "Law" is actually a small approximation
Today I learned that Fahrenheit(the person) wasn't a dumb dumb and actually had good reasons for defining Fahrenheit in that way. Definition 1.2.2 (Operational Definition).
Defining a quantity by how you measure it. Like defining time as the quantity driving a clock, or temperature by the displacement of mercury on a thermometer Does it ever make sense to say that one object is “twice as hot” as another? Does the answer depend on units? Yes because given two of the same temperature heat dumps, I can define something being twice as hot as an object which starts off displacing heat twice as fast. Or using the operational definition as twice as high on the scale When you’re sick with a fever and you take your temperature with a thermometer, approximately what is the relaxation time? A second or two with a digital thermo? Exercise 1.2.3 (Derive the formula to convert between Celcius to farenheit given that ice melts at 32F˚ and boils at 212˚F). We then can assume that the difference is linear (Why?). Then we just fit a line to the relationship to describe the equations! ]]></description><link>school/physics/statistical-mechanics/notes/1.2-thermal-equilibrium.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.2 Thermal Equilibrium.md</guid><pubDate>Wed, 27 Aug 2025 00:00:00 GMT</pubDate></item><item><title><![CDATA[1.1 Temperature]]></title><description><![CDATA[Why is it that while a blackbody will emit radiation in wavelengths longer than it's peak, it won't emit in wavelengths lower?<img src="supplemental-files/images/pasted-image-20250825113835.png" target="_self">
Quantum mechanics ig?
Class Question: What si temperature? How would you explain it?
The average kinetic energy of a system. I can explain it through using pressure, since that will give both the intuition of high velocity increasing momentum but also high mass
It's actually the entropy and the energy has the most concrete abstract definition. There's no clear definition on what it is fundamentally for a bit.
For now we're using an operational definition of temperature: "Temperature is what you measure with a thermometer"Cleaner definition: Temperature is a measure of the tendency of an object to give energy up to it's surroundings. This definition leverages the property of heat flow being contingent on temperature. Equilibrium between two objects means that there will be no temperature flow
Go to Q3 downstairs, then comparch, then print out the form, then aaronson, then go through courses, then lab work (is lauren active on slack?)]]></description><link>school/physics/statistical-mechanics/notes/1.1-temperature.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/1.1 Temperature.md</guid><pubDate>Mon, 25 Aug 2025 00:00:00 GMT</pubDate><enclosure url="." length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="."&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[0.1 Introduction]]></title><description><![CDATA[Link to the <a data-tooltip-position="top" aria-label="https://utexas.instructure.com/courses/1424219/pages/course-timeline-activities-and-grading-syllabus?module_item_id=15168939" rel="noopener nofollow" class="external-link is-unresolved" href="https://utexas.instructure.com/courses/1424219/pages/course-timeline-activities-and-grading-syllabus?module_item_id=15168939" target="_self">Syllabus</a> is here<br>
Link to the <a class="internal-link" data-href="../Class Official Files/An Introduction to Thermal Physics -- Daniel V_ Schroeder -- 2000 -- Addison - Wesley -- 9781292026213 -- aef3c843e4e459e342094d2568011e5b -- Anna’s Archive.pdf" href=".html" target="_self" rel="noopener nofollow">Textbook</a> is here
Link to Squarecap
Midterm I:&nbsp; &nbsp; &nbsp;Wed, Sept 24&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 11am-12pm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;IN CLASS
Midterm II: &nbsp;&nbsp; Wed, Oct 22&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;11am-12pm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;IN CLASS
Midterm III:&nbsp; &nbsp;Wed, Nov 19&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 11am-12pm&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;IN CLASS
Fill out a notecard, and drop it by MA 12.224
Just something to help him get to know us. It's participation oints
Name, how do i refer to you, what school, subjects, what do you wanna get out of this
what concerns
What did you and the person have in commonWe can get half credit back on missed exam points by redoing problems that we missed.Why does the powerpoint describe the course as having "3+1" units?
The last unit is smaller than the other 3, and it was also like a reference to spacetime having 3(space)+1 (time) dimension
There are aspects of statistical mechancis which don't describe a system governed by thermodynamics. <br>What is random matrix theory? How is it relevant to simulating nuclear dynamics?
<a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Random_matrix" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Random_matrix" target="_self">Wiki</a> Random matrix theory first gained attention beyond mathematics literature in the context of nuclear physics. Experiments by <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Enrico_Fermi" rel="noopener nofollow" class="external-link is-unresolved" title="Enrico Fermi" href="https://en.wikipedia.org/wiki/Enrico_Fermi" target="_self">Enrico Fermi</a> and others demonstrated evidence that individual <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Nucleon" rel="noopener nofollow" class="external-link is-unresolved" title="Nucleon" href="https://en.wikipedia.org/wiki/Nucleon" target="_self">nucleons</a> cannot be approximated to move independently, leading <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Niels_Bohr" rel="noopener nofollow" class="external-link is-unresolved" title="Niels Bohr" href="https://en.wikipedia.org/wiki/Niels_Bohr" target="_self">Niels Bohr</a> to formulate the idea of a <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Compound_nucleus" rel="noopener nofollow" class="external-link is-unresolved" title="Compound nucleus" href="https://en.wikipedia.org/wiki/Compound_nucleus" target="_self">compound nucleus</a>. Because there was no knowledge of direct nucleon-nucleon interactions, <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Eugene_Wigner" rel="noopener nofollow" class="external-link is-unresolved" title="Eugene Wigner" href="https://en.wikipedia.org/wiki/Eugene_Wigner" target="_self">Eugene Wigner</a> and <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Leonard_Eisenbud" rel="noopener nofollow" class="external-link is-unresolved" title="Leonard Eisenbud" href="https://en.wikipedia.org/wiki/Leonard_Eisenbud" target="_self">Leonard Eisenbud</a> approximated that the nuclear <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Hamiltonian_(quantum_mechanics)" rel="noopener nofollow" class="external-link is-unresolved" title="Hamiltonian (quantum mechanics)" href="https://en.wikipedia.org/wiki/Hamiltonian_(quantum_mechanics)" target="_self">Hamiltonian</a> could be modeled as a random matrix. For larger atoms, the distribution of the <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Energy_eigenvalues" rel="noopener nofollow" class="external-link is-unresolved" title="Energy eigenvalues" href="https://en.wikipedia.org/wiki/Energy_eigenvalues" target="_self">energy eigenvalues</a> of the Hamiltonian could be computed in order to approximate <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Scattering_cross_section" rel="noopener nofollow" class="external-link is-unresolved" title="Scattering cross section" href="https://en.wikipedia.org/wiki/Scattering_cross_section" target="_self">scattering cross sections</a> by invoking the <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Wishart_distribution" rel="noopener nofollow" class="external-link is-unresolved" title="Wishart distribution" href="https://en.wikipedia.org/wiki/Wishart_distribution" target="_self">Wishart distribution</a>.<a data-href="4" href=".html" class="internal-link" target="_self" rel="noopener nofollow">4</a>(<a rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Random_matrix#cite_note-4" target="_self">https://en.wikipedia.org/wiki/Random_matrix#cite_note-4</a>) WTF this is insane??
]]></description><link>school/physics/statistical-mechanics/notes/0.1-introduction.html</link><guid isPermaLink="false">School/Physics/Statistical Mechanics/Notes/0.1 Introduction.md</guid><pubDate>Sun, 24 Aug 2025 00:00:00 GMT</pubDate></item></channel></rss>